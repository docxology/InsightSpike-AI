{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "69de859b",
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-907070862.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# InsightSpike-AI: Large Scale RAG (Colab Pro / A100)\n",
        "\n",
        "This notebook runs a large-scale RAG experiment with the Exp2-4 lite pipeline.\n",
        "\n",
        "Notes:\n",
        "- Runtime > Change runtime type > GPU (A100 if available).\n",
        "- Results, cache, and dataset are stored on Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup Environment\n",
        "Clone the repo and install dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "REPO_URL = 'https://github.com/miyauchikazuyoshi/InsightSpike-AI.git'\n",
        "REPO_DIR = '/content/InsightSpike-AI'\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    !git clone --depth 1 {REPO_URL}\n",
        "\n",
        "%cd /content/InsightSpike-AI\n",
        "!pip -q install -e .\n",
        "!pip -q install sentence-transformers scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure Scale\n",
        "Adjust sizes below for larger or smaller runs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "DRIVE_ROOT = '/content/drive/MyDrive/insightspike/rag_large_scale'\n",
        "os.makedirs(DRIVE_ROOT, exist_ok=True)\n",
        "\n",
        "TOTAL_DOCS = 50000\n",
        "TOTAL_QUERIES = 5000\n",
        "MAX_QUERIES = TOTAL_QUERIES\n",
        "\n",
        "if TOTAL_DOCS % TOTAL_QUERIES != 0:\n",
        "    raise ValueError('TOTAL_DOCS must be divisible by TOTAL_QUERIES')\n",
        "DOCS_PER_QUERY = TOTAL_DOCS // TOTAL_QUERIES\n",
        "\n",
        "DATASET_PATH = os.path.join(DRIVE_ROOT, f'synthetic_{TOTAL_DOCS}_docs_{TOTAL_QUERIES}_queries.jsonl')\n",
        "RESULTS_DIR = os.path.join(DRIVE_ROOT, 'results')\n",
        "CACHE_DIR = os.path.join(DRIVE_ROOT, 'cache')\n",
        "CONFIG_PATH = os.path.join(DRIVE_ROOT, 'rag_large_scale_config.yaml')\n",
        "\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "print('Dataset:', DATASET_PATH)\n",
        "print('Results:', RESULTS_DIR)\n",
        "print('Cache:', CACHE_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Generate Large Dataset\n",
        "Creates a synthetic dataset on Drive (skips if already exists).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "if not os.path.exists(DATASET_PATH):\n",
        "    random.seed(42)\n",
        "    print(f'Generating {TOTAL_QUERIES} queries and {TOTAL_DOCS} documents...')\n",
        "\n",
        "    with open(DATASET_PATH, 'w', encoding='utf-8') as f:\n",
        "        doc_counter = 0\n",
        "        for q_idx in range(TOTAL_QUERIES):\n",
        "            batch_docs = []\n",
        "            for _ in range(DOCS_PER_QUERY):\n",
        "                doc_id = f'doc_{doc_counter}'\n",
        "                text = (\n",
        "                    f'This is the content of document {doc_counter}. '\n",
        "                    f'It contains information relevant to query {q_idx} if selected as ground truth.'\n",
        "                )\n",
        "                metadata = {'id': doc_id, 'source': 'synthetic'}\n",
        "                batch_docs.append({'id': doc_id, 'text': text, 'metadata': metadata})\n",
        "                doc_counter += 1\n",
        "\n",
        "            target_doc = batch_docs[0]\n",
        "            query_text = 'What is the content of document {}?'.format(target_doc['id'])\n",
        "            ground_truth = target_doc['text']\n",
        "\n",
        "            entry = {\n",
        "                'query': query_text,\n",
        "                'ground_truth': ground_truth,\n",
        "                'documents': batch_docs,\n",
        "            }\n",
        "            f.write(json.dumps(entry) + '\\n')\n",
        "\n",
        "    print('Created:', DATASET_PATH)\n",
        "else:\n",
        "    print('Dataset exists, skipping:', DATASET_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create Configuration\n",
        "Writes a config file pointing to the Drive dataset and output directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config_text = f'''\n",
        "experiment:\n",
        "  name: exp23_large_scale_{TOTAL_DOCS}\n",
        "  output_dir: {RESULTS_DIR}\n",
        "  seed: 42\n",
        "  target_ag_rate: 0.08\n",
        "  target_dg_rate: 0.04\n",
        "\n",
        "dataset:\n",
        "  path: {DATASET_PATH}\n",
        "  max_queries: {MAX_QUERIES}\n",
        "\n",
        "embedding:\n",
        "  model: sentence-transformers/all-MiniLM-L6-v2\n",
        "  normalize: true\n",
        "  cache_dir: {CACHE_DIR}\n",
        "\n",
        "retrieval:\n",
        "  top_k: 10\n",
        "  bm25_weight: 0.5\n",
        "  embedding_weight: 0.5\n",
        "  expansion_hops: 1\n",
        "\n",
        "gedig:\n",
        "  lambda: 0.6\n",
        "  use_multihop: true\n",
        "  max_hops: 3\n",
        "  decay_factor: 0.7\n",
        "  sp_beta: 0.2\n",
        "  theta_ag: 2.0\n",
        "  theta_dg: 0.05\n",
        "  ig_mode: raw\n",
        "  spike_mode: and\n",
        "\n",
        "psz:\n",
        "  acceptance_threshold: 0.6\n",
        "  fmr_threshold: 0.02\n",
        "  latency_p50_threshold_ms: 200\n",
        "\n",
        "baselines:\n",
        "  - name: static_rag\n",
        "    type: static\n",
        "  - name: gedig_ag_dg\n",
        "    type: gedig\n",
        "\n",
        "logging:\n",
        "  save_step_logs: false\n",
        "  save_memory_snapshots: false\n",
        "  snapshot_interval: 200\n",
        "'''\n",
        "\n",
        "with open(CONFIG_PATH, 'w', encoding='utf-8') as f:\n",
        "    f.write(config_text)\n",
        "\n",
        "print('Wrote config:', CONFIG_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Run Experiment\n",
        "This may take time at scale. Progress and results will be saved to Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m experiments.exp2to4_lite.src.run_experiment --config \"{CONFIG_PATH}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Inspect Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ls -lh \"{RESULTS_DIR}\" | tail -n 20\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
