{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# InsightSpike-AI: Large Scale RAG Experiment (Colab)\n",
                "\n",
                "This notebook demonstrates how to run a large-scale RAG experiment (e.g., 10,000 nodes, 1,000 queries) using the InsightSpike-AI framework.\n",
                "\n",
                "**Goal**: Evaluate geDIG on a larger dataset with real embeddings.\n",
                "**Target**: 1,000 queries, 10,000 documents, SentenceTransformers embeddings."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Environment\n",
                "We need `sentence-transformers` and `torch` for this experiment."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a672e15d",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!git clone https://github.com/miyauchikazuyoshi/InsightSpike-AI.git\n",
                "%cd InsightSpike-AI\n",
                "!pip install -e .[dev]\n",
                "!pip install sentence-transformers scikit-learn"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Generate Large Dataset (10k Nodes, 1k Queries)\n",
                "Since the repository only contains small samples, we will generate a synthetic dataset with:\n",
                "- **10,000 Documents**: Distributed across queries to build the corpus.\n",
                "- **1,000 Queries**: Each with a unique ground truth.\n",
                "- **Format**: Compatible with `dataset.py`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import random\n",
                "import os\n",
                "\n",
                "output_file = \"experiments/exp2to4_lite/data/synthetic_10k.jsonl\"\n",
                "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
                "\n",
                "total_docs = 10000\n",
                "total_queries = 1000\n",
                "docs_per_query = total_docs // total_queries  # 10 docs per query line\n",
                "\n",
                "print(f\"Generating {total_queries} queries and {total_docs} documents...\")\n",
                "\n",
                "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
                "    doc_counter = 0\n",
                "    for q_idx in range(total_queries):\n",
                "        # Generate 10 documents for this batch\n",
                "        batch_docs = []\n",
                "        for _ in range(docs_per_query):\n",
                "            doc_id = f\"doc_{doc_counter}\"\n",
                "            # Simple synthetic text\n",
                "            text = f\"This is the content of document {doc_counter}. It contains information relevant to query {q_idx} if selected as ground truth.\"\n",
                "            metadata = {\"id\": doc_id, \"source\": \"synthetic\"}\n",
                "            batch_docs.append({\"id\": doc_id, \"text\": text, \"metadata\": metadata})\n",
                "            doc_counter += 1\n",
                "        \n",
                "        # Pick the first one as 'relevant' for this query\n",
                "        target_doc = batch_docs[0]\n",
                "        query_text = f\"What is the content of document {target_doc['id']}?\"\n",
                "        ground_truth = target_doc['text']\n",
                "        \n",
                "        entry = {\n",
                "            \"query\": query_text,\n",
                "            \"ground_truth\": ground_truth,\n",
                "            \"documents\": batch_docs  # These will be added to the global corpus\n",
                "        }\n",
                "        f.write(json.dumps(entry) + \"\\n\")\n",
                "\n",
                "print(f\"Created {output_file}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Create Configuration\n",
                "We will create a custom configuration file `large_scale_config.yaml` that targets the full dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile large_scale_config.yaml\n",
                "experiment:\n",
                "  name: exp23_large_scale_10k\n",
                "  output_dir: experiments/exp2to4_lite/results\n",
                "  seed: 42\n",
                "  target_ag_rate: 0.08\n",
                "  target_dg_rate: 0.04\n",
                "\n",
                "dataset:\n",
                "  # Use the synthetic 10k dataset\n",
                "  path: experiments/exp2to4_lite/data/synthetic_10k.jsonl\n",
                "  max_queries: null  # Run all 1000 queries\n",
                "\n",
                "embedding:\n",
                "  model: sentence-transformers/all-MiniLM-L6-v2\n",
                "  normalize: true\n",
                "  cache_dir: experiments/exp2to4_lite/cache\n",
                "\n",
                "retrieval:\n",
                "  top_k: 10\n",
                "  bm25_weight: 0.5\n",
                "  embedding_weight: 0.5\n",
                "  expansion_hops: 1\n",
                "\n",
                "gedig:\n",
                "  lambda: 0.6\n",
                "  use_multihop: true\n",
                "  max_hops: 3\n",
                "  decay_factor: 0.7\n",
                "  sp_beta: 0.2\n",
                "  theta_ag: 2.0\n",
                "  theta_dg: 0.05\n",
                "  ig_mode: raw\n",
                "  spike_mode: and\n",
                "\n",
                "psz:\n",
                "  acceptance_threshold: 0.6\n",
                "  fmr_threshold: 0.02\n",
                "  latency_p50_threshold_ms: 200\n",
                "\n",
                "baselines:\n",
                "  - name: static_rag\n",
                "    type: static\n",
                "  - name: gedig_ag_dg\n",
                "    type: gedig\n",
                "\n",
                "logging:\n",
                "  save_step_logs: false\n",
                "  save_memory_snapshots: false\n",
                "  snapshot_interval: 200"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Run Experiment\n",
                "Execute the experiment using the custom config."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python -m experiments.exp2to4_lite.src.run_experiment --config large_scale_config.yaml"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fc58be90",
            "metadata": {},
            "source": [
                "## 5. Download Results (Base64 Fallback)\n",
                "If file explorer and direct download fail, run this cell.\n",
                "It will print a long text string. Copy that string to a local file named `results_base64.txt` and run the provided decode script."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7912e547",
            "metadata": {},
            "outputs": [],
            "source": [
                "import base64\n",
                "import os\n",
                "\n",
                "# Ensure zip exists\n",
                "if not os.path.exists('/content/results.zip'):\n",
                "    os.system('zip -r /content/results.zip experiments/exp2to4_lite/results')\n",
                "\n",
                "with open('/content/results.zip', 'rb') as f:\n",
                "    data = f.read()\n",
                "    b64_data = base64.b64encode(data).decode('utf-8')\n",
                "\n",
                "print(\"COPY THE STRING BELOW (BETWEEN THE SEPARATORS) AND SAVE TO 'results_base64.txt' LOCALLY:\")\n",
                "print(\"=\"*80)\n",
                "print(b64_data)\n",
                "print(\"=\"*80)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
