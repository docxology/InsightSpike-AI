{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-Regularization Experiment (Phase 5)\n",
    "\n",
    "**Goal**: Test causal hypothesis - Does minimizing geDIG F during training improve performance?\n",
    "\n",
    "- Baseline: standard CrossEntropy fine-tuning\n",
    "- Treatment: L_total = L_CE + α * F_mean\n",
    "- α sweep: [0, 0.001, 0.01, 0.1, 1.0] × 3 seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inline the training script (to avoid file upload issues)\n",
    "TRAIN_SCRIPT = '''\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "F-Regularized Training Experiment\n",
    "\n",
    "Tests the causal hypothesis: Does minimizing geDIG F during training improve performance?\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DifferentiableGeDIG:\n",
    "    \"\"\"Computes geDIG F in a differentiable manner.\"\"\"\n",
    "    lambda_param: float = 1.0\n",
    "    gamma: float = 0.5\n",
    "    temperature: float = 0.1\n",
    "    percentile: float = 0.9\n",
    "    max_path_length: int = 4\n",
    "\n",
    "    def compute_F(self, attention: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:\n",
    "        batch_size, num_heads, seq_len, _ = attention.shape\n",
    "        if attention_mask is not None:\n",
    "            mask_2d = attention_mask.unsqueeze(1).unsqueeze(2) * attention_mask.unsqueeze(1).unsqueeze(3)\n",
    "            attention = attention * mask_2d.float()\n",
    "        delta_epc = self._compute_soft_density(attention)\n",
    "        delta_h = self._compute_entropy(attention, attention_mask)\n",
    "        delta_sp = self._compute_soft_path_efficiency(attention, attention_mask)\n",
    "        F_values = delta_epc - self.lambda_param * (delta_h + self.gamma * delta_sp)\n",
    "        return {\"F\": F_values, \"F_mean\": F_values.mean(), \"delta_epc\": delta_epc, \"delta_h\": delta_h, \"delta_sp\": delta_sp}\n",
    "\n",
    "    def _compute_soft_density(self, attention: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, num_heads, seq_len, _ = attention.shape\n",
    "        attn_flat = attention.view(batch_size, num_heads, -1)\n",
    "        k = int(self.percentile * seq_len * seq_len)\n",
    "        threshold = torch.kthvalue(attn_flat, k, dim=-1).values.unsqueeze(-1).unsqueeze(-1)\n",
    "        edge_probs = torch.sigmoid((attention - threshold) / self.temperature)\n",
    "        return edge_probs.sum(dim=(-2, -1)) / (seq_len * seq_len)\n",
    "\n",
    "    def _compute_entropy(self, attention: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        batch_size, num_heads, seq_len, _ = attention.shape\n",
    "        attn_flat = attention.view(batch_size, num_heads, -1)\n",
    "        attn_norm = attn_flat / (attn_flat.sum(dim=-1, keepdim=True) + 1e-10)\n",
    "        entropy = -(attn_norm * torch.log(attn_norm + 1e-10)).sum(dim=-1)\n",
    "        if attention_mask is not None:\n",
    "            valid_count = attention_mask.sum(dim=-1).float()\n",
    "            max_entropy = torch.log(valid_count * valid_count + 1e-10).unsqueeze(1)\n",
    "        else:\n",
    "            max_entropy = math.log(seq_len * seq_len)\n",
    "        return entropy / (max_entropy + 1e-10)\n",
    "\n",
    "    def _compute_soft_path_efficiency(self, attention: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        batch_size, num_heads, seq_len, _ = attention.shape\n",
    "        attn_flat = attention.view(batch_size, num_heads, -1)\n",
    "        k = int(self.percentile * seq_len * seq_len)\n",
    "        threshold = torch.kthvalue(attn_flat, k, dim=-1).values.unsqueeze(-1).unsqueeze(-1)\n",
    "        adj = torch.sigmoid((attention - threshold) / self.temperature)\n",
    "        eye = torch.eye(seq_len, device=attention.device).unsqueeze(0).unsqueeze(0)\n",
    "        adj = adj + eye\n",
    "        path_efficiency = torch.zeros(batch_size, num_heads, device=attention.device)\n",
    "        adj_power = adj.clone()\n",
    "        for path_len in range(1, self.max_path_length + 1):\n",
    "            if path_len > 1:\n",
    "                adj_power = torch.clamp(torch.matmul(adj_power, adj), 0, 1)\n",
    "            path_efficiency = path_efficiency + (1.0 / path_len) * (adj_power > 0.5).float().mean(dim=(-2, -1))\n",
    "        return path_efficiency / self.max_path_length\n",
    "\n",
    "\n",
    "class FRegularizedModel(nn.Module):\n",
    "    \"\"\"Wrapper that adds geDIG F regularization to the loss.\"\"\"\n",
    "    def __init__(self, base_model: nn.Module, alpha: float = 0.1, gedig_config: Optional[Dict[str, Any]] = None):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.alpha = alpha\n",
    "        self.gedig = DifferentiableGeDIG(**(gedig_config or {}))\n",
    "        self._last_gedig_metrics: Optional[Dict[str, float]] = None\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: Optional[torch.Tensor] = None, labels: Optional[torch.Tensor] = None, **kwargs) -> SequenceClassifierOutput:\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels, output_attentions=True, **kwargs)\n",
    "        if labels is not None and self.alpha > 0:\n",
    "            f_values = [self.gedig.compute_F(layer_attn, attention_mask)[\"F_mean\"] for layer_attn in outputs.attentions]\n",
    "            f_mean = torch.stack(f_values).mean()\n",
    "            total_loss = outputs.loss + self.alpha * f_mean\n",
    "            self._last_gedig_metrics = {\"f_mean\": f_mean.item(), \"ce_loss\": outputs.loss.item(), \"total_loss\": total_loss.item()}\n",
    "            return SequenceClassifierOutput(loss=total_loss, logits=outputs.logits, hidden_states=None, attentions=None)\n",
    "        return SequenceClassifierOutput(loss=outputs.loss, logits=outputs.logits, hidden_states=None, attentions=None)\n",
    "\n",
    "\n",
    "class FRegularizedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        if hasattr(model, \"_last_gedig_metrics\") and model._last_gedig_metrics:\n",
    "            self.log(model._last_gedig_metrics)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "def compute_final_gedig_metrics(model, eval_dataset, tokenizer, data_collator):\n",
    "    from torch.utils.data import DataLoader\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    dataloader = DataLoader(eval_dataset, batch_size=32, collate_fn=data_collator)\n",
    "    gedig = DifferentiableGeDIG()\n",
    "    all_f, all_epc, all_h, all_sp = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n",
    "            base = model.base_model if hasattr(model, \"base_model\") else model\n",
    "            outputs = base(input_ids=batch[\"input_ids\"], attention_mask=batch.get(\"attention_mask\"), output_attentions=True)\n",
    "            for layer_attn in outputs.attentions:\n",
    "                metrics = gedig.compute_F(layer_attn, batch.get(\"attention_mask\"))\n",
    "                all_f.append(metrics[\"F\"].mean().item())\n",
    "                all_epc.append(metrics[\"delta_epc\"].mean().item())\n",
    "                all_h.append(metrics[\"delta_h\"].mean().item())\n",
    "                all_sp.append(metrics[\"delta_sp\"].mean().item())\n",
    "    return {\"f_mean\": np.mean(all_f), \"f_std\": np.std(all_f), \"delta_epc_mean\": np.mean(all_epc), \"delta_h_mean\": np.mean(all_h), \"delta_sp_mean\": np.mean(all_sp)}\n",
    "\n",
    "\n",
    "def run_experiment(alpha, model_name=\"distilbert-base-uncased\", train_samples=1000, eval_samples=500, epochs=3, batch_size=16, learning_rate=2e-5, seed=42, output_dir=None):\n",
    "    set_seed(seed)\n",
    "    if output_dir is None:\n",
    "        output_dir = Path(f\"results/f_reg/alpha_{alpha}_seed_{seed}\")\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"\\\\n{\\\"=\"*60}\\\\nRunning: alpha={alpha}, seed={seed}\\\\n{\\\"=\"*60}\")\n",
    "    \n",
    "    ds_train = load_dataset(\"glue\", \"sst2\", split=f\"train[:{train_samples}]\")\n",
    "    ds_eval = load_dataset(\"glue\", \"sst2\", split=f\"validation[:{eval_samples}]\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenize_fn = lambda ex: tokenizer(ex[\"sentence\"], truncation=True, max_length=128)\n",
    "    train_ds = ds_train.map(tokenize_fn, batched=True)\n",
    "    eval_ds = ds_eval.map(tokenize_fn, batched=True)\n",
    "    cols = [c for c in train_ds.column_names if c not in (\"input_ids\", \"attention_mask\", \"label\")]\n",
    "    train_ds = train_ds.remove_columns(cols).with_format(\"torch\")\n",
    "    eval_ds = eval_ds.remove_columns(cols).with_format(\"torch\")\n",
    "    \n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "    model = FRegularizedModel(base_model, alpha=alpha) if alpha > 0 else base_model\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=str(output_dir), eval_strategy=\"steps\", eval_steps=50, logging_steps=10,\n",
    "        save_strategy=\"epoch\", per_device_train_batch_size=batch_size, per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epochs, learning_rate=learning_rate, weight_decay=0.01, report_to=[], seed=seed,\n",
    "    )\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    trainer = FRegularizedTrainer(\n",
    "        model=model, args=training_args, train_dataset=train_ds, eval_dataset=eval_ds,\n",
    "        tokenizer=tokenizer, data_collator=data_collator,\n",
    "        compute_metrics=lambda p: {\"accuracy\": (np.argmax(p.predictions, axis=1) == p.label_ids).mean()},\n",
    "    )\n",
    "    train_result = trainer.train()\n",
    "    eval_result = trainer.evaluate()\n",
    "    final_f = compute_final_gedig_metrics(model, eval_ds, tokenizer, data_collator)\n",
    "    \n",
    "    result = {\"alpha\": alpha, \"seed\": seed, \"final_accuracy\": eval_result.get(\"eval_accuracy\"),\n",
    "              \"final_loss\": eval_result.get(\"eval_loss\"), \"train_runtime\": train_result.metrics.get(\"train_runtime\"), \"final_gedig\": final_f}\n",
    "    (output_dir / \"result.json\").write_text(json.dumps(result, indent=2))\n",
    "    print(f\"Result: acc={result[\\\"final_accuracy\\\"]:.4f}, F={final_f.get(\\\"f_mean\\\", \\\"N/A\\\")}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def run_alpha_sweep(alphas=[0.0, 0.001, 0.01, 0.1, 1.0], seeds=[42, 123, 456], **kwargs):\n",
    "    results = []\n",
    "    for alpha in alphas:\n",
    "        for seed in seeds:\n",
    "            results.append(run_experiment(alpha=alpha, seed=seed, **kwargs))\n",
    "    return results\n",
    "'''\n",
    "\n",
    "# Write to file\n",
    "with open('train_f_reg.py', 'w') as f:\n",
    "    f.write(TRAIN_SCRIPT)\n",
    "print('Script written to train_f_reg.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and run\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "exec(open('train_f_reg.py').read())\n",
    "\n",
    "# Configuration\n",
    "ALPHAS = [0.0, 0.001, 0.01, 0.1, 1.0]\n",
    "SEEDS = [42, 123, 456]\n",
    "TRAIN_SAMPLES = 2000  # Increase for better results\n",
    "EVAL_SAMPLES = 500\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "print(f\"Running {len(ALPHAS)} alphas x {len(SEEDS)} seeds = {len(ALPHAS)*len(SEEDS)} experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full sweep\n",
    "results = run_alpha_sweep(\n",
    "    alphas=ALPHAS,\n",
    "    seeds=SEEDS,\n",
    "    train_samples=TRAIN_SAMPLES,\n",
    "    eval_samples=EVAL_SAMPLES,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "# Save all results\n",
    "Path('results').mkdir(exist_ok=True)\n",
    "with open('results/all_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"\\nSaved {len(results)} results to results/all_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Summary by alpha\n",
    "summary = df.groupby('alpha').agg({\n",
    "    'final_accuracy': ['mean', 'std'],\n",
    "    'final_loss': ['mean', 'std'],\n",
    "}).round(4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(summary)\n",
    "\n",
    "# Best alpha\n",
    "best_idx = df.groupby('alpha')['final_accuracy'].mean().idxmax()\n",
    "baseline_acc = df[df['alpha']==0]['final_accuracy'].mean()\n",
    "best_acc = df[df['alpha']==best_idx]['final_accuracy'].mean()\n",
    "\n",
    "print(f\"\\nBaseline (α=0): {baseline_acc:.4f}\")\n",
    "print(f\"Best (α={best_idx}): {best_acc:.4f}\")\n",
    "print(f\"Improvement: {best_acc - baseline_acc:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Alpha vs Accuracy\n",
    "grouped = df.groupby('alpha')['final_accuracy'].agg(['mean', 'std']).reset_index()\n",
    "ax1 = axes[0]\n",
    "ax1.errorbar(range(len(grouped)), grouped['mean'], yerr=grouped['std'], \n",
    "             marker='o', markersize=10, linewidth=2, capsize=5)\n",
    "ax1.set_xticks(range(len(grouped)))\n",
    "ax1.set_xticklabels([f\"{a}\" for a in grouped['alpha']])\n",
    "ax1.set_xlabel('Alpha (F-regularization weight)')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Alpha vs Accuracy')\n",
    "ax1.axhline(y=baseline_acc, color='gray', linestyle='--', alpha=0.7, label='Baseline')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Alpha vs Final F\n",
    "f_data = []\n",
    "for r in results:\n",
    "    if r.get('final_gedig'):\n",
    "        f_data.append({'alpha': r['alpha'], 'f_mean': r['final_gedig']['f_mean']})\n",
    "f_df = pd.DataFrame(f_data)\n",
    "f_grouped = f_df.groupby('alpha')['f_mean'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "ax2 = axes[1]\n",
    "ax2.errorbar(range(len(f_grouped)), f_grouped['mean'], yerr=f_grouped['std'],\n",
    "             marker='s', markersize=10, linewidth=2, capsize=5, color='orange')\n",
    "ax2.set_xticks(range(len(f_grouped)))\n",
    "ax2.set_xticklabels([f\"{a}\" for a in f_grouped['alpha']])\n",
    "ax2.set_xlabel('Alpha (F-regularization weight)')\n",
    "ax2.set_ylabel('Final F (geDIG)')\n",
    "ax2.set_title('Alpha vs Final F')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/fig_f_reg_summary.png', dpi=150)\n",
    "plt.show()\n",
    "print(\"Saved: results/fig_f_reg_summary.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download results\n",
    "from google.colab import files\n",
    "\n",
    "# Zip results\n",
    "!zip -r f_reg_results.zip results/\n",
    "files.download('f_reg_results.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "**Success criteria**:\n",
    "1. α > 0 outperforms baseline (α=0) → F-regularization helps\n",
    "2. Optimal α exists (not monotonic) → there's a sweet spot\n",
    "3. Final F is lower for regularized models → F is being minimized\n",
    "\n",
    "**If successful**: geDIG F is not just correlated with good attention, but causally contributes to it."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
