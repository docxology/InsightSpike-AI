{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f79aded9",
      "metadata": {},
      "source": [
        "# geDIG Attention Update (Modern LLMs)\n",
        "\n",
        "Goal: sample attention maps from a newer model (e.g., Llama 3 / Phi-3) and compute geDIG F to confirm whether the sign and delta vs. random are preserved.\n",
        "\n",
        "Notes:\n",
        "- Llama 3 requires a Hugging Face token and license acceptance.\n",
        "- If you do not have access, use an open model such as `microsoft/Phi-3-mini-4k-instruct`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07196659",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb77d96a",
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/miyauchikazuyoshi/InsightSpike-AI.git\n",
        "%cd InsightSpike-AI\n",
        "!pip -q install -U pip\n",
        "!pip -q install transformers datasets accelerate sentencepiece networkx scipy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94c57753",
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# login()  # Uncomment and paste your HF token for gated models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67e7a4ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_ID = \"meta-llama/Meta-Llama-3-8B\"  # requires HF token + license\n",
        "# MODEL_ID = \"microsoft/Phi-3-mini-4k-instruct\"  # open fallback\n",
        "DTYPE = \"bfloat16\"  # use \"float16\" for T4, \"float32\" for CPU\n",
        "OUT = \"results/transformer_gedig/score_llm_update.json\"\n",
        "\n",
        "!python experiments/transformer_gedig/extract_and_score.py \\\n",
        "  --model \"$MODEL_ID\" \\\n",
        "  --text-count 16 \\\n",
        "  --layer-cap 4 \\\n",
        "  --attn-max-len 256 \\\n",
        "  --percentile 0.90 \\\n",
        "  --out \"$OUT\" \\\n",
        "  --device auto \\\n",
        "  --dtype \"$DTYPE\" \\\n",
        "  --device-map auto \\\n",
        "  --trust-remote-code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70fbe854",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "with open(OUT, \"r\", encoding=\"utf-8\") as fh:\n",
        "    data = json.load(fh)\n",
        "\n",
        "f_real = np.mean([d[\"F\"] for d in data])\n",
        "f_rand = np.mean([d[\"baseline_F_random\"] for d in data])\n",
        "print(\"F_real mean:\", f_real)\n",
        "print(\"F_random mean:\", f_rand)\n",
        "print(\"Delta (real - random):\", f_real - f_rand)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bfe06ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "out_path = Path(OUT)\n",
        "dest_dir = Path(\"/content/drive/MyDrive/insightspike/gedig_attention\")\n",
        "dest_dir.mkdir(parents=True, exist_ok=True)\n",
        "shutil.copy2(out_path, dest_dir / out_path.name)\n",
        "print(\"Saved to:\", dest_dir / out_path.name)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "gedig_attention_update.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}