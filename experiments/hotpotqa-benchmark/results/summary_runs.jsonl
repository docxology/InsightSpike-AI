{"method": "bm25", "data": "data/hotpotqa_sample_100.jsonl", "count": 0, "timestamp": "20260113_131039", "em": 0.0, "f1": 0.0, "precision": 0.0, "recall": 0.0, "sf_em": 0.0, "sf_f1": 0.0, "sf_precision": 0.0, "sf_recall": 0.0, "latency_p50_ms": 0.0, "latency_p95_ms": 0.0}
{"method": "bm25", "data": "data/hotpotqa_sample_100.jsonl", "count": 10, "timestamp": "20260113_131705", "em": 0.5, "f1": 0.5582, "precision": 0.535, "recall": 0.7, "sf_em": 0.0, "sf_f1": 0.2365, "sf_precision": 0.18, "sf_recall": 0.3583, "latency_p50_ms": 1455.32, "latency_p95_ms": 42108.05}
{"method": "bm25", "data": "data/hotpotqa_sample_500.jsonl", "count": 500, "timestamp": "20260113_132836", "em": 0.296, "f1": 0.4509, "precision": 0.4504, "recall": 0.5524, "sf_em": 0.0, "sf_f1": 0.2543, "sf_precision": 0.1896, "sf_recall": 0.4036, "latency_p50_ms": 756.6, "latency_p95_ms": 1510.97}
{"method": "bm25", "data": "data/hotpotqa_sample_100.jsonl", "count": 100, "timestamp": "20260113_153149", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/baselines.yaml", "parameters": {"name": "BM25 + GPT-4o-mini", "retrieval": {"method": "bm25", "top_k": 5}, "llm": {"model": "gpt-4o-mini", "temperature": 0.0, "max_tokens": 256}}, "em": 0.38, "f1": 0.5462, "precision": 0.5772, "recall": 0.6004, "sf_em": 0.0, "sf_f1": 0.3675, "sf_precision": 0.276, "sf_recall": 0.5723, "latency_p50_ms": 732.62, "latency_p95_ms": 1536.84}
{"method": "bm25", "data": "data/hotpotqa_sample_500.jsonl", "count": 500, "timestamp": "20260113_155504", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/baselines.yaml", "parameters": {"name": "BM25 + GPT-4o-mini", "retrieval": {"method": "bm25", "top_k": 5}, "llm": {"model": "gpt-4o-mini", "temperature": 0.0, "max_tokens": 256}}, "em": 0.364, "f1": 0.525, "precision": 0.5287, "recall": 0.6173, "sf_em": 0.0, "sf_f1": 0.356, "sf_precision": 0.266, "sf_recall": 0.5631, "latency_p50_ms": 802.46, "latency_p95_ms": 1559.1}
{"method": "bm25", "data": "data/hotpotqa_distractor_dev.jsonl", "count": 7371, "timestamp": "20260115_201605", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/baselines.yaml", "parameters": {"name": "BM25 + GPT-4o-mini", "retrieval": {"method": "bm25", "top_k": 5}, "llm": {"model": "gpt-4o-mini", "temperature": 0.0, "max_tokens": 256}}, "em": 0.366, "f1": 0.5227, "precision": 0.5192, "recall": 0.6102, "sf_em": 0.0001, "sf_f1": 0.3497, "sf_precision": 0.3024, "sf_recall": 0.4582, "latency_p50_ms": 819.76, "latency_p95_ms": 18532.36, "incomplete": true, "expected_count": 7405}
{"method": "bm25", "data": "experiments/hotpotqa-benchmark/data/hotpotqa_distractor_dev.jsonl", "count": 7405, "timestamp": "20260115_210922", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/baselines.yaml", "parameters": {"name": "BM25 + GPT-4o-mini", "retrieval": {"method": "bm25", "top_k": 5}, "llm": {"model": "gpt-4o-mini", "temperature": 0.0, "max_tokens": 256}}, "em": 0.3662, "f1": 0.5229, "precision": 0.5192, "recall": 0.6108, "sf_em": 0.0001, "sf_f1": 0.3497, "sf_precision": 0.3022, "sf_recall": 0.4588, "latency_p50_ms": 819.98, "latency_p95_ms": 18532.92}
{"method": "closed_book", "data": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/data/hotpotqa_sample_100.jsonl", "count": 100, "timestamp": "20260113_211550", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/baselines.yaml", "parameters": {"name": "Closed-book GPT-4o-mini", "llm": {"model": "gpt-4o-mini", "temperature": 0.0, "max_tokens": 256}}, "em": 0.29, "f1": 0.4139, "precision": 0.4302, "recall": 0.4718, "sf_em": 0.0, "sf_f1": 0.0, "sf_precision": 0.0, "sf_recall": 0.0, "latency_p50_ms": 716.62, "latency_p95_ms": 1223.77}
{"method": "closed_book", "data": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/data/hotpotqa_sample_500.jsonl", "count": 500, "timestamp": "20260113_211718", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/baselines.yaml", "parameters": {"name": "Closed-book GPT-4o-mini", "llm": {"model": "gpt-4o-mini", "temperature": 0.0, "max_tokens": 256}}, "em": 0.222, "f1": 0.3526, "precision": 0.3433, "recall": 0.4411, "sf_em": 0.0, "sf_f1": 0.0, "sf_precision": 0.0, "sf_recall": 0.0, "latency_p50_ms": 656.11, "latency_p95_ms": 1214.12}
{"method": "closed_book", "data": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/data/hotpotqa_distractor_dev.jsonl", "count": 4911, "timestamp": "20260113_220125", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/baselines.yaml", "parameters": {"name": "Closed-book GPT-4o-mini", "llm": {"model": "gpt-4o-mini", "temperature": 0.0, "max_tokens": 256}}, "incomplete": true, "expected_count": 7405, "processed_count": 4911, "em": 0.2258, "f1": 0.3544, "precision": 0.3497, "recall": 0.4318, "sf_em": 0.0, "sf_f1": 0.0, "sf_precision": 0.0, "sf_recall": 0.0, "latency_p50_ms": 739.68, "latency_p95_ms": 10065.97}
{"method": "closed_book", "data": "experiments/hotpotqa-benchmark/data/hotpotqa_distractor_dev.jsonl", "count": 7405, "timestamp": "20260116_190253", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/baselines.yaml", "parameters": {"name": "Closed-book GPT-4o-mini", "llm": {"model": "gpt-4o-mini", "temperature": 0.0, "max_tokens": 256}}, "em": 0.2204, "f1": 0.3511, "precision": 0.3465, "recall": 0.43, "sf_em": 0.0, "sf_f1": 0.0, "sf_precision": 0.0, "sf_recall": 0.0, "latency_p50_ms": 769.83, "latency_p95_ms": 10034.88}
{"method": "contriever", "data": "data/hotpotqa_sample_100.jsonl", "count": 100, "timestamp": "20260113_154022", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/baselines.yaml", "parameters": {"name": "Contriever + GPT-4o-mini", "retrieval": {"method": "contriever", "model": "facebook/contriever", "top_k": 5, "device": "auto", "max_length": 256, "batch_size": 16}, "llm": {"model": "gpt-4o-mini", "temperature": 0.0, "max_tokens": 256}}, "em": 0.27, "f1": 0.4081, "precision": 0.4161, "recall": 0.5038, "sf_em": 0.0, "sf_f1": 0.1575, "sf_precision": 0.118, "sf_recall": 0.247, "latency_p50_ms": 7436.4, "latency_p95_ms": 11647.25}
{"method": "contriever", "data": "data/hotpotqa_sample_500.jsonl", "count": 499, "timestamp": "20260113_161057", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/baselines.yaml", "parameters": {"name": "Contriever + GPT-4o-mini", "retrieval": {"method": "contriever", "model": "facebook/contriever", "top_k": 5, "device": "auto", "max_length": 256, "batch_size": 16}, "llm": {"model": "gpt-4o-mini", "temperature": 0.0, "max_tokens": 256}}, "em": 0.2525, "f1": 0.4026, "precision": 0.4033, "recall": 0.5018, "sf_em": 0.0, "sf_f1": 0.1634, "sf_precision": 0.1218, "sf_recall": 0.2594, "latency_p50_ms": 6866.1, "latency_p95_ms": 11271.89}
{"method": "contriever", "data": "experiments/hotpotqa-benchmark/data/hotpotqa_distractor_dev.jsonl", "count": 7405, "timestamp": "20260117_024211", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/baselines.yaml", "parameters": {"name": "Contriever + GPT-4o-mini", "retrieval": {"method": "contriever", "model": "facebook/contriever", "top_k": 5, "device": "auto", "max_length": 256, "batch_size": 16}, "llm": {"model": "gpt-4o-mini", "temperature": 0.0, "max_tokens": 256}}, "em": 0.2747, "f1": 0.4216, "precision": 0.4163, "recall": 0.5126, "sf_em": 0.0001, "sf_f1": 0.1656, "sf_precision": 0.1229, "sf_recall": 0.2642, "latency_p50_ms": 2787.84, "latency_p95_ms": 19642.07}
{"method": "gedig", "data": "data/hotpotqa_sample_100.jsonl", "count": 5, "timestamp": "20260113_135059", "parameters": {"lambda_weight": 1.0, "theta_ag": 0.4, "theta_dg": 0.0, "top_k": 5}, "em": 0.2, "f1": 0.3, "precision": 0.3, "recall": 0.3, "sf_em": 0.0, "sf_f1": 0.1571, "sf_precision": 0.12, "sf_recall": 0.2333, "latency_p50_ms": 791.74, "latency_p95_ms": 2300.95, "ag_fire_rate": 0.0, "dg_fire_rate": 1.0, "avg_gedig_score": 0.0, "avg_graph_edges": 5.6}
{"method": "gedig", "data": "data/hotpotqa_sample_500.jsonl", "count": 500, "timestamp": "20260113_135255", "parameters": {"lambda_weight": 1.0, "theta_ag": 0.4, "theta_dg": 0.0, "top_k": 5}, "em": 0.292, "f1": 0.4434, "precision": 0.4407, "recall": 0.5447, "sf_em": 0.0, "sf_f1": 0.2543, "sf_precision": 0.1896, "sf_recall": 0.4036, "latency_p50_ms": 788.89, "latency_p95_ms": 1316.36, "ag_fire_rate": 0.0, "dg_fire_rate": 1.0, "avg_gedig_score": 0.0, "avg_graph_edges": 5.286}
{"method": "gedig", "data": "data/hotpotqa_sample_100.jsonl", "count": 100, "timestamp": "20260113_153327", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 0.4, "theta_dg": 0.0, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256}, "em": 0.38, "f1": 0.5509, "precision": 0.5852, "recall": 0.5971, "sf_em": 0.0, "sf_f1": 0.3675, "sf_precision": 0.276, "sf_recall": 0.5723, "latency_p50_ms": 758.46, "latency_p95_ms": 1252.1, "ag_fire_rate": 0.0, "dg_fire_rate": 1.0, "avg_gedig_score": 0.0, "avg_graph_edges": 5.82}
{"method": "gedig", "data": "data/hotpotqa_sample_500.jsonl", "count": 500, "timestamp": "20260113_160235", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 0.4, "theta_dg": 0.0, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256}, "em": 0.37, "f1": 0.53, "precision": 0.5346, "recall": 0.6203, "sf_em": 0.0, "sf_f1": 0.356, "sf_precision": 0.266, "sf_recall": 0.5631, "latency_p50_ms": 861.13, "latency_p95_ms": 1823.49, "ag_fire_rate": 0.0, "dg_fire_rate": 1.0, "avg_gedig_score": 0.0, "avg_graph_edges": 5.784}
{"method": "gedig", "data": "data/hotpotqa_sample_100.jsonl", "count": 100, "timestamp": "20260113_180650", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 0.0, "theta_dg": 0.0, "top_k": 5, "max_expansions": 2, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2}, "tuning": {"enabled": true, "sample_size": 50, "ag_percentile": 70, "dg_percentile": 30, "theta_ag": 0.0, "theta_dg": 0.0}, "em": 0.38, "f1": 0.5397, "precision": 0.5728, "recall": 0.5904, "sf_em": 0.0, "sf_f1": 0.3675, "sf_precision": 0.276, "sf_recall": 0.5723, "latency_p50_ms": 657.56, "latency_p95_ms": 1133.79, "ag_fire_rate": 0.0, "dg_fire_rate": 1.0, "avg_gedig_score": 0.0, "avg_graph_edges": 5.82}
{"method": "gedig", "data": "data/hotpotqa_sample_500.jsonl", "count": 500, "timestamp": "20260113_180815", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 0.0, "theta_dg": 0.0, "top_k": 5, "max_expansions": 2, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 70, "dg_percentile": 30, "theta_ag": 0.0, "theta_dg": 0.0}, "em": 0.356, "f1": 0.5204, "precision": 0.5259, "recall": 0.6135, "sf_em": 0.0, "sf_f1": 0.356, "sf_precision": 0.266, "sf_recall": 0.5631, "latency_p50_ms": 660.28, "latency_p95_ms": 1228.51, "ag_fire_rate": 0.0, "dg_fire_rate": 1.0, "avg_gedig_score": 0.0, "avg_graph_edges": 5.784}
{"method": "gedig", "data": "data/hotpotqa_sample_100.jsonl", "count": 100, "timestamp": "20260113_181651", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 1.6666666666666667, "theta_dg": 1.5714285714285714, "top_k": 5, "max_expansions": 2, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2}, "tuning": {"enabled": true, "sample_size": 50, "ag_percentile": 70, "dg_percentile": 30, "theta_ag": 1.6666666666666667, "theta_dg": 1.5714285714285714}, "em": 0.38, "f1": 0.5447, "precision": 0.5762, "recall": 0.6004, "sf_em": 0.0, "sf_f1": 0.3675, "sf_precision": 0.276, "sf_recall": 0.5723, "latency_p50_ms": 671.16, "latency_p95_ms": 1745.96, "ag_fire_rate": 0.0, "dg_fire_rate": 0.62, "avg_gedig_score": 1.5943968253968268, "avg_graph_edges": 5.82}
{"method": "gedig", "data": "data/hotpotqa_sample_500.jsonl", "count": 500, "timestamp": "20260113_181820", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 1.6666666666666667, "theta_dg": 1.5714285714285714, "top_k": 5, "max_expansions": 2, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 70, "dg_percentile": 30, "theta_ag": 1.6666666666666667, "theta_dg": 1.5714285714285714}, "em": 0.366, "f1": 0.5262, "precision": 0.5317, "recall": 0.6149, "sf_em": 0.0, "sf_f1": 0.356, "sf_precision": 0.266, "sf_recall": 0.5631, "latency_p50_ms": 711.94, "latency_p95_ms": 1300.49, "ag_fire_rate": 0.0, "dg_fire_rate": 0.548, "avg_gedig_score": 1.5995650793650713, "avg_graph_edges": 5.784}
{"method": "gedig", "data": "data/hotpotqa_sample_100.jsonl", "count": 100, "timestamp": "20260113_182556", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 1.5714275714285715, "theta_dg": 1.5714285714285714, "top_k": 5, "max_expansions": 2, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2}, "tuning": {"enabled": true, "sample_size": 50, "ag_percentile": 50, "dg_percentile": 30, "theta_ag": 1.5714275714285715, "theta_dg": 1.5714285714285714}, "em": 0.39, "f1": 0.5567, "precision": 0.5825, "recall": 0.6121, "sf_em": 0.0, "sf_f1": 0.3326, "sf_precision": 0.238, "sf_recall": 0.6247, "latency_p50_ms": 696.43, "latency_p95_ms": 1409.04, "ag_fire_rate": 0.52, "dg_fire_rate": 1.0, "avg_gedig_score": 1.4071274193642618, "avg_graph_edges": 8.9}
{"method": "gedig", "data": "data/hotpotqa_sample_500.jsonl", "count": 500, "timestamp": "20260113_182728", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 1.6190466190476192, "theta_dg": 1.5714285714285714, "top_k": 5, "max_expansions": 2, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 50, "dg_percentile": 30, "theta_ag": 1.6190466190476192, "theta_dg": 1.5714285714285714}, "em": 0.352, "f1": 0.5148, "precision": 0.5148, "recall": 0.6186, "sf_em": 0.0, "sf_f1": 0.3082, "sf_precision": 0.2184, "sf_recall": 0.6062, "latency_p50_ms": 675.16, "latency_p95_ms": 1369.61, "ag_fire_rate": 0.01, "dg_fire_rate": 1.0, "avg_gedig_score": 1.3753137734585077, "avg_graph_edges": 9.562}
{"method": "gedig", "data": "data/hotpotqa_sample_100.jsonl", "count": 100, "timestamp": "20260113_190025", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 1.5714275714285715, "theta_dg": 1.4944444444444445, "top_k": 5, "max_expansions": 2, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2}, "tuning": {"enabled": true, "sample_size": 50, "ag_percentile": 30.0, "dg_percentile": 10.0, "theta_ag": 1.5714275714285715, "theta_dg": 1.4944444444444445}, "em": 0.42, "f1": 0.5899, "precision": 0.6135, "recall": 0.6471, "sf_em": 0.0, "sf_f1": 0.2849, "sf_precision": 0.185, "sf_recall": 0.6822, "latency_p50_ms": 717.98, "latency_p95_ms": 3589.64, "ag_fire_rate": 0.04, "dg_fire_rate": 0.91, "avg_gedig_score": 1.2054250620810218, "avg_graph_edges": 12.65}
{"method": "gedig", "data": "data/hotpotqa_sample_500.jsonl", "count": 500, "timestamp": "20260113_190208", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 1.5714275714285715, "theta_dg": 1.5, "top_k": 5, "max_expansions": 2, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 30.0, "dg_percentile": 10.0, "theta_ag": 1.5714275714285715, "theta_dg": 1.5}, "em": 0.37, "f1": 0.5379, "precision": 0.5416, "recall": 0.6369, "sf_em": 0.0, "sf_f1": 0.2723, "sf_precision": 0.1778, "sf_recall": 0.6611, "latency_p50_ms": 721.0, "latency_p95_ms": 1464.8, "ag_fire_rate": 0.04, "dg_fire_rate": 1.0, "avg_gedig_score": 1.196432799497831, "avg_graph_edges": 13.066}
{"method": "gedig", "data": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/data/hotpotqa_sample_100.jsonl", "count": 100, "timestamp": "20260113_191338", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 1.499999, "theta_dg": 1.4972222222222222, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 10.0, "dg_percentile": 5.0, "theta_ag": 1.499999, "theta_dg": 1.4972222222222222}, "em": 0.43, "f1": 0.5868, "precision": 0.6084, "recall": 0.6454, "sf_em": 0.0, "sf_f1": 0.2733, "sf_precision": 0.175, "sf_recall": 0.6788, "latency_p50_ms": 708.96, "latency_p95_ms": 1328.25, "ag_fire_rate": 0.04, "dg_fire_rate": 1.0, "avg_gedig_score": 1.1744043829127455, "avg_graph_edges": 13.44}
{"method": "gedig", "data": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/data/hotpotqa_sample_500.jsonl", "count": 500, "timestamp": "20260113_191515", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 1.499999, "theta_dg": 1.5, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 10.0, "dg_percentile": 5.0, "theta_ag": 1.499999, "theta_dg": 1.5}, "em": 0.368, "f1": 0.5385, "precision": 0.5408, "recall": 0.6462, "sf_em": 0.0, "sf_f1": 0.2723, "sf_precision": 0.1778, "sf_recall": 0.6611, "latency_p50_ms": 711.37, "latency_p95_ms": 1312.63, "ag_fire_rate": 0.114, "dg_fire_rate": 1.0, "avg_gedig_score": 1.196432799497831, "avg_graph_edges": 13.066}
{"method": "gedig", "data": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/data/hotpotqa_sample_100.jsonl", "count": 100, "timestamp": "20260113_194735", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 0.4, "theta_dg": 0.0, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2, "tfidf_dim": 64}, "tuning": {"enabled": false}, "em": 0.38, "f1": 0.5462, "precision": 0.5772, "recall": 0.6004, "sf_em": 0.0, "sf_f1": 0.3675, "sf_precision": 0.276, "sf_recall": 0.5723, "latency_p50_ms": 692.71, "latency_p95_ms": 1129.65, "ag_fire_rate": 0.0, "dg_fire_rate": 0.14, "final_ag_fire_rate": 0.0, "final_dg_fire_rate": 0.14, "avg_gedig_score": 0.13046275625362325, "avg_graph_edges": 5.82}
{"method": "gedig", "data": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/data/hotpotqa_sample_500.jsonl", "count": 500, "timestamp": "20260113_194906", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 0.4, "theta_dg": 0.0, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2, "tfidf_dim": 64}, "tuning": {"enabled": false}, "em": 0.366, "f1": 0.5288, "precision": 0.5322, "recall": 0.6195, "sf_em": 0.0, "sf_f1": 0.356, "sf_precision": 0.266, "sf_recall": 0.5631, "latency_p50_ms": 635.41, "latency_p95_ms": 1120.81, "ag_fire_rate": 0.0, "dg_fire_rate": 0.14, "final_ag_fire_rate": 0.0, "final_dg_fire_rate": 0.14, "avg_gedig_score": 0.14079602447448106, "avg_graph_edges": 5.784}
{"method": "gedig", "data": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/data/hotpotqa_sample_100.jsonl", "count": 100, "timestamp": "20260113_195613", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 0.08826300283872693, "theta_dg": 0.08529408217267345, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2, "tfidf_dim": 64}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 50, "dg_percentile": 30, "theta_ag": 0.08826300283872693, "theta_dg": 0.08529408217267345}, "em": 0.41, "f1": 0.5736, "precision": 0.5958, "recall": 0.6237, "sf_em": 0.0, "sf_f1": 0.327, "sf_precision": 0.23, "sf_recall": 0.6422, "latency_p50_ms": 716.5, "latency_p95_ms": 1319.73, "ag_fire_rate": 0.5, "dg_fire_rate": 0.3, "final_ag_fire_rate": 0.5, "final_dg_fire_rate": 0.3, "avg_gedig_score": 0.21112063431961903, "avg_graph_edges": 9.94}
{"method": "gedig", "data": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/data/hotpotqa_sample_500.jsonl", "count": 500, "timestamp": "20260113_200620", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 0.18841522925817614, "theta_dg": 0.08588810622506693, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2, "tfidf_dim": 64}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 50.0, "dg_percentile": 30.0, "theta_ag": 0.18841522925817614, "theta_dg": 0.08588810622506693}, "em": 0.354, "f1": 0.5168, "precision": 0.5189, "recall": 0.6141, "sf_em": 0.0, "sf_f1": 0.3082, "sf_precision": 0.2184, "sf_recall": 0.6062, "latency_p50_ms": 717.24, "latency_p95_ms": 1375.3, "ag_fire_rate": 0.452, "dg_fire_rate": 0.334, "final_ag_fire_rate": 0.448, "final_dg_fire_rate": 0.336, "avg_gedig_score": 0.19337948703564015, "avg_graph_edges": 9.562}
{"method": "gedig", "data": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/data/hotpotqa_sample_100.jsonl", "count": 100, "timestamp": "20260114_120549", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 0.8, "theta_ag": 0.3848959165566958, "theta_dg": 0.382520980023853, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2, "tfidf_dim": 64}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 50, "dg_percentile": 30, "theta_ag": 0.3848959165566958, "theta_dg": 0.382520980023853}, "em": 0.41, "f1": 0.5604, "precision": 0.5821, "recall": 0.6171, "sf_em": 0.0, "sf_f1": 0.327, "sf_precision": 0.23, "sf_recall": 0.6422, "latency_p50_ms": 723.13, "latency_p95_ms": 2112.38, "ag_fire_rate": 0.5, "dg_fire_rate": 0.3, "final_ag_fire_rate": 0.5, "final_dg_fire_rate": 0.31, "avg_gedig_score": 0.43904096124751746, "avg_graph_edges": 9.94}
{"method": "gedig", "data": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/data/hotpotqa_sample_100.jsonl", "count": 100, "timestamp": "20260114_120738", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 0.5, "theta_ag": 0.8298452871336491, "theta_dg": 0.8283613268006225, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2, "tfidf_dim": 64}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 50, "dg_percentile": 30, "theta_ag": 0.8298452871336491, "theta_dg": 0.8283613268006225}, "em": 0.41, "f1": 0.5682, "precision": 0.5923, "recall": 0.6137, "sf_em": 0.0, "sf_f1": 0.327, "sf_precision": 0.23, "sf_recall": 0.6422, "latency_p50_ms": 751.17, "latency_p95_ms": 2114.3, "ag_fire_rate": 0.5, "dg_fire_rate": 0.3, "final_ag_fire_rate": 0.11, "final_dg_fire_rate": 0.8, "avg_gedig_score": 0.7809214516393651, "avg_graph_edges": 9.94}
{"method": "gedig", "data": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/data/hotpotqa_sample_100.jsonl", "count": 100, "timestamp": "20260114_120931", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 0.41205498034489146, "theta_dg": 0.27727950600844914, "top_k": 7, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2, "tfidf_dim": 64}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 50, "dg_percentile": 30, "theta_ag": 0.41205498034489146, "theta_dg": 0.27727950600844914}, "em": 0.43, "f1": 0.5827, "precision": 0.6089, "recall": 0.6454, "sf_em": 0.0, "sf_f1": 0.2645, "sf_precision": 0.17, "sf_recall": 0.6922, "latency_p50_ms": 820.9, "latency_p95_ms": 3709.67, "ag_fire_rate": 0.5, "dg_fire_rate": 0.3, "final_ag_fire_rate": 0.46, "final_dg_fire_rate": 0.3, "avg_gedig_score": 0.3502215331097041, "avg_graph_edges": 15.12}
{"method": "gedig", "data": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/data/hotpotqa_sample_100.jsonl", "count": 100, "timestamp": "20260114_121134", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 0.08826300283872693, "theta_dg": 0.08529408217267345, "top_k": 5, "max_expansions": 2, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 3, "tfidf_dim": 64}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 50, "dg_percentile": 30, "theta_ag": 0.08826300283872693, "theta_dg": 0.08529408217267345}, "em": 0.43, "f1": 0.5905, "precision": 0.6076, "recall": 0.6479, "sf_em": 0.0, "sf_f1": 0.3034, "sf_precision": 0.2107, "sf_recall": 0.69, "latency_p50_ms": 809.55, "latency_p95_ms": 1468.97, "ag_fire_rate": 0.5, "dg_fire_rate": 0.3, "final_ag_fire_rate": 0.5, "final_dg_fire_rate": 0.33, "avg_gedig_score": 0.2138054539451108, "avg_graph_edges": 15.21}
{"method": "gedig", "data": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/data/hotpotqa_sample_100.jsonl", "count": 100, "timestamp": "20260114_121317", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 1.0, "theta_ag": 0.08897941910549059, "theta_dg": 0.08561371506910602, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2, "tfidf_dim": 128}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 50, "dg_percentile": 30, "theta_ag": 0.08897941910549059, "theta_dg": 0.08561371506910602}, "em": 0.41, "f1": 0.5617, "precision": 0.585, "recall": 0.6196, "sf_em": 0.0, "sf_f1": 0.3246, "sf_precision": 0.228, "sf_recall": 0.6372, "latency_p50_ms": 732.88, "latency_p95_ms": 1367.37, "ag_fire_rate": 0.5, "dg_fire_rate": 0.3, "final_ag_fire_rate": 0.5, "final_dg_fire_rate": 0.3, "avg_gedig_score": 0.21166173244477973, "avg_graph_edges": 9.92}
{"method": "gedig", "data": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/data/hotpotqa_sample_100.jsonl", "count": 100, "timestamp": "20260114_121454", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 0.8, "theta_ag": 0.6630938823636723, "theta_dg": 0.5420519977671051, "top_k": 7, "max_expansions": 2, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 3, "tfidf_dim": 128}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 50, "dg_percentile": 30, "theta_ag": 0.6630938823636723, "theta_dg": 0.5420519977671051}, "em": 0.41, "f1": 0.5718, "precision": 0.5854, "recall": 0.6496, "sf_em": 0.0, "sf_f1": 0.2602, "sf_precision": 0.1674, "sf_recall": 0.6822, "latency_p50_ms": 766.47, "latency_p95_ms": 1606.3, "ag_fire_rate": 0.5, "dg_fire_rate": 0.3, "final_ag_fire_rate": 0.0, "final_dg_fire_rate": 0.57, "avg_gedig_score": 0.5409336991585629, "avg_graph_edges": 15.94}
{"method": "gedig", "data": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/data/hotpotqa_sample_500.jsonl", "count": 500, "timestamp": "20260114_122219", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 0.8, "theta_ag": 0.47454150721606464, "theta_dg": 0.3829961992657679, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2, "tfidf_dim": 64}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 50, "dg_percentile": 30, "theta_ag": 0.47454150721606464, "theta_dg": 0.3829961992657679}, "em": 0.35, "f1": 0.5159, "precision": 0.5183, "recall": 0.6157, "sf_em": 0.0, "sf_f1": 0.3082, "sf_precision": 0.2184, "sf_recall": 0.6062, "latency_p50_ms": 696.7, "latency_p95_ms": 1229.19, "ag_fire_rate": 0.452, "dg_fire_rate": 0.334, "final_ag_fire_rate": 0.384, "final_dg_fire_rate": 0.34, "avg_gedig_score": 0.4297663443202141, "avg_graph_edges": 9.562}
{"method": "gedig", "data": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/data/hotpotqa_sample_500.jsonl", "count": 500, "timestamp": "20260114_122922", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 0.5, "theta_ag": 0.9037309241528976, "theta_dg": 0.8286583388268192, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2, "tfidf_dim": 64}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 50, "dg_percentile": 30, "theta_ag": 0.9037309241528976, "theta_dg": 0.8286583388268192}, "em": 0.35, "f1": 0.5135, "precision": 0.5147, "recall": 0.6159, "sf_em": 0.0, "sf_f1": 0.3082, "sf_precision": 0.2184, "sf_recall": 0.6062, "latency_p50_ms": 668.6, "latency_p95_ms": 1229.91, "ag_fire_rate": 0.452, "dg_fire_rate": 0.334, "final_ag_fire_rate": 0.068, "final_dg_fire_rate": 0.786, "avg_gedig_score": 0.7843466302470751, "avg_graph_edges": 9.562}
{"method": "gedig", "data": "data/hotpotqa_distractor_dev.jsonl", "count": 0, "timestamp": "20260114_125014", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 0.8, "theta_ag": 0.3848959165566958, "theta_dg": 0.382520980023853, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2, "tfidf_dim": 64}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 50, "dg_percentile": 30, "theta_ag": 0.3848959165566958, "theta_dg": 0.382520980023853}, "em": 0.0, "f1": 0.0, "precision": 0.0, "recall": 0.0, "sf_em": 0.0, "sf_f1": 0.0, "sf_precision": 0.0, "sf_recall": 0.0, "latency_p50_ms": 0.0, "latency_p95_ms": 0.0, "ag_fire_rate": 0.0, "dg_fire_rate": 0.0, "final_ag_fire_rate": 0.0, "final_dg_fire_rate": 0.0, "avg_gedig_score": 0.0, "avg_graph_edges": 0.0}
{"method": "gedig", "data": "data/hotpotqa_distractor_dev.jsonl", "count": 7242, "timestamp": "20260114_174808", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 0.8, "theta_ag": 0.3848959165566958, "theta_dg": 0.382520980023853, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2, "tfidf_dim": 64}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 50, "dg_percentile": 30, "theta_ag": 0.3848959165566958, "theta_dg": 0.382520980023853}, "em": 0.373, "f1": 0.5359, "precision": 0.5296, "recall": 0.6338, "sf_em": 0.0001, "sf_f1": 0.3039, "sf_precision": 0.2755, "sf_recall": 0.4013, "latency_p50_ms": 779.44, "latency_p95_ms": 18632.45, "ag_fire_rate": 0.5465341066003866, "dg_fire_rate": 0.26898646782656727, "final_ag_fire_rate": 0.5443247721623861, "final_dg_fire_rate": 0.29025131179232255, "avg_gedig_score": 0.44853364562319475, "avg_graph_edges": 10.355840927920465}
{"method": "gedig", "data": "data/hotpotqa_distractor_dev.jsonl", "count": 7402, "timestamp": "20260114_221732", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 0.8, "theta_ag": 0.3848959165566958, "theta_dg": 0.382520980023853, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2, "tfidf_dim": 64}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 50, "dg_percentile": 30, "theta_ag": 0.3848959165566958, "theta_dg": 0.382520980023853}, "em": 0.3731, "f1": 0.5356, "precision": 0.5291, "recall": 0.6335, "sf_em": 0.0001, "sf_f1": 0.3043, "sf_precision": 0.2743, "sf_recall": 0.4066, "latency_p50_ms": 783.13, "latency_p95_ms": 18628.74, "ag_fire_rate": 0.546068630099973, "dg_fire_rate": 0.269386652256147, "final_ag_fire_rate": 0.5439070521480681, "final_dg_fire_rate": 0.2905971359092137, "avg_gedig_score": 0.448370972085499, "avg_graph_edges": 10.350716022696568}
{"method": "gedig", "data": "data/hotpotqa_distractor_dev.jsonl", "count": 7405, "timestamp": "20260114_233600", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 0.8, "theta_ag": 0.3848959165566958, "theta_dg": 0.382520980023853, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2, "tfidf_dim": 64}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 50, "dg_percentile": 30, "theta_ag": 0.3848959165566958, "theta_dg": 0.382520980023853}, "em": 0.3733, "f1": 0.5358, "precision": 0.5293, "recall": 0.6336, "sf_em": 0.0001, "sf_f1": 0.3043, "sf_precision": 0.2743, "sf_recall": 0.4067, "latency_p50_ms": 783.2, "latency_p95_ms": 18628.74, "ag_fire_rate": 0.5459824442943957, "dg_fire_rate": 0.26941255908170153, "final_ag_fire_rate": 0.5438217420661715, "final_dg_fire_rate": 0.29061444969615124, "avg_gedig_score": 0.44835077993012423, "avg_graph_edges": 10.349898717083052}
{"method": "gedig", "data": "data/hotpotqa_distractor_dev.jsonl", "count": 7403, "timestamp": "20260115_114256", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 0.5, "theta_ag": 0.8298452871336491, "theta_dg": 0.8283613268006225, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2, "tfidf_dim": 64}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 50, "dg_percentile": 30, "theta_ag": 0.8298452871336491, "theta_dg": 0.8283613268006225}, "em": 0.3747, "f1": 0.5374, "precision": 0.5316, "recall": 0.635, "sf_em": 0.0001, "sf_f1": 0.3042, "sf_precision": 0.2121, "sf_recall": 0.6213, "latency_p50_ms": 872.39, "latency_p95_ms": 18545.52, "ag_fire_rate": 0.5459948669458328, "dg_fire_rate": 0.269350263406727, "final_ag_fire_rate": 0.12940699716331217, "final_dg_fire_rate": 0.8153451303525597, "avg_gedig_score": 0.7802527901526632, "avg_graph_edges": 10.349588004862893}
{"method": "gedig", "data": "data/hotpotqa_distractor_dev.jsonl", "count": 7405, "timestamp": "20260115_115335", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/gedig_hotpotqa.yaml", "parameters": {"lambda_weight": 0.5, "theta_ag": 0.8298452871336491, "theta_dg": 0.8283613268006225, "top_k": 5, "max_expansions": 1, "max_hops": 3, "gamma": 1.0, "llm_model": "gpt-4o-mini", "llm_temperature": 0.0, "llm_max_tokens": 256, "expansion_seeds": 2, "tfidf_dim": 64}, "tuning": {"enabled": true, "sample_size": 100, "ag_percentile": 50, "dg_percentile": 30, "theta_ag": 0.8298452871336491, "theta_dg": 0.8283613268006225}, "em": 0.3749, "f1": 0.5375, "precision": 0.5318, "recall": 0.6351, "sf_em": 0.0001, "sf_f1": 0.3043, "sf_precision": 0.2122, "sf_recall": 0.6214, "latency_p50_ms": 872.52, "latency_p95_ms": 18545.52, "ag_fire_rate": 0.5459824442943957, "dg_fire_rate": 0.26941255908170153, "final_ag_fire_rate": 0.12937204591492235, "final_dg_fire_rate": 0.8153950033760973, "avg_gedig_score": 0.7802155589854142, "avg_graph_edges": 10.349898717083052}
{"method": "static_graphrag", "data": "data/hotpotqa_sample_100.jsonl", "count": 100, "timestamp": "20260113_155336", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/baselines.yaml", "parameters": {"name": "Static GraphRAG", "retrieval": {"top_k": 5, "window": 1}, "llm": {"model": "gpt-4o-mini", "temperature": 0.0, "max_tokens": 256}}, "em": 0.44, "f1": 0.6091, "precision": 0.6294, "recall": 0.6771, "sf_em": 0.0, "sf_f1": 0.3675, "sf_precision": 0.276, "sf_recall": 0.5723, "latency_p50_ms": 770.64, "latency_p95_ms": 1391.11}
{"method": "static_graphrag", "data": "data/hotpotqa_sample_500.jsonl", "count": 500, "timestamp": "20260113_171119", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/baselines.yaml", "parameters": {"name": "Static GraphRAG", "retrieval": {"top_k": 5, "window": 1}, "llm": {"model": "gpt-4o-mini", "temperature": 0.0, "max_tokens": 256}}, "em": 0.396, "f1": 0.5667, "precision": 0.5659, "recall": 0.6867, "sf_em": 0.0, "sf_f1": 0.356, "sf_precision": 0.266, "sf_recall": 0.5631, "latency_p50_ms": 705.63, "latency_p95_ms": 1191.19}
{"method": "static_graphrag", "data": "data/hotpotqa_distractor_dev.jsonl", "count": 7403, "timestamp": "20260116_051947", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/baselines.yaml", "parameters": {"name": "Static GraphRAG", "retrieval": {"top_k": 5, "window": 1}, "llm": {"model": "gpt-4o-mini", "temperature": 0.0, "max_tokens": 256}}, "em": 0.3893, "f1": 0.5594, "precision": 0.5516, "recall": 0.6689, "sf_em": 0.0001, "sf_f1": 0.3497, "sf_precision": 0.261, "sf_recall": 0.5533, "latency_p50_ms": 913.71, "latency_p95_ms": 18503.34, "incomplete": true, "expected_count": 7405}
{"method": "static_graphrag", "data": "data/hotpotqa_distractor_dev.jsonl", "count": 7405, "timestamp": "20260116_075326", "config": "/Users/miyauchikazuyoshi/Documents/GitHub/InsightSpike-AI/experiments/hotpotqa-benchmark/configs/baselines.yaml", "parameters": {"name": "Static GraphRAG", "retrieval": {"top_k": 5, "window": 1}, "llm": {"model": "gpt-4o-mini", "temperature": 0.0, "max_tokens": 256}}, "em": 0.3893, "f1": 0.5594, "precision": 0.5515, "recall": 0.6688, "sf_em": 0.0001, "sf_f1": 0.3497, "sf_precision": 0.261, "sf_recall": 0.5533, "latency_p50_ms": 913.71, "latency_p95_ms": 18503.34}
