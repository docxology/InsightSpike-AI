{
  "report": {
    "name": "comprehensive_report",
    "generated": "2026-01-19T10:42:25.051520",
    "version": "1.0"
  },
  "discovery": {
    "methods": [
      {
        "name": "About",
        "module": "insightspike",
        "type": "class",
        "signature": "()",
        "docstring": "",
        "full_name": "insightspike.About",
        "tags": []
      },
      {
        "name": "AgentConfigBuilder",
        "module": "insightspike",
        "type": "class",
        "signature": "()",
        "docstring": "Builder pattern for agent configuration",
        "full_name": "insightspike.AgentConfigBuilder",
        "tags": []
      },
      {
        "name": "CycleResult",
        "module": "insightspike",
        "type": "class",
        "signature": "(**kwargs)",
        "docstring": "",
        "full_name": "insightspike.CycleResult",
        "tags": []
      },
      {
        "name": "EnvironmentInterface",
        "module": "insightspike",
        "type": "class",
        "signature": "()",
        "docstring": "Generic environment interface for any domain",
        "full_name": "insightspike.EnvironmentInterface",
        "tags": []
      },
      {
        "name": "GenericInsightSpikeAgent",
        "module": "insightspike",
        "type": "class",
        "signature": "(agent_id: str, environment: insightspike.core.base.generic_interfaces.EnvironmentInterface, insight_detector: insightspike.core.base.generic_interfaces.InsightDetectorInterface, state_encoder: insightspike.core.base.generic_interfaces.StateEncoder, reward_normalizer: insightspike.core.base.generic_interfaces.RewardNormalizer, config: Optional[Dict[str, Any]] = None)",
        "docstring": "Generic InsightSpike agent that works with any environment",
        "full_name": "insightspike.GenericInsightSpikeAgent",
        "tags": []
      },
      {
        "name": "InsightMoment",
        "module": "insightspike",
        "type": "class",
        "signature": "(episode: int, step: int, insight_type: str, description: str, dged_value: float, dig_value: float, confidence: float = 0.0, performance_impact: float = 0.0, state: Optional[insightspike.core.base.generic_interfaces.EnvironmentState] = None, action: Optional[Any] = None, reward: Optional[float] = None, detection_method: str = 'default', timestamp: Optional[float] = None, metadata: Optional[Dict[str, Any]] = None) -> None",
        "docstring": "Generic insight moment representation",
        "full_name": "insightspike.InsightMoment",
        "tags": []
      },
      {
        "name": "InsightSpikeAgentFactory",
        "module": "insightspike",
        "type": "class",
        "signature": "()",
        "docstring": "Factory for creating InsightSpike agents for different domains",
        "full_name": "insightspike.InsightSpikeAgentFactory",
        "tags": []
      },
      {
        "name": "L3GraphReasoner",
        "module": "insightspike",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Enhanced graph reasoning layer with GNN processing and spike detection.",
        "full_name": "insightspike.L3GraphReasoner",
        "tags": []
      },
      {
        "name": "MainAgent",
        "module": "insightspike",
        "type": "class",
        "signature": "(*_, **__)",
        "docstring": "",
        "full_name": "insightspike.MainAgent",
        "tags": []
      },
      {
        "name": "StandaloneL3GraphReasoner",
        "module": "insightspike",
        "type": "class",
        "signature": "(config: Union[Dict[str, Any], insightspike.tools.standalone.standalone_l3.StandaloneConfig, NoneType] = None)",
        "docstring": "Standalone version of L3 Graph Reasoner",
        "full_name": "insightspike.StandaloneL3GraphReasoner",
        "tags": []
      },
      {
        "name": "TaskType",
        "module": "insightspike",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Supported task types for insight detection",
        "full_name": "insightspike.TaskType",
        "tags": []
      },
      {
        "name": "about",
        "module": "insightspike",
        "type": "function",
        "signature": "()",
        "docstring": "Return package information as a dictionary.",
        "full_name": "insightspike.about",
        "tags": []
      },
      {
        "name": "analyze_documents_simple",
        "module": "insightspike",
        "type": "function",
        "signature": "(documents: List[str]) -> Dict[str, Any]",
        "docstring": "Simple function to analyze a list of text documents",
        "full_name": "insightspike.analyze_documents_simple",
        "tags": []
      },
      {
        "name": "create_configured_maze_agent",
        "module": "insightspike",
        "type": "function",
        "signature": "(maze_size: int = 10, learning_rate: float = 0.15, exploration_rate: float = 0.4, dged_threshold: float = -0.3, dig_threshold: float = 1.0) -> insightspike.implementations.agents.generic_agent.GenericInsightSpikeAgent",
        "docstring": "Create maze agent with specific parameters",
        "full_name": "insightspike.create_configured_maze_agent",
        "tags": []
      },
      {
        "name": "create_maze_agent",
        "module": "insightspike",
        "type": "function",
        "signature": "(maze_size: int = 10, agent_config: Optional[Dict[str, Any]] = None) -> insightspike.implementations.agents.generic_agent.GenericInsightSpikeAgent",
        "docstring": "Quick function to create a maze agent",
        "full_name": "insightspike.create_maze_agent",
        "tags": []
      },
      {
        "name": "create_standalone_reasoner",
        "module": "insightspike",
        "type": "function",
        "signature": "(config: Optional[Dict[str, Any]] = None) -> insightspike.tools.standalone.standalone_l3.StandaloneL3GraphReasoner",
        "docstring": "Create a standalone graph reasoner with optional configuration",
        "full_name": "insightspike.create_standalone_reasoner",
        "tags": []
      },
      {
        "name": "get_config",
        "module": "insightspike",
        "type": "function",
        "signature": "() -> insightspike.config.models.InsightSpikeConfig",
        "docstring": "Get current configuration or load defaults",
        "full_name": "insightspike.get_config",
        "tags": []
      },
      {
        "name": "run_app",
        "module": "insightspike.__main__",
        "type": "function",
        "signature": "()",
        "docstring": "Composition Root - Where all dependencies are resolved and injected.",
        "full_name": "insightspike.__main__.run_app",
        "tags": []
      },
      {
        "name": "AdaptiveProcessor",
        "module": "insightspike.adaptive",
        "type": "class",
        "signature": "(exploration_loop: insightspike.adaptive.core.exploration_loop.ExplorationLoop, strategy: insightspike.adaptive.core.interfaces.ExplorationStrategy, topk_calculator: insightspike.adaptive.core.interfaces.TopKCalculator, l4_llm, pattern_learner: Optional[insightspike.adaptive.core.interfaces.PatternLearner] = None, max_attempts: int = 5, datastore: Optional[insightspike.core.base.datastore.DataStore] = None)",
        "docstring": "Main adaptive processing coordinator.",
        "full_name": "insightspike.adaptive.AdaptiveProcessor",
        "tags": []
      },
      {
        "name": "ExplorationLoop",
        "module": "insightspike.adaptive",
        "type": "class",
        "signature": "(l1_monitor, l2_memory, l3_graph, spike_thresholds: Optional[Dict[str, float]] = None)",
        "docstring": "Manages the L1\u2192L2\u2192L3 exploration loop.",
        "full_name": "insightspike.adaptive.ExplorationLoop",
        "tags": []
      },
      {
        "name": "ExplorationParams",
        "module": "insightspike.adaptive",
        "type": "class",
        "signature": "(radius: float, topk_l1: int, topk_l2: int, topk_l3: int, temperature: float, attempt_number: int = 0) -> None",
        "docstring": "Parameters for a single exploration attempt",
        "full_name": "insightspike.adaptive.ExplorationParams",
        "tags": []
      },
      {
        "name": "ExplorationResult",
        "module": "insightspike.adaptive",
        "type": "class",
        "signature": "(spike_detected: bool, confidence: float, retrieved_docs: List[Dict[str, Any]], graph_analysis: Dict[str, Any], metrics: Dict[str, float], params: insightspike.adaptive.core.interfaces.ExplorationParams) -> None",
        "docstring": "Result of a single exploration attempt",
        "full_name": "insightspike.adaptive.ExplorationResult",
        "tags": []
      },
      {
        "name": "ExplorationStrategy",
        "module": "insightspike.adaptive",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract base class for exploration strategies",
        "full_name": "insightspike.adaptive.ExplorationStrategy",
        "tags": []
      },
      {
        "name": "PatternLearner",
        "module": "insightspike.adaptive",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract base class for pattern learning",
        "full_name": "insightspike.adaptive.PatternLearner",
        "tags": []
      },
      {
        "name": "TopKCalculator",
        "module": "insightspike.adaptive",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract base class for topK calculation",
        "full_name": "insightspike.adaptive.TopKCalculator",
        "tags": []
      },
      {
        "name": "AdaptiveTopKCalculator",
        "module": "insightspike.adaptive.calculators.adaptive_topk",
        "type": "class",
        "signature": "(config: Optional[insightspike.adaptive.calculators.adaptive_topk.AdaptiveTopKConfig] = None)",
        "docstring": "Calculates adaptive topK values based on Layer 1 analysis.",
        "full_name": "insightspike.adaptive.calculators.adaptive_topk.AdaptiveTopKCalculator",
        "tags": []
      },
      {
        "name": "AdaptiveTopKConfig",
        "module": "insightspike.adaptive.calculators.adaptive_topk",
        "type": "class",
        "signature": "(base_layer1_k: int = 20, base_layer2_k: int = 15, base_layer3_k: int = 12, synthesis_multiplier: float = 1.5, complexity_multiplier: float = 1.3, unknown_ratio_multiplier: float = 1.2, max_layer1_k: int = 50, max_layer2_k: int = 30, max_layer3_k: int = 25, min_k: int = 3, low_confidence_multiplier: float = 1.4, confidence_threshold: float = 0.6) -> None",
        "docstring": "Configuration for adaptive topK algorithm",
        "full_name": "insightspike.adaptive.calculators.adaptive_topk.AdaptiveTopKConfig",
        "tags": []
      },
      {
        "name": "TopKCalculator",
        "module": "insightspike.adaptive.calculators.adaptive_topk",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract base class for topK calculation",
        "full_name": "insightspike.adaptive.calculators.adaptive_topk.TopKCalculator",
        "tags": []
      },
      {
        "name": "estimate_chain_reaction_potential",
        "module": "insightspike.adaptive.calculators.adaptive_topk",
        "type": "function",
        "signature": "(l1_analysis: Dict[str, Any], adaptive_topk: Dict[str, int]) -> float",
        "docstring": "Estimate the potential for chain reaction insight improvement.",
        "full_name": "insightspike.adaptive.calculators.adaptive_topk.estimate_chain_reaction_potential",
        "tags": []
      },
      {
        "name": "SimpleTopKCalculator",
        "module": "insightspike.adaptive.calculators.simple_topk",
        "type": "class",
        "signature": "(k: 'int' = 5)",
        "docstring": "",
        "full_name": "insightspike.adaptive.calculators.simple_topk.SimpleTopKCalculator",
        "tags": []
      },
      {
        "name": "AdaptiveProcessor",
        "module": "insightspike.adaptive.core.adaptive_processor",
        "type": "class",
        "signature": "(exploration_loop: insightspike.adaptive.core.exploration_loop.ExplorationLoop, strategy: insightspike.adaptive.core.interfaces.ExplorationStrategy, topk_calculator: insightspike.adaptive.core.interfaces.TopKCalculator, l4_llm, pattern_learner: Optional[insightspike.adaptive.core.interfaces.PatternLearner] = None, max_attempts: int = 5, datastore: Optional[insightspike.core.base.datastore.DataStore] = None)",
        "docstring": "Main adaptive processing coordinator.",
        "full_name": "insightspike.adaptive.core.adaptive_processor.AdaptiveProcessor",
        "tags": []
      },
      {
        "name": "DataStore",
        "module": "insightspike.adaptive.core.adaptive_processor",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for data persistence",
        "full_name": "insightspike.adaptive.core.adaptive_processor.DataStore",
        "tags": []
      },
      {
        "name": "ExplorationLoop",
        "module": "insightspike.adaptive.core.adaptive_processor",
        "type": "class",
        "signature": "(l1_monitor, l2_memory, l3_graph, spike_thresholds: Optional[Dict[str, float]] = None)",
        "docstring": "Manages the L1\u2192L2\u2192L3 exploration loop.",
        "full_name": "insightspike.adaptive.core.adaptive_processor.ExplorationLoop",
        "tags": []
      },
      {
        "name": "ExplorationParams",
        "module": "insightspike.adaptive.core.adaptive_processor",
        "type": "class",
        "signature": "(radius: float, topk_l1: int, topk_l2: int, topk_l3: int, temperature: float, attempt_number: int = 0) -> None",
        "docstring": "Parameters for a single exploration attempt",
        "full_name": "insightspike.adaptive.core.adaptive_processor.ExplorationParams",
        "tags": []
      },
      {
        "name": "ExplorationResult",
        "module": "insightspike.adaptive.core.adaptive_processor",
        "type": "class",
        "signature": "(spike_detected: bool, confidence: float, retrieved_docs: List[Dict[str, Any]], graph_analysis: Dict[str, Any], metrics: Dict[str, float], params: insightspike.adaptive.core.interfaces.ExplorationParams) -> None",
        "docstring": "Result of a single exploration attempt",
        "full_name": "insightspike.adaptive.core.adaptive_processor.ExplorationResult",
        "tags": []
      },
      {
        "name": "ExplorationStrategy",
        "module": "insightspike.adaptive.core.adaptive_processor",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract base class for exploration strategies",
        "full_name": "insightspike.adaptive.core.adaptive_processor.ExplorationStrategy",
        "tags": []
      },
      {
        "name": "PatternLearner",
        "module": "insightspike.adaptive.core.adaptive_processor",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract base class for pattern learning",
        "full_name": "insightspike.adaptive.core.adaptive_processor.PatternLearner",
        "tags": []
      },
      {
        "name": "TopKCalculator",
        "module": "insightspike.adaptive.core.adaptive_processor",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract base class for topK calculation",
        "full_name": "insightspike.adaptive.core.adaptive_processor.TopKCalculator",
        "tags": []
      },
      {
        "name": "ExplorationLoop",
        "module": "insightspike.adaptive.core.exploration_loop",
        "type": "class",
        "signature": "(l1_monitor, l2_memory, l3_graph, spike_thresholds: Optional[Dict[str, float]] = None)",
        "docstring": "Manages the L1\u2192L2\u2192L3 exploration loop.",
        "full_name": "insightspike.adaptive.core.exploration_loop.ExplorationLoop",
        "tags": []
      },
      {
        "name": "ExplorationParams",
        "module": "insightspike.adaptive.core.exploration_loop",
        "type": "class",
        "signature": "(radius: float, topk_l1: int, topk_l2: int, topk_l3: int, temperature: float, attempt_number: int = 0) -> None",
        "docstring": "Parameters for a single exploration attempt",
        "full_name": "insightspike.adaptive.core.exploration_loop.ExplorationParams",
        "tags": []
      },
      {
        "name": "ExplorationResult",
        "module": "insightspike.adaptive.core.exploration_loop",
        "type": "class",
        "signature": "(spike_detected: bool, confidence: float, retrieved_docs: List[Dict[str, Any]], graph_analysis: Dict[str, Any], metrics: Dict[str, float], params: insightspike.adaptive.core.interfaces.ExplorationParams) -> None",
        "docstring": "Result of a single exploration attempt",
        "full_name": "insightspike.adaptive.core.exploration_loop.ExplorationResult",
        "tags": []
      },
      {
        "name": "NormalizedConfig",
        "module": "insightspike.adaptive.core.exploration_loop",
        "type": "class",
        "signature": "(embedding_model: 'str', embedding_dim: 'int', enable_layer1_bypass: 'bool', bypass_uncertainty_threshold: 'float', bypass_known_ratio_threshold: 'float', enable_learning: 'bool', graph_weight_ged: 'float', graph_weight_ig: 'float', environment: 'str', gedig_mode: 'str' = 'full', max_retrieved_docs: 'int' = 10, dynamic_doc_adjustment: 'bool' = True, max_docs_with_insights: 'int' = 5, insight_relevance_boost: 'float' = 0.2, enable_insight_search: 'bool' = True, max_insights_per_query: 'int' = 5, enable_graph_search: 'bool' = False, enable_insight_registration: 'bool' = True, similarity_threshold: 'float' = 0.3, hop_limit: 'int' = 2, path_decay: 'float' = 0.7, spike_ged_threshold: 'float' = -0.5, spike_ig_threshold: 'float' = 0.2, episode_merge_threshold: 'float' = 0.8, episode_split_threshold: 'float' = 0.3, episode_prune_threshold: 'float' = 0.1, theta_cand: 'float' = 0.45, theta_link: 'float' = 0.35, candidate_cap: 'int' = 32, top_m: 'Optional[int]' = None, ig_denominator: 'str' = 'fixed_kstar', use_local_normalization: 'bool' = False, sp_engine: 'str' = 'core', norm_spec: 'Optional[Dict[str, Any]]' = None, source_type: 'str' = 'unknown', applied_defaults: 'tuple[str, ...]' = <factory>, _raw: 'Any' = None) -> None",
        "docstring": "NormalizedConfig(embedding_model: 'str', embedding_dim: 'int', enable_layer1_bypass: 'bool', bypass_uncertainty_threshold: 'float', bypass_known_ratio_threshold: 'float', enable_learning: 'bool', graph_weight_ged: 'float', graph_weight_ig: 'float', environment: 'str', gedig_mode: 'str' = 'full', max_retrieved_docs: 'int' = 10, dynamic_doc_adjustment: 'bool' = True, max_docs_with_insights: 'int' = 5, insight_relevance_boost: 'float' = 0.2, enable_insight_search: 'bool' = True, max_insights_per_query: 'int' = 5, enable_graph_search: 'bool' = False, enable_insight_registration: 'bool' = True, similarity_threshold: 'float' = 0.3, hop_limit: 'int' = 2, path_decay: 'float' = 0.7, spike_ged_threshold: 'float' = -0.5, spike_ig_threshold: 'float' = 0.2, episode_merge_threshold: 'float' = 0.8, episode_split_threshold: 'float' = 0.3, episode_prune_threshold: 'float' = 0.1, theta_cand: 'float' = 0.45, theta_link: 'float' = 0.35, candidate_cap: 'int' = 32, top_m: 'Optional[int]' = None, ig_denominator: 'str' = 'fixed_kstar', use_local_normalization: 'bool' = False, sp_engine: 'str' = 'core', norm_spec: 'Optional[Dict[str, Any]]' = None, source_type: 'str' = 'unknown', applied_defaults: 'tuple[str, ...]' = <factory>, _raw: 'Any' = None)",
        "full_name": "insightspike.adaptive.core.exploration_loop.NormalizedConfig",
        "tags": []
      },
      {
        "name": "get_config",
        "module": "insightspike.adaptive.core.exploration_loop",
        "type": "function",
        "signature": "() -> insightspike.config.models.InsightSpikeConfig",
        "docstring": "Get current configuration or load defaults",
        "full_name": "insightspike.adaptive.core.exploration_loop.get_config",
        "tags": []
      },
      {
        "name": "ExplorationLoopFixed",
        "module": "insightspike.adaptive.core.exploration_loop_fixed",
        "type": "class",
        "signature": "(l1_monitor, l2_memory, l3_graph, spike_thresholds: Optional[Dict[str, float]] = None)",
        "docstring": "Fixed exploration loop that properly compares graphs for spike detection.",
        "full_name": "insightspike.adaptive.core.exploration_loop_fixed.ExplorationLoopFixed",
        "tags": []
      },
      {
        "name": "ExplorationParams",
        "module": "insightspike.adaptive.core.exploration_loop_fixed",
        "type": "class",
        "signature": "(radius: float, topk_l1: int, topk_l2: int, topk_l3: int, temperature: float, attempt_number: int = 0) -> None",
        "docstring": "Parameters for a single exploration attempt",
        "full_name": "insightspike.adaptive.core.exploration_loop_fixed.ExplorationParams",
        "tags": []
      },
      {
        "name": "ExplorationResult",
        "module": "insightspike.adaptive.core.exploration_loop_fixed",
        "type": "class",
        "signature": "(spike_detected: bool, confidence: float, retrieved_docs: List[Dict[str, Any]], graph_analysis: Dict[str, Any], metrics: Dict[str, float], params: insightspike.adaptive.core.interfaces.ExplorationParams) -> None",
        "docstring": "Result of a single exploration attempt",
        "full_name": "insightspike.adaptive.core.exploration_loop_fixed.ExplorationResult",
        "tags": []
      },
      {
        "name": "NormalizedConfig",
        "module": "insightspike.adaptive.core.exploration_loop_fixed",
        "type": "class",
        "signature": "(embedding_model: 'str', embedding_dim: 'int', enable_layer1_bypass: 'bool', bypass_uncertainty_threshold: 'float', bypass_known_ratio_threshold: 'float', enable_learning: 'bool', graph_weight_ged: 'float', graph_weight_ig: 'float', environment: 'str', gedig_mode: 'str' = 'full', max_retrieved_docs: 'int' = 10, dynamic_doc_adjustment: 'bool' = True, max_docs_with_insights: 'int' = 5, insight_relevance_boost: 'float' = 0.2, enable_insight_search: 'bool' = True, max_insights_per_query: 'int' = 5, enable_graph_search: 'bool' = False, enable_insight_registration: 'bool' = True, similarity_threshold: 'float' = 0.3, hop_limit: 'int' = 2, path_decay: 'float' = 0.7, spike_ged_threshold: 'float' = -0.5, spike_ig_threshold: 'float' = 0.2, episode_merge_threshold: 'float' = 0.8, episode_split_threshold: 'float' = 0.3, episode_prune_threshold: 'float' = 0.1, theta_cand: 'float' = 0.45, theta_link: 'float' = 0.35, candidate_cap: 'int' = 32, top_m: 'Optional[int]' = None, ig_denominator: 'str' = 'fixed_kstar', use_local_normalization: 'bool' = False, sp_engine: 'str' = 'core', norm_spec: 'Optional[Dict[str, Any]]' = None, source_type: 'str' = 'unknown', applied_defaults: 'tuple[str, ...]' = <factory>, _raw: 'Any' = None) -> None",
        "docstring": "NormalizedConfig(embedding_model: 'str', embedding_dim: 'int', enable_layer1_bypass: 'bool', bypass_uncertainty_threshold: 'float', bypass_known_ratio_threshold: 'float', enable_learning: 'bool', graph_weight_ged: 'float', graph_weight_ig: 'float', environment: 'str', gedig_mode: 'str' = 'full', max_retrieved_docs: 'int' = 10, dynamic_doc_adjustment: 'bool' = True, max_docs_with_insights: 'int' = 5, insight_relevance_boost: 'float' = 0.2, enable_insight_search: 'bool' = True, max_insights_per_query: 'int' = 5, enable_graph_search: 'bool' = False, enable_insight_registration: 'bool' = True, similarity_threshold: 'float' = 0.3, hop_limit: 'int' = 2, path_decay: 'float' = 0.7, spike_ged_threshold: 'float' = -0.5, spike_ig_threshold: 'float' = 0.2, episode_merge_threshold: 'float' = 0.8, episode_split_threshold: 'float' = 0.3, episode_prune_threshold: 'float' = 0.1, theta_cand: 'float' = 0.45, theta_link: 'float' = 0.35, candidate_cap: 'int' = 32, top_m: 'Optional[int]' = None, ig_denominator: 'str' = 'fixed_kstar', use_local_normalization: 'bool' = False, sp_engine: 'str' = 'core', norm_spec: 'Optional[Dict[str, Any]]' = None, source_type: 'str' = 'unknown', applied_defaults: 'tuple[str, ...]' = <factory>, _raw: 'Any' = None)",
        "full_name": "insightspike.adaptive.core.exploration_loop_fixed.NormalizedConfig",
        "tags": []
      },
      {
        "name": "get_config",
        "module": "insightspike.adaptive.core.exploration_loop_fixed",
        "type": "function",
        "signature": "() -> insightspike.config.models.InsightSpikeConfig",
        "docstring": "Get current configuration or load defaults",
        "full_name": "insightspike.adaptive.core.exploration_loop_fixed.get_config",
        "tags": []
      },
      {
        "name": "ExplorationParams",
        "module": "insightspike.adaptive.core.interfaces",
        "type": "class",
        "signature": "(radius: float, topk_l1: int, topk_l2: int, topk_l3: int, temperature: float, attempt_number: int = 0) -> None",
        "docstring": "Parameters for a single exploration attempt",
        "full_name": "insightspike.adaptive.core.interfaces.ExplorationParams",
        "tags": []
      },
      {
        "name": "ExplorationResult",
        "module": "insightspike.adaptive.core.interfaces",
        "type": "class",
        "signature": "(spike_detected: bool, confidence: float, retrieved_docs: List[Dict[str, Any]], graph_analysis: Dict[str, Any], metrics: Dict[str, float], params: insightspike.adaptive.core.interfaces.ExplorationParams) -> None",
        "docstring": "Result of a single exploration attempt",
        "full_name": "insightspike.adaptive.core.interfaces.ExplorationResult",
        "tags": []
      },
      {
        "name": "ExplorationStrategy",
        "module": "insightspike.adaptive.core.interfaces",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract base class for exploration strategies",
        "full_name": "insightspike.adaptive.core.interfaces.ExplorationStrategy",
        "tags": []
      },
      {
        "name": "PatternLearner",
        "module": "insightspike.adaptive.core.interfaces",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract base class for pattern learning",
        "full_name": "insightspike.adaptive.core.interfaces.PatternLearner",
        "tags": []
      },
      {
        "name": "TopKCalculator",
        "module": "insightspike.adaptive.core.interfaces",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract base class for topK calculation",
        "full_name": "insightspike.adaptive.core.interfaces.TopKCalculator",
        "tags": []
      },
      {
        "name": "AlternatingStrategy",
        "module": "insightspike.adaptive.strategies",
        "type": "class",
        "signature": "(broad_radius: float = 0.8, narrow_radius: float = 0.3, **kwargs)",
        "docstring": "Alternating exploration strategy.",
        "full_name": "insightspike.adaptive.strategies.AlternatingStrategy",
        "tags": []
      },
      {
        "name": "ExpandingStrategy",
        "module": "insightspike.adaptive.strategies",
        "type": "class",
        "signature": "(initial_radius: float = 0.3, radius_growth_factor: float = 1.3, **kwargs)",
        "docstring": "Expanding exploration strategy.",
        "full_name": "insightspike.adaptive.strategies.ExpandingStrategy",
        "tags": []
      },
      {
        "name": "ExponentialStrategy",
        "module": "insightspike.adaptive.strategies",
        "type": "class",
        "signature": "(decay: float = 0.9, **kwargs)",
        "docstring": "Simple exponential decay variant (delegates to BaseStrategy).",
        "full_name": "insightspike.adaptive.strategies.ExponentialStrategy",
        "tags": []
      },
      {
        "name": "NarrowingStrategy",
        "module": "insightspike.adaptive.strategies",
        "type": "class",
        "signature": "(initial_radius: float = 0.8, radius_decay_factor: float = 0.8, **kwargs)",
        "docstring": "Narrowing exploration strategy.",
        "full_name": "insightspike.adaptive.strategies.NarrowingStrategy",
        "tags": []
      },
      {
        "name": "AlternatingStrategy",
        "module": "insightspike.adaptive.strategies.alternating",
        "type": "class",
        "signature": "(broad_radius: float = 0.8, narrow_radius: float = 0.3, **kwargs)",
        "docstring": "Alternating exploration strategy.",
        "full_name": "insightspike.adaptive.strategies.alternating.AlternatingStrategy",
        "tags": []
      },
      {
        "name": "BaseStrategy",
        "module": "insightspike.adaptive.strategies.alternating",
        "type": "class",
        "signature": "(initial_radius: float = 0.7, initial_temperature: float = 1.0, min_radius: float = 0.1, max_radius: float = 1.0, temperature_decay: float = 0.95, confidence_threshold: float = 0.8)",
        "docstring": "Base class with common strategy functionality",
        "full_name": "insightspike.adaptive.strategies.alternating.BaseStrategy",
        "tags": []
      },
      {
        "name": "ExplorationParams",
        "module": "insightspike.adaptive.strategies.alternating",
        "type": "class",
        "signature": "(radius: float, topk_l1: int, topk_l2: int, topk_l3: int, temperature: float, attempt_number: int = 0) -> None",
        "docstring": "Parameters for a single exploration attempt",
        "full_name": "insightspike.adaptive.strategies.alternating.ExplorationParams",
        "tags": []
      },
      {
        "name": "ExplorationResult",
        "module": "insightspike.adaptive.strategies.alternating",
        "type": "class",
        "signature": "(spike_detected: bool, confidence: float, retrieved_docs: List[Dict[str, Any]], graph_analysis: Dict[str, Any], metrics: Dict[str, float], params: insightspike.adaptive.core.interfaces.ExplorationParams) -> None",
        "docstring": "Result of a single exploration attempt",
        "full_name": "insightspike.adaptive.strategies.alternating.ExplorationResult",
        "tags": []
      },
      {
        "name": "AdaptiveTopKCalculator",
        "module": "insightspike.adaptive.strategies.base",
        "type": "class",
        "signature": "(config: Optional[insightspike.adaptive.calculators.adaptive_topk.AdaptiveTopKConfig] = None)",
        "docstring": "Calculates adaptive topK values based on Layer 1 analysis.",
        "full_name": "insightspike.adaptive.strategies.base.AdaptiveTopKCalculator",
        "tags": []
      },
      {
        "name": "BaseStrategy",
        "module": "insightspike.adaptive.strategies.base",
        "type": "class",
        "signature": "(initial_radius: float = 0.7, initial_temperature: float = 1.0, min_radius: float = 0.1, max_radius: float = 1.0, temperature_decay: float = 0.95, confidence_threshold: float = 0.8)",
        "docstring": "Base class with common strategy functionality",
        "full_name": "insightspike.adaptive.strategies.base.BaseStrategy",
        "tags": []
      },
      {
        "name": "ExplorationParams",
        "module": "insightspike.adaptive.strategies.base",
        "type": "class",
        "signature": "(radius: float, topk_l1: int, topk_l2: int, topk_l3: int, temperature: float, attempt_number: int = 0) -> None",
        "docstring": "Parameters for a single exploration attempt",
        "full_name": "insightspike.adaptive.strategies.base.ExplorationParams",
        "tags": []
      },
      {
        "name": "ExplorationResult",
        "module": "insightspike.adaptive.strategies.base",
        "type": "class",
        "signature": "(spike_detected: bool, confidence: float, retrieved_docs: List[Dict[str, Any]], graph_analysis: Dict[str, Any], metrics: Dict[str, float], params: insightspike.adaptive.core.interfaces.ExplorationParams) -> None",
        "docstring": "Result of a single exploration attempt",
        "full_name": "insightspike.adaptive.strategies.base.ExplorationResult",
        "tags": []
      },
      {
        "name": "ExplorationStrategy",
        "module": "insightspike.adaptive.strategies.base",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract base class for exploration strategies",
        "full_name": "insightspike.adaptive.strategies.base.ExplorationStrategy",
        "tags": []
      },
      {
        "name": "BaseStrategy",
        "module": "insightspike.adaptive.strategies.expanding",
        "type": "class",
        "signature": "(initial_radius: float = 0.7, initial_temperature: float = 1.0, min_radius: float = 0.1, max_radius: float = 1.0, temperature_decay: float = 0.95, confidence_threshold: float = 0.8)",
        "docstring": "Base class with common strategy functionality",
        "full_name": "insightspike.adaptive.strategies.expanding.BaseStrategy",
        "tags": []
      },
      {
        "name": "ExpandingStrategy",
        "module": "insightspike.adaptive.strategies.expanding",
        "type": "class",
        "signature": "(initial_radius: float = 0.3, radius_growth_factor: float = 1.3, **kwargs)",
        "docstring": "Expanding exploration strategy.",
        "full_name": "insightspike.adaptive.strategies.expanding.ExpandingStrategy",
        "tags": []
      },
      {
        "name": "ExplorationParams",
        "module": "insightspike.adaptive.strategies.expanding",
        "type": "class",
        "signature": "(radius: float, topk_l1: int, topk_l2: int, topk_l3: int, temperature: float, attempt_number: int = 0) -> None",
        "docstring": "Parameters for a single exploration attempt",
        "full_name": "insightspike.adaptive.strategies.expanding.ExplorationParams",
        "tags": []
      },
      {
        "name": "ExplorationResult",
        "module": "insightspike.adaptive.strategies.expanding",
        "type": "class",
        "signature": "(spike_detected: bool, confidence: float, retrieved_docs: List[Dict[str, Any]], graph_analysis: Dict[str, Any], metrics: Dict[str, float], params: insightspike.adaptive.core.interfaces.ExplorationParams) -> None",
        "docstring": "Result of a single exploration attempt",
        "full_name": "insightspike.adaptive.strategies.expanding.ExplorationResult",
        "tags": []
      },
      {
        "name": "BaseStrategy",
        "module": "insightspike.adaptive.strategies.exponential_strategy",
        "type": "class",
        "signature": "(initial_radius: float = 0.7, initial_temperature: float = 1.0, min_radius: float = 0.1, max_radius: float = 1.0, temperature_decay: float = 0.95, confidence_threshold: float = 0.8)",
        "docstring": "Base class with common strategy functionality",
        "full_name": "insightspike.adaptive.strategies.exponential_strategy.BaseStrategy",
        "tags": []
      },
      {
        "name": "ExponentialStrategy",
        "module": "insightspike.adaptive.strategies.exponential_strategy",
        "type": "class",
        "signature": "(decay: float = 0.9, **kwargs)",
        "docstring": "Simple exponential decay variant (delegates to BaseStrategy).",
        "full_name": "insightspike.adaptive.strategies.exponential_strategy.ExponentialStrategy",
        "tags": []
      },
      {
        "name": "BaseStrategy",
        "module": "insightspike.adaptive.strategies.narrowing",
        "type": "class",
        "signature": "(initial_radius: float = 0.7, initial_temperature: float = 1.0, min_radius: float = 0.1, max_radius: float = 1.0, temperature_decay: float = 0.95, confidence_threshold: float = 0.8)",
        "docstring": "Base class with common strategy functionality",
        "full_name": "insightspike.adaptive.strategies.narrowing.BaseStrategy",
        "tags": []
      },
      {
        "name": "ExplorationParams",
        "module": "insightspike.adaptive.strategies.narrowing",
        "type": "class",
        "signature": "(radius: float, topk_l1: int, topk_l2: int, topk_l3: int, temperature: float, attempt_number: int = 0) -> None",
        "docstring": "Parameters for a single exploration attempt",
        "full_name": "insightspike.adaptive.strategies.narrowing.ExplorationParams",
        "tags": []
      },
      {
        "name": "ExplorationResult",
        "module": "insightspike.adaptive.strategies.narrowing",
        "type": "class",
        "signature": "(spike_detected: bool, confidence: float, retrieved_docs: List[Dict[str, Any]], graph_analysis: Dict[str, Any], metrics: Dict[str, float], params: insightspike.adaptive.core.interfaces.ExplorationParams) -> None",
        "docstring": "Result of a single exploration attempt",
        "full_name": "insightspike.adaptive.strategies.narrowing.ExplorationResult",
        "tags": []
      },
      {
        "name": "NarrowingStrategy",
        "module": "insightspike.adaptive.strategies.narrowing",
        "type": "class",
        "signature": "(initial_radius: float = 0.8, radius_decay_factor: float = 0.8, **kwargs)",
        "docstring": "Narrowing exploration strategy.",
        "full_name": "insightspike.adaptive.strategies.narrowing.NarrowingStrategy",
        "tags": []
      },
      {
        "name": "test",
        "module": "insightspike.cli.simple_cli",
        "type": "function",
        "signature": "()",
        "docstring": "Test command that works immediately",
        "full_name": "insightspike.cli.simple_cli.test",
        "tags": []
      },
      {
        "name": "version",
        "module": "insightspike.cli.simple_cli",
        "type": "function",
        "signature": "()",
        "docstring": "Show version information",
        "full_name": "insightspike.cli.simple_cli.version",
        "tags": []
      },
      {
        "name": "CLIState",
        "module": "insightspike.cli.spike",
        "type": "class",
        "signature": "()",
        "docstring": "Container for CLI state shared across commands.",
        "full_name": "insightspike.cli.spike.CLIState",
        "tags": []
      },
      {
        "name": "ConfigLoader",
        "module": "insightspike.cli.spike",
        "type": "class",
        "signature": "()",
        "docstring": "Unified configuration loader that handles all configuration sources",
        "full_name": "insightspike.cli.spike.ConfigLoader",
        "tags": []
      },
      {
        "name": "ConfigPresets",
        "module": "insightspike.cli.spike",
        "type": "class",
        "signature": "()",
        "docstring": "Configuration presets for different environments and use cases",
        "full_name": "insightspike.cli.spike.ConfigPresets",
        "tags": []
      },
      {
        "name": "DependencyFactory",
        "module": "insightspike.cli.spike",
        "type": "class",
        "signature": "(base_config: insightspike.config.models.InsightSpikeConfig, datastore: Optional[Any] = None)",
        "docstring": "Factory for creating agents with different configurations.",
        "full_name": "insightspike.cli.spike.DependencyFactory",
        "tags": []
      },
      {
        "name": "InsightSpikeConfig",
        "module": "insightspike.cli.spike",
        "type": "class",
        "signature": "(*, environment: Literal['development', 'experiment', 'production', 'research', 'test', 'testing', 'custom'] = 'development', pre_warm_models: bool = True, llm: insightspike.config.models.LLMConfig = <factory>, embedding: insightspike.config.models.EmbeddingConfig = <factory>, memory: insightspike.config.models.MemoryConfig = <factory>, graph: insightspike.config.models.GraphConfig = <factory>, monitoring: insightspike.config.models.MonitoringConfig = <factory>, logging: insightspike.config.models.LoggingConfig = <factory>, paths: insightspike.config.models.PathsConfig = <factory>, processing: insightspike.config.models.ProcessingConfig = <factory>, output: insightspike.config.models.OutputConfig = <factory>, datastore: insightspike.config.models.DataStoreConfig = <factory>, metrics: insightspike.config.models.MetricsConfig = <factory>, reasoning: insightspike.config.models.ReasoningConfig = <factory>, performance: insightspike.config.models.PerformanceConfig = <factory>, vector_search: insightspike.config.models.VectorSearchConfig = <factory>, wake_sleep: insightspike.config.wake_sleep_config.WakeSleepConfig = <factory>) -> None",
        "docstring": "Complete InsightSpike configuration - clean structure without backward compatibility",
        "full_name": "insightspike.cli.spike.InsightSpikeConfig",
        "tags": []
      },
      {
        "name": "InsightSpikeError",
        "module": "insightspike.cli.spike",
        "type": "class",
        "signature": "()",
        "docstring": "InsightSpike\u57fa\u5e95\u4f8b\u5916",
        "full_name": "insightspike.cli.spike.InsightSpikeError",
        "tags": []
      },
      {
        "name": "MainAgent",
        "module": "insightspike.cli.spike",
        "type": "class",
        "signature": "(config=None, datastore: Optional[insightspike.core.base.datastore.DataStore] = None)",
        "docstring": "Main orchestrating agent that coordinates all layers.",
        "full_name": "insightspike.cli.spike.MainAgent",
        "tags": []
      },
      {
        "name": "analyze_command",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "(export: Optional[pathlib._local.Path] = <typer.models.OptionInfo object at 0x149400690>, verbose: bool = <typer.models.OptionInfo object at 0x1494007d0>)",
        "docstring": "Analyze knowledge graph structure and metrics",
        "full_name": "insightspike.cli.spike.analyze_command",
        "tags": []
      },
      {
        "name": "bridge_command",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "(concept1: str = <typer.models.ArgumentInfo object at 0x1492bb380>, concept2: str = <typer.models.ArgumentInfo object at 0x149243ed0>, max_hops: int = <typer.models.OptionInfo object at 0x149400050>, top_k: int = <typer.models.OptionInfo object at 0x149400190>, export: Optional[pathlib._local.Path] = <typer.models.OptionInfo object at 0x1494002d0>, verbose: bool = <typer.models.OptionInfo object at 0x149400410>)",
        "docstring": "Find conceptual bridges between two ideas",
        "full_name": "insightspike.cli.spike.bridge_command",
        "tags": []
      },
      {
        "name": "config",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "(ctx: typer.models.Context, action: str = <typer.models.ArgumentInfo object at 0x149401810>, key: Optional[str] = <typer.models.ArgumentInfo object at 0x149401950>, value: Optional[str] = <typer.models.ArgumentInfo object at 0x149401a90>)",
        "docstring": "Manage configuration settings",
        "full_name": "insightspike.cli.spike.config",
        "tags": []
      },
      {
        "name": "demo",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "(ctx: typer.models.Context)",
        "docstring": "Run interactive demo showcasing InsightSpike capabilities",
        "full_name": "insightspike.cli.spike.demo",
        "tags": []
      },
      {
        "name": "discover_command",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "(ctx: typer.models.Context, corpus: Optional[pathlib._local.Path] = <typer.models.OptionInfo object at 0x1492434d0>, min_spike: float = <typer.models.OptionInfo object at 0x149243610>, max_insights: int = <typer.models.OptionInfo object at 0x149243750>, categories: Optional[str] = <typer.models.OptionInfo object at 0x149243890>, export_path: Optional[pathlib._local.Path] = <typer.models.OptionInfo object at 0x1492439d0>, verbose: bool = <typer.models.OptionInfo object at 0x149243b10>)",
        "docstring": "Discover hidden insights and unexpected connections in your knowledge base.",
        "full_name": "insightspike.cli.spike.discover_command",
        "tags": []
      },
      {
        "name": "embed",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "(ctx: typer.models.Context, path: pathlib._local.Path, preset: str = <typer.models.OptionInfo object at 0x1494016d0>)",
        "docstring": "Add documents to the knowledge base (aliases: learn, l, e)",
        "full_name": "insightspike.cli.spike.embed",
        "tags": []
      },
      {
        "name": "experiment",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "(ctx: typer.models.Context, name: str = <typer.models.OptionInfo object at 0x149401bd0>, episodes: int = <typer.models.OptionInfo object at 0x149401d10>)",
        "docstring": "Run experiments to demonstrate capabilities",
        "full_name": "insightspike.cli.spike.experiment",
        "tags": []
      },
      {
        "name": "get_config",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "() -> insightspike.config.models.InsightSpikeConfig",
        "docstring": "Get current configuration or load defaults",
        "full_name": "insightspike.cli.spike.get_config",
        "tags": []
      },
      {
        "name": "get_logger",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "(name: str) -> logging.Logger",
        "docstring": "\u30ed\u30ac\u30fc\u3092\u53d6\u5f97\u3059\u308b\u4fbf\u5229\u95a2\u6570",
        "full_name": "insightspike.cli.spike.get_logger",
        "tags": []
      },
      {
        "name": "insights",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "(ctx: typer.models.Context, limit: int = <typer.models.OptionInfo object at 0x149401e50>)",
        "docstring": "Show discovered insights and statistics",
        "full_name": "insightspike.cli.spike.insights",
        "tags": []
      },
      {
        "name": "insights_search",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "(ctx: typer.models.Context, concept: str, limit: int = <typer.models.OptionInfo object at 0x149401f90>)",
        "docstring": "Search for insights related to a concept",
        "full_name": "insightspike.cli.spike.insights_search",
        "tags": []
      },
      {
        "name": "interactive",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "(ctx: typer.models.Context)",
        "docstring": "Interactive chat mode (alias: chat)",
        "full_name": "insightspike.cli.spike.interactive",
        "tags": []
      },
      {
        "name": "load_config",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "(config_path: Union[str, pathlib._local.Path, NoneType] = None, preset: Optional[str] = None, overrides: Optional[Dict[str, Any]] = None) -> insightspike.config.models.InsightSpikeConfig",
        "docstring": "Load configuration using global loader",
        "full_name": "insightspike.cli.spike.load_config",
        "tags": []
      },
      {
        "name": "main",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "()",
        "docstring": "",
        "full_name": "insightspike.cli.spike.main",
        "tags": []
      },
      {
        "name": "query",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "(ctx: typer.models.Context, question: str, preset: str = <typer.models.OptionInfo object at 0x149400550>, verbose: bool = <typer.models.OptionInfo object at 0x149401450>)",
        "docstring": "Query the knowledge base and get insights",
        "full_name": "insightspike.cli.spike.query",
        "tags": []
      },
      {
        "name": "run_cli",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "(config: insightspike.config.models.InsightSpikeConfig, datastore: Optional[Any] = None)",
        "docstring": "Main entry point for the CLI, called from __main__.py",
        "full_name": "insightspike.cli.spike.run_cli",
        "tags": []
      },
      {
        "name": "show_stats",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "(factory: insightspike.cli.spike.DependencyFactory)",
        "docstring": "Display agent statistics",
        "full_name": "insightspike.cli.spike.show_stats",
        "tags": []
      },
      {
        "name": "sleep_gc_command",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "(namespace: str = <typer.models.OptionInfo object at 0x149400e10>, max_degree: int = <typer.models.OptionInfo object at 0x149400f50>, min_weight: float = <typer.models.OptionInfo object at 0x149401090>, decay: float = <typer.models.OptionInfo object at 0x1494011d0>, keep_pinned: bool = <typer.models.OptionInfo object at 0x149401310>)",
        "docstring": "Run sleep/forget maintenance: edge pooling, weight decay, orphan pruning.",
        "full_name": "insightspike.cli.spike.sleep_gc_command",
        "tags": []
      },
      {
        "name": "stats",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "(ctx: typer.models.Context)",
        "docstring": "Show agent statistics and insights",
        "full_name": "insightspike.cli.spike.stats",
        "tags": []
      },
      {
        "name": "version",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "()",
        "docstring": "Show version information",
        "full_name": "insightspike.cli.spike.version",
        "tags": []
      },
      {
        "name": "visualize_command",
        "module": "insightspike.cli.spike",
        "type": "function",
        "signature": "(output: pathlib._local.Path = <typer.models.ArgumentInfo object at 0x149400910>, format: str = <typer.models.OptionInfo object at 0x149400a50>, insights_only: bool = <typer.models.OptionInfo object at 0x149400b90>, verbose: bool = <typer.models.OptionInfo object at 0x149400cd0>)",
        "docstring": "Generate interactive visualization of the knowledge graph",
        "full_name": "insightspike.cli.spike.visualize_command",
        "tags": []
      },
      {
        "name": "ConfigPresets",
        "module": "insightspike.config",
        "type": "class",
        "signature": "()",
        "docstring": "Configuration presets for different environments and use cases",
        "full_name": "insightspike.config.ConfigPresets",
        "tags": []
      },
      {
        "name": "InsightSpikeConfig",
        "module": "insightspike.config",
        "type": "class",
        "signature": "(*, environment: Literal['development', 'experiment', 'production', 'research', 'test', 'testing', 'custom'] = 'development', pre_warm_models: bool = True, llm: insightspike.config.models.LLMConfig = <factory>, embedding: insightspike.config.models.EmbeddingConfig = <factory>, memory: insightspike.config.models.MemoryConfig = <factory>, graph: insightspike.config.models.GraphConfig = <factory>, monitoring: insightspike.config.models.MonitoringConfig = <factory>, logging: insightspike.config.models.LoggingConfig = <factory>, paths: insightspike.config.models.PathsConfig = <factory>, processing: insightspike.config.models.ProcessingConfig = <factory>, output: insightspike.config.models.OutputConfig = <factory>, datastore: insightspike.config.models.DataStoreConfig = <factory>, metrics: insightspike.config.models.MetricsConfig = <factory>, reasoning: insightspike.config.models.ReasoningConfig = <factory>, performance: insightspike.config.models.PerformanceConfig = <factory>, vector_search: insightspike.config.models.VectorSearchConfig = <factory>, wake_sleep: insightspike.config.wake_sleep_config.WakeSleepConfig = <factory>) -> None",
        "docstring": "Complete InsightSpike configuration - clean structure without backward compatibility",
        "full_name": "insightspike.config.InsightSpikeConfig",
        "tags": []
      },
      {
        "name": "get_config",
        "module": "insightspike.config",
        "type": "function",
        "signature": "() -> insightspike.config.models.InsightSpikeConfig",
        "docstring": "Get current configuration or load defaults",
        "full_name": "insightspike.config.get_config",
        "tags": []
      },
      {
        "name": "load_config",
        "module": "insightspike.config",
        "type": "function",
        "signature": "(config_path: Union[str, pathlib._local.Path, NoneType] = None, preset: Optional[str] = None, overrides: Optional[Dict[str, Any]] = None) -> insightspike.config.models.InsightSpikeConfig",
        "docstring": "Load configuration using global loader",
        "full_name": "insightspike.config.load_config",
        "tags": []
      },
      {
        "name": "ConfigNormalizer",
        "module": "insightspike.config.compat",
        "type": "class",
        "signature": "()",
        "docstring": "Normalizes various configuration formats to standard Pydantic models.",
        "full_name": "insightspike.config.compat.ConfigNormalizer",
        "tags": []
      },
      {
        "name": "InsightSpikeConfig",
        "module": "insightspike.config.compat",
        "type": "class",
        "signature": "(*, environment: Literal['development', 'experiment', 'production', 'research', 'test', 'testing', 'custom'] = 'development', pre_warm_models: bool = True, llm: insightspike.config.models.LLMConfig = <factory>, embedding: insightspike.config.models.EmbeddingConfig = <factory>, memory: insightspike.config.models.MemoryConfig = <factory>, graph: insightspike.config.models.GraphConfig = <factory>, monitoring: insightspike.config.models.MonitoringConfig = <factory>, logging: insightspike.config.models.LoggingConfig = <factory>, paths: insightspike.config.models.PathsConfig = <factory>, processing: insightspike.config.models.ProcessingConfig = <factory>, output: insightspike.config.models.OutputConfig = <factory>, datastore: insightspike.config.models.DataStoreConfig = <factory>, metrics: insightspike.config.models.MetricsConfig = <factory>, reasoning: insightspike.config.models.ReasoningConfig = <factory>, performance: insightspike.config.models.PerformanceConfig = <factory>, vector_search: insightspike.config.models.VectorSearchConfig = <factory>, wake_sleep: insightspike.config.wake_sleep_config.WakeSleepConfig = <factory>) -> None",
        "docstring": "Complete InsightSpike configuration - clean structure without backward compatibility",
        "full_name": "insightspike.config.compat.InsightSpikeConfig",
        "tags": []
      },
      {
        "name": "detect_config_type",
        "module": "insightspike.config.compat",
        "type": "function",
        "signature": "(config: 'Any') -> 'str'",
        "docstring": "Return 'pydantic' for InsightSpikeConfig, else 'dict'.",
        "full_name": "insightspike.config.compat.detect_config_type",
        "tags": []
      },
      {
        "name": "is_pydantic_config",
        "module": "insightspike.config.compat",
        "type": "function",
        "signature": "(config: 'Any') -> 'bool'",
        "docstring": "True if config is an InsightSpikeConfig instance.",
        "full_name": "insightspike.config.compat.is_pydantic_config",
        "tags": []
      },
      {
        "name": "normalize",
        "module": "insightspike.config.compat",
        "type": "function",
        "signature": "(config: 'Any') -> 'InsightSpikeConfig'",
        "docstring": "Normalize input config (dict or Pydantic) into InsightSpikeConfig.",
        "full_name": "insightspike.config.compat.normalize",
        "tags": []
      },
      {
        "name": "DataType",
        "module": "insightspike.config.constants",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Types of data stored by the system.",
        "full_name": "insightspike.config.constants.DataType",
        "tags": []
      },
      {
        "name": "Defaults",
        "module": "insightspike.config.constants",
        "type": "class",
        "signature": "()",
        "docstring": "Default values used throughout the system.",
        "full_name": "insightspike.config.constants.Defaults",
        "tags": []
      },
      {
        "name": "FileFormat",
        "module": "insightspike.config.constants",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Supported file formats for data storage.",
        "full_name": "insightspike.config.constants.FileFormat",
        "tags": []
      },
      {
        "name": "IndexFeatureFlags",
        "module": "insightspike.config.index_config",
        "type": "class",
        "signature": "(*, use_integrated_index: bool = False, rollout_percentage: Annotated[int, Ge(ge=0), Le(le=100)] = 0, enable_performance_monitoring: bool = True, enable_rollback: bool = True) -> None",
        "docstring": "\u6a5f\u80fd\u30d5\u30e9\u30b0\u8a2d\u5b9a",
        "full_name": "insightspike.config.index_config.IndexFeatureFlags",
        "tags": []
      },
      {
        "name": "IntegratedIndexConfig",
        "module": "insightspike.config.index_config",
        "type": "class",
        "signature": "(*, enabled: bool = False, dimension: int = 768, similarity_threshold: float = 0.3, use_faiss: bool = True, faiss_threshold: int = 100000, migration_mode: str = 'shadow', auto_save: bool = True, save_interval: int = 1000) -> None",
        "docstring": "\u7d71\u5408\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306e\u8a2d\u5b9a",
        "full_name": "insightspike.config.index_config.IntegratedIndexConfig",
        "tags": []
      },
      {
        "name": "ConfigNormalizer",
        "module": "insightspike.config.legacy_adapter",
        "type": "class",
        "signature": "()",
        "docstring": "Normalizes various configuration formats to standard Pydantic models.",
        "full_name": "insightspike.config.legacy_adapter.ConfigNormalizer",
        "tags": []
      },
      {
        "name": "InsightSpikeConfig",
        "module": "insightspike.config.legacy_adapter",
        "type": "class",
        "signature": "(*, environment: Literal['development', 'experiment', 'production', 'research', 'test', 'testing', 'custom'] = 'development', pre_warm_models: bool = True, llm: insightspike.config.models.LLMConfig = <factory>, embedding: insightspike.config.models.EmbeddingConfig = <factory>, memory: insightspike.config.models.MemoryConfig = <factory>, graph: insightspike.config.models.GraphConfig = <factory>, monitoring: insightspike.config.models.MonitoringConfig = <factory>, logging: insightspike.config.models.LoggingConfig = <factory>, paths: insightspike.config.models.PathsConfig = <factory>, processing: insightspike.config.models.ProcessingConfig = <factory>, output: insightspike.config.models.OutputConfig = <factory>, datastore: insightspike.config.models.DataStoreConfig = <factory>, metrics: insightspike.config.models.MetricsConfig = <factory>, reasoning: insightspike.config.models.ReasoningConfig = <factory>, performance: insightspike.config.models.PerformanceConfig = <factory>, vector_search: insightspike.config.models.VectorSearchConfig = <factory>, wake_sleep: insightspike.config.wake_sleep_config.WakeSleepConfig = <factory>) -> None",
        "docstring": "Complete InsightSpike configuration - clean structure without backward compatibility",
        "full_name": "insightspike.config.legacy_adapter.InsightSpikeConfig",
        "tags": []
      },
      {
        "name": "LegacyConfigAdapter",
        "module": "insightspike.config.legacy_adapter",
        "type": "class",
        "signature": "()",
        "docstring": "Adapter for converting legacy configurations to Pydantic models.",
        "full_name": "insightspike.config.legacy_adapter.LegacyConfigAdapter",
        "tags": []
      },
      {
        "name": "ConfigLoader",
        "module": "insightspike.config.loader",
        "type": "class",
        "signature": "()",
        "docstring": "Unified configuration loader that handles all configuration sources",
        "full_name": "insightspike.config.loader.ConfigLoader",
        "tags": []
      },
      {
        "name": "ConfigPresets",
        "module": "insightspike.config.loader",
        "type": "class",
        "signature": "()",
        "docstring": "Configuration presets for different environments and use cases",
        "full_name": "insightspike.config.loader.ConfigPresets",
        "tags": []
      },
      {
        "name": "InsightSpikeConfig",
        "module": "insightspike.config.loader",
        "type": "class",
        "signature": "(*, environment: Literal['development', 'experiment', 'production', 'research', 'test', 'testing', 'custom'] = 'development', pre_warm_models: bool = True, llm: insightspike.config.models.LLMConfig = <factory>, embedding: insightspike.config.models.EmbeddingConfig = <factory>, memory: insightspike.config.models.MemoryConfig = <factory>, graph: insightspike.config.models.GraphConfig = <factory>, monitoring: insightspike.config.models.MonitoringConfig = <factory>, logging: insightspike.config.models.LoggingConfig = <factory>, paths: insightspike.config.models.PathsConfig = <factory>, processing: insightspike.config.models.ProcessingConfig = <factory>, output: insightspike.config.models.OutputConfig = <factory>, datastore: insightspike.config.models.DataStoreConfig = <factory>, metrics: insightspike.config.models.MetricsConfig = <factory>, reasoning: insightspike.config.models.ReasoningConfig = <factory>, performance: insightspike.config.models.PerformanceConfig = <factory>, vector_search: insightspike.config.models.VectorSearchConfig = <factory>, wake_sleep: insightspike.config.wake_sleep_config.WakeSleepConfig = <factory>) -> None",
        "docstring": "Complete InsightSpike configuration - clean structure without backward compatibility",
        "full_name": "insightspike.config.loader.InsightSpikeConfig",
        "tags": []
      },
      {
        "name": "get_config",
        "module": "insightspike.config.loader",
        "type": "function",
        "signature": "() -> insightspike.config.models.InsightSpikeConfig",
        "docstring": "Get current configuration or load defaults",
        "full_name": "insightspike.config.loader.get_config",
        "tags": []
      },
      {
        "name": "load_config",
        "module": "insightspike.config.loader",
        "type": "function",
        "signature": "(config_path: Union[str, pathlib._local.Path, NoneType] = None, preset: Optional[str] = None, overrides: Optional[Dict[str, Any]] = None) -> insightspike.config.models.InsightSpikeConfig",
        "docstring": "Load configuration using global loader",
        "full_name": "insightspike.config.loader.load_config",
        "tags": []
      },
      {
        "name": "MessagePassingConfig",
        "module": "insightspike.config.message_passing_config",
        "type": "class",
        "signature": "(*, alpha: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.3, iterations: Annotated[int, Ge(ge=1), Le(le=5)] = 2, max_hops: Annotated[int, Ge(ge=1), Le(le=3)] = 1, aggregation: Literal['weighted_mean', 'max', 'attention'] = 'weighted_mean', self_loop_weight: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.5, decay_factor: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.8, similarity_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.3, convergence_threshold: Annotated[float, Gt(gt=0.0), Le(le=0.01)] = 0.0001, enable_batch_computation: bool = True, cache_similarities: bool = True, top_k_relevance_percentile: Annotated[int, Ge(ge=50), Le(le=95)] = 75) -> None",
        "docstring": "Configuration for question-aware message passing",
        "full_name": "insightspike.config.message_passing_config.MessagePassingConfig",
        "tags": []
      },
      {
        "name": "get_default_message_passing_config",
        "module": "insightspike.config.message_passing_config",
        "type": "function",
        "signature": "() -> dict",
        "docstring": "Get default message passing configuration as dict",
        "full_name": "insightspike.config.message_passing_config.get_default_message_passing_config",
        "tags": []
      },
      {
        "name": "get_performance_optimized_config",
        "module": "insightspike.config.message_passing_config",
        "type": "function",
        "signature": "() -> dict",
        "docstring": "Get performance-optimized configuration",
        "full_name": "insightspike.config.message_passing_config.get_performance_optimized_config",
        "tags": []
      },
      {
        "name": "get_quality_optimized_config",
        "module": "insightspike.config.message_passing_config",
        "type": "function",
        "signature": "() -> dict",
        "docstring": "Get quality-optimized configuration (slower but more thorough)",
        "full_name": "insightspike.config.message_passing_config.get_quality_optimized_config",
        "tags": []
      },
      {
        "name": "DataStoreConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, type: Literal['filesystem', 'in_memory'] = 'filesystem', root_path: str = './data/insight_store', explicit_root_path: bool = False) -> None",
        "docstring": "DataStore configuration",
        "full_name": "insightspike.config.models.DataStoreConfig",
        "tags": []
      },
      {
        "name": "DefaultsAppliedMixin",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, defaults_applied: list[str] = <factory>) -> None",
        "docstring": "Mixin to record which config defaults were auto-applied at load time.",
        "full_name": "insightspike.config.models.DefaultsAppliedMixin",
        "tags": []
      },
      {
        "name": "EmbeddingConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, model_name: str = 'sentence-transformers/all-MiniLM-L6-v2', dimension: Annotated[int, Ge(ge=1)] = 384, device: str = 'cpu') -> None",
        "docstring": "Embedding configuration",
        "full_name": "insightspike.config.models.EmbeddingConfig",
        "tags": []
      },
      {
        "name": "GraphConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, spike_ged_threshold: Annotated[float, Ge(ge=-1.0), Le(le=1.0)] = -0.5, spike_ig_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.2, similarity_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.3, conflict_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.5, use_gnn: bool = False, gnn_hidden_dim: Annotated[int, Ge(ge=1)] = 64, ged_algorithm: Literal['simple', 'advanced', 'networkx', 'hybrid'] = 'advanced', ig_algorithm: Literal['simple', 'advanced', 'entropy', 'hybrid'] = 'advanced', hybrid_weights: insightspike.config.models.HybridWeightsConfig = <factory>, sp_scope_mode: Literal['auto', 'union'] = 'auto', sp_eval_mode: Literal['connected', 'fixed_before_pairs'] = 'connected', sp_hop_expand: Annotated[int, Ge(ge=0), Le(le=5)] = 0, sp_boundary_mode: Literal['induced', 'trim', 'nodes'] = 'induced', ig_source_mode: Literal['graph', 'linkset', 'hybrid', 'paper', 'strict'] = 'graph', ged_norm_scheme: Literal['edges_after', 'candidate_base'] = 'edges_after', linkset_query_weight: Annotated[float, Ge(ge=0.0), Le(le=10.0)] = 1.0, lambda_weight: Annotated[float, Ge(ge=0.0), Le(le=10.0)] = 1.0, sp_beta: Annotated[float, Ge(ge=0.0), Le(le=10.0)] = 0.2, enable_graph_search: bool = False, hop_limit: Annotated[int, Ge(ge=1), Le(le=3)] = 2, neighbor_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.4, path_decay: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.7, enable_message_passing: bool = False, message_passing: Optional[Dict[str, Any]] = None, weight_ged: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.5, weight_ig: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.5, temperature: Annotated[float, Ge(ge=0.1), Le(le=10.0)] = 1.0, structural_similarity: insightspike.config.models.StructuralSimilarityConfig = <factory>) -> None",
        "docstring": "Graph processing & spike detection",
        "full_name": "insightspike.config.models.GraphConfig",
        "tags": []
      },
      {
        "name": "HybridWeightsConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, structure: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.4, semantic: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.4, quality: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.2) -> None",
        "docstring": "Hybrid algorithm weights (v1/v2 compatible)",
        "full_name": "insightspike.config.models.HybridWeightsConfig",
        "tags": []
      },
      {
        "name": "InsightSpikeConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, environment: Literal['development', 'experiment', 'production', 'research', 'test', 'testing', 'custom'] = 'development', pre_warm_models: bool = True, llm: insightspike.config.models.LLMConfig = <factory>, embedding: insightspike.config.models.EmbeddingConfig = <factory>, memory: insightspike.config.models.MemoryConfig = <factory>, graph: insightspike.config.models.GraphConfig = <factory>, monitoring: insightspike.config.models.MonitoringConfig = <factory>, logging: insightspike.config.models.LoggingConfig = <factory>, paths: insightspike.config.models.PathsConfig = <factory>, processing: insightspike.config.models.ProcessingConfig = <factory>, output: insightspike.config.models.OutputConfig = <factory>, datastore: insightspike.config.models.DataStoreConfig = <factory>, metrics: insightspike.config.models.MetricsConfig = <factory>, reasoning: insightspike.config.models.ReasoningConfig = <factory>, performance: insightspike.config.models.PerformanceConfig = <factory>, vector_search: insightspike.config.models.VectorSearchConfig = <factory>, wake_sleep: insightspike.config.wake_sleep_config.WakeSleepConfig = <factory>) -> None",
        "docstring": "Complete InsightSpike configuration - clean structure without backward compatibility",
        "full_name": "insightspike.config.models.InsightSpikeConfig",
        "tags": []
      },
      {
        "name": "LLMConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, provider: Literal['local', 'openai', 'anthropic', 'ollama', 'mock'] = 'local', model: str = 'distilgpt2', max_tokens: Annotated[int, Ge(ge=1), Le(le=4096)] = 256, temperature: Annotated[float, Ge(ge=0.0), Le(le=2.0)] = 0.3, top_p: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.9, timeout: Annotated[int, Ge(ge=1)] = 30, api_key: Optional[str] = None, api_base: Optional[str] = None, organization: Optional[str] = None, device: str = 'cpu', load_in_8bit: bool = False, system_prompt: Optional[str] = None, prompt_style: Literal['standard', 'detailed', 'minimal', 'association', 'association_extended'] = 'standard', max_context_docs: Annotated[int, Ge(ge=1), Le(le=20)] = 5, use_simple_prompt: bool = False, include_metadata: bool = False, branching_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.8, branching_min_branches: Annotated[int, Ge(ge=2), Le(le=10)] = 2, branching_max_gap: Annotated[float, Ge(ge=0.0), Le(le=0.5)] = 0.15) -> None",
        "docstring": "Language Model configuration",
        "full_name": "insightspike.config.models.LLMConfig",
        "tags": []
      },
      {
        "name": "LoggingConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, level: Literal['DEBUG', 'INFO', 'WARNING', 'ERROR'] = 'INFO', file_path: str = '/Users/miyauchikazuyoshi/.insightspike/logs', log_to_console: bool = False, max_size_mb: int = 50, backup_count: int = 3) -> None",
        "docstring": "Logging configuration",
        "full_name": "insightspike.config.models.LoggingConfig",
        "tags": []
      },
      {
        "name": "MazeConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, size: tuple[int, int] = (20, 20), maze_type: Literal['simple', 'complex', 'random'] = 'simple', max_steps: int = 1000, num_episodes: int = 100, render_mode: Optional[Literal['ascii', 'matplotlib', 'none']] = 'ascii', render_frequency: int = 10, save_animations: bool = True) -> None",
        "docstring": "Configuration for maze environment.",
        "full_name": "insightspike.config.models.MazeConfig",
        "tags": []
      },
      {
        "name": "MazeExperimentConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, maze: insightspike.maze_experimental.maze_config.MazeConfig = <factory>, navigator: insightspike.maze_experimental.maze_config.MazeNavigatorConfig = <factory>, experiment_name: str = 'maze_gediq', algorithms: list[str] = ['random', 'dfs', 'astar', 'gediq'], log_metrics: bool = True, save_checkpoints: bool = True, checkpoint_interval: int = 20, seed: Optional[int] = 42) -> None",
        "docstring": "Full configuration for maze experiments.",
        "full_name": "insightspike.config.models.MazeExperimentConfig",
        "tags": []
      },
      {
        "name": "MazeNavigatorConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, node_creation_cost: float = 0.0, search_radius: float = 5.0, donut_inner_radius: float = 0.0, donut_outer_radius: float = 3.0, exploration_epsilon: float = 0.1, wall_penalty: float = 0.0, unknown_bonus: float = 0.0, w_ged: float = 1.0, k_ig: float = 2.0, temperature: float = 1.0, ged_weight: float = 1.0, ig_weight: float = 2.0, sleep_interval: int = 10, sleep_optimization_steps: int = 50, feature_dim: int = 16, use_pretrained_embedder: bool = False, use_refactored_gedig: bool = True, enable_dual_evaluate: bool = False, dual_delta_threshold: float = 0.3, structural_improvement_weight: float = 0.5, spike_outcome_mode: str = 'mirror', tau_s: float = 0.15, tau_i: float = 0.25, spike_detection_mode: str = 'and') -> None",
        "docstring": "Configuration for maze navigation with geDIG.",
        "full_name": "insightspike.config.models.MazeNavigatorConfig",
        "tags": []
      },
      {
        "name": "MemoryConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, max_retrieved_docs: Annotated[int, Ge(ge=1)] = 15, short_term_capacity: Annotated[int, Ge(ge=1)] = 10, working_memory_capacity: Annotated[int, Ge(ge=1)] = 20, episodic_memory_capacity: Annotated[int, Ge(ge=1)] = 60, pattern_cache_capacity: Annotated[int, Ge(ge=1)] = 15, faiss_index_type: str = 'FlatL2', metric: str = 'l2', similarity_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.3, use_c_values: bool = True, use_graph_integration: bool = False, use_scalable_indexing: bool = True, batch_size: Annotated[int, Ge(ge=1)] = 32, cache_embeddings: bool = True, vector_search_backend: str = 'auto', defaults_applied: list[str] = <factory>) -> None",
        "docstring": "Memory system configuration",
        "full_name": "insightspike.config.models.MemoryConfig",
        "tags": []
      },
      {
        "name": "MetricsConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, use_normalized_ged: bool = True, use_entropy_variance_ig: bool = False, use_multihop_gedig: bool = False, query_centric: bool = True, query_topk_centers: Annotated[int, Ge(ge=1), Le(le=50)] = 3, query_radius: Annotated[int, Ge(ge=0), Le(le=5)] = 1, spectral_evaluation: insightspike.config.models.SpectralEvaluationConfig = <factory>, multihop_config: insightspike.config.models.MultihopConfig = <factory>, theta_cand: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.45, theta_link: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.35, candidate_cap: Annotated[int, Ge(ge=1), Le(le=1024)] = 32, top_m: Optional[int] = None, ig_denominator: Literal['legacy', 'fixed_kstar'] = 'fixed_kstar', use_local_normalization: bool = False) -> None",
        "docstring": "Advanced metrics configuration",
        "full_name": "insightspike.config.models.MetricsConfig",
        "tags": []
      },
      {
        "name": "MonitoringConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, enabled: bool = False, performance_tracking: bool = False, detailed_tracing: bool = False, metrics_port: int = 9090) -> None",
        "docstring": "Monitoring configuration",
        "full_name": "insightspike.config.models.MonitoringConfig",
        "tags": []
      },
      {
        "name": "MultihopConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, max_hops: Annotated[int, Ge(ge=1), Le(le=10)] = 3, decay_factor: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.5) -> None",
        "docstring": "Multi-hop analysis configuration",
        "full_name": "insightspike.config.models.MultihopConfig",
        "tags": []
      },
      {
        "name": "OutputConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, format: Literal['json', 'markdown', 'html'] = 'json', include_reasoning: bool = True, include_sources: bool = True, max_sources: Annotated[int, Ge(ge=1)] = 5, max_context_length: Annotated[int, Ge(ge=100)] = 2000, max_documents: Annotated[int, Ge(ge=1)] = 10, include_metadata: bool = True) -> None",
        "docstring": "Output configuration",
        "full_name": "insightspike.config.models.OutputConfig",
        "tags": []
      },
      {
        "name": "PathsConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, data_dir: pathlib._local.Path = PosixPath('data'), raw_dir: pathlib._local.Path = PosixPath('data/raw'), processed_dir: pathlib._local.Path = PosixPath('data/processed'), embeddings_dir: pathlib._local.Path = PosixPath('data/embeddings'), cache_dir: pathlib._local.Path = PosixPath('data/cache'), models_dir: pathlib._local.Path = PosixPath('data/models'), logs_dir: pathlib._local.Path = '~/.insightspike/logs') -> None",
        "docstring": "File system paths (with home expansion compatible across pydantic versions)",
        "full_name": "insightspike.config.models.PathsConfig",
        "tags": []
      },
      {
        "name": "PerformanceConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, enable_cache: bool = True, parallel_workers: Annotated[int, Ge(ge=1), Le(le=32)] = 4) -> None",
        "docstring": "Performance optimization configuration",
        "full_name": "insightspike.config.models.PerformanceConfig",
        "tags": []
      },
      {
        "name": "ProcessingConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, batch_size: Annotated[int, Ge(ge=1)] = 32, max_workers: Annotated[int, Ge(ge=1)] = 4, chunk_size: Annotated[int, Ge(ge=50)] = 500, overlap: Annotated[int, Ge(ge=0)] = 50, min_chunk_size: Annotated[int, Ge(ge=10)] = 100, max_cycles: Annotated[int, Ge(ge=1)] = 10, convergence_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.8, min_quality_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.7, use_advanced_metrics: bool = True, enable_layer1_bypass: bool = False, bypass_uncertainty_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.2, bypass_known_ratio_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.9, enable_insight_registration: bool = True, enable_insight_search: bool = True, max_insights_per_query: Annotated[int, Ge(ge=0), Le(le=20)] = 5, dynamic_doc_adjustment: bool = True, max_docs_with_insights: Annotated[int, Ge(ge=1), Le(le=20)] = 5, insight_relevance_boost: Annotated[float, Ge(ge=0.0), Le(le=0.5)] = 0.2, enable_learning: bool = False, learning_rate: Annotated[float, Ge(ge=0.01), Le(le=0.5)] = 0.1, exploration_rate: Annotated[float, Ge(ge=0.01), Le(le=0.3)] = 0.1) -> None",
        "docstring": "Processing configuration",
        "full_name": "insightspike.config.models.ProcessingConfig",
        "tags": []
      },
      {
        "name": "ReasoningConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, max_cycles: Annotated[int, Ge(ge=1), Le(le=100)] = 10, convergence_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.8, spike_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.7) -> None",
        "docstring": "Reasoning engine configuration",
        "full_name": "insightspike.config.models.ReasoningConfig",
        "tags": []
      },
      {
        "name": "SpectralEvaluationConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, enabled: bool = False, weight: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.3) -> None",
        "docstring": "Spectral evaluation configuration",
        "full_name": "insightspike.config.models.SpectralEvaluationConfig",
        "tags": []
      },
      {
        "name": "StructuralSimilarityConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, enabled: bool = False, method: Literal['signature', 'spectral', 'wl_kernel', 'motif'] = 'signature', max_signature_hops: Annotated[int, Ge(ge=1), Le(le=5)] = 3, include_triangles: bool = True, include_clustering: bool = True, include_density: bool = True, spectral_k: Annotated[int, Ge(ge=1), Le(le=50)] = 10, wl_iterations: Annotated[int, Ge(ge=1), Le(le=10)] = 5, analogy_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.7, analogy_weight: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.3, cross_domain_only: bool = True, domain_attribute: str = 'domain') -> None",
        "docstring": "Structural similarity evaluation for analogy detection.",
        "full_name": "insightspike.config.models.StructuralSimilarityConfig",
        "tags": []
      },
      {
        "name": "VectorSearchConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, backend: Literal['auto', 'numpy', 'faiss'] = 'auto', optimize: bool = True, batch_size: Annotated[int, Ge(ge=1)] = 1000) -> None",
        "docstring": "Vector search backend configuration",
        "full_name": "insightspike.config.models.VectorSearchConfig",
        "tags": []
      },
      {
        "name": "WakeSleepConfig",
        "module": "insightspike.config.models",
        "type": "class",
        "signature": "(*, mode: Literal['wake', 'sleep', 'auto'] = 'wake', wake: insightspike.config.wake_sleep_config.WakeModeConfig = <factory>, sleep: insightspike.config.wake_sleep_config.SleepModeConfig = <factory>, wake_duration: Annotated[int, Ge(ge=1)] = 100, sleep_duration: Annotated[int, Ge(ge=1)] = 20, switch_on_low_performance: bool = True, performance_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.5) -> None",
        "docstring": "Complete wake-sleep cycle configuration.",
        "full_name": "insightspike.config.models.WakeSleepConfig",
        "tags": []
      },
      {
        "name": "InsightSpikeConfig",
        "module": "insightspike.config.normalized",
        "type": "class",
        "signature": "(*, environment: Literal['development', 'experiment', 'production', 'research', 'test', 'testing', 'custom'] = 'development', pre_warm_models: bool = True, llm: insightspike.config.models.LLMConfig = <factory>, embedding: insightspike.config.models.EmbeddingConfig = <factory>, memory: insightspike.config.models.MemoryConfig = <factory>, graph: insightspike.config.models.GraphConfig = <factory>, monitoring: insightspike.config.models.MonitoringConfig = <factory>, logging: insightspike.config.models.LoggingConfig = <factory>, paths: insightspike.config.models.PathsConfig = <factory>, processing: insightspike.config.models.ProcessingConfig = <factory>, output: insightspike.config.models.OutputConfig = <factory>, datastore: insightspike.config.models.DataStoreConfig = <factory>, metrics: insightspike.config.models.MetricsConfig = <factory>, reasoning: insightspike.config.models.ReasoningConfig = <factory>, performance: insightspike.config.models.PerformanceConfig = <factory>, vector_search: insightspike.config.models.VectorSearchConfig = <factory>, wake_sleep: insightspike.config.wake_sleep_config.WakeSleepConfig = <factory>) -> None",
        "docstring": "Complete InsightSpike configuration - clean structure without backward compatibility",
        "full_name": "insightspike.config.normalized.InsightSpikeConfig",
        "tags": []
      },
      {
        "name": "NormalizedConfig",
        "module": "insightspike.config.normalized",
        "type": "class",
        "signature": "(embedding_model: 'str', embedding_dim: 'int', enable_layer1_bypass: 'bool', bypass_uncertainty_threshold: 'float', bypass_known_ratio_threshold: 'float', enable_learning: 'bool', graph_weight_ged: 'float', graph_weight_ig: 'float', environment: 'str', gedig_mode: 'str' = 'full', max_retrieved_docs: 'int' = 10, dynamic_doc_adjustment: 'bool' = True, max_docs_with_insights: 'int' = 5, insight_relevance_boost: 'float' = 0.2, enable_insight_search: 'bool' = True, max_insights_per_query: 'int' = 5, enable_graph_search: 'bool' = False, enable_insight_registration: 'bool' = True, similarity_threshold: 'float' = 0.3, hop_limit: 'int' = 2, path_decay: 'float' = 0.7, spike_ged_threshold: 'float' = -0.5, spike_ig_threshold: 'float' = 0.2, episode_merge_threshold: 'float' = 0.8, episode_split_threshold: 'float' = 0.3, episode_prune_threshold: 'float' = 0.1, theta_cand: 'float' = 0.45, theta_link: 'float' = 0.35, candidate_cap: 'int' = 32, top_m: 'Optional[int]' = None, ig_denominator: 'str' = 'fixed_kstar', use_local_normalization: 'bool' = False, sp_engine: 'str' = 'core', norm_spec: 'Optional[Dict[str, Any]]' = None, source_type: 'str' = 'unknown', applied_defaults: 'tuple[str, ...]' = <factory>, _raw: 'Any' = None) -> None",
        "docstring": "NormalizedConfig(embedding_model: 'str', embedding_dim: 'int', enable_layer1_bypass: 'bool', bypass_uncertainty_threshold: 'float', bypass_known_ratio_threshold: 'float', enable_learning: 'bool', graph_weight_ged: 'float', graph_weight_ig: 'float', environment: 'str', gedig_mode: 'str' = 'full', max_retrieved_docs: 'int' = 10, dynamic_doc_adjustment: 'bool' = True, max_docs_with_insights: 'int' = 5, insight_relevance_boost: 'float' = 0.2, enable_insight_search: 'bool' = True, max_insights_per_query: 'int' = 5, enable_graph_search: 'bool' = False, enable_insight_registration: 'bool' = True, similarity_threshold: 'float' = 0.3, hop_limit: 'int' = 2, path_decay: 'float' = 0.7, spike_ged_threshold: 'float' = -0.5, spike_ig_threshold: 'float' = 0.2, episode_merge_threshold: 'float' = 0.8, episode_split_threshold: 'float' = 0.3, episode_prune_threshold: 'float' = 0.1, theta_cand: 'float' = 0.45, theta_link: 'float' = 0.35, candidate_cap: 'int' = 32, top_m: 'Optional[int]' = None, ig_denominator: 'str' = 'fixed_kstar', use_local_normalization: 'bool' = False, sp_engine: 'str' = 'core', norm_spec: 'Optional[Dict[str, Any]]' = None, source_type: 'str' = 'unknown', applied_defaults: 'tuple[str, ...]' = <factory>, _raw: 'Any' = None)",
        "full_name": "insightspike.config.normalized.NormalizedConfig",
        "tags": []
      },
      {
        "name": "ConfigNormalizer",
        "module": "insightspike.config.normalizer",
        "type": "class",
        "signature": "()",
        "docstring": "Normalizes various configuration formats to standard Pydantic models.",
        "full_name": "insightspike.config.normalizer.ConfigNormalizer",
        "tags": []
      },
      {
        "name": "EmbeddingConfig",
        "module": "insightspike.config.normalizer",
        "type": "class",
        "signature": "(*, model_name: str = 'sentence-transformers/all-MiniLM-L6-v2', dimension: Annotated[int, Ge(ge=1)] = 384, device: str = 'cpu') -> None",
        "docstring": "Embedding configuration",
        "full_name": "insightspike.config.normalizer.EmbeddingConfig",
        "tags": []
      },
      {
        "name": "GraphConfig",
        "module": "insightspike.config.normalizer",
        "type": "class",
        "signature": "(*, spike_ged_threshold: Annotated[float, Ge(ge=-1.0), Le(le=1.0)] = -0.5, spike_ig_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.2, similarity_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.3, conflict_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.5, use_gnn: bool = False, gnn_hidden_dim: Annotated[int, Ge(ge=1)] = 64, ged_algorithm: Literal['simple', 'advanced', 'networkx', 'hybrid'] = 'advanced', ig_algorithm: Literal['simple', 'advanced', 'entropy', 'hybrid'] = 'advanced', hybrid_weights: insightspike.config.models.HybridWeightsConfig = <factory>, sp_scope_mode: Literal['auto', 'union'] = 'auto', sp_eval_mode: Literal['connected', 'fixed_before_pairs'] = 'connected', sp_hop_expand: Annotated[int, Ge(ge=0), Le(le=5)] = 0, sp_boundary_mode: Literal['induced', 'trim', 'nodes'] = 'induced', ig_source_mode: Literal['graph', 'linkset', 'hybrid', 'paper', 'strict'] = 'graph', ged_norm_scheme: Literal['edges_after', 'candidate_base'] = 'edges_after', linkset_query_weight: Annotated[float, Ge(ge=0.0), Le(le=10.0)] = 1.0, lambda_weight: Annotated[float, Ge(ge=0.0), Le(le=10.0)] = 1.0, sp_beta: Annotated[float, Ge(ge=0.0), Le(le=10.0)] = 0.2, enable_graph_search: bool = False, hop_limit: Annotated[int, Ge(ge=1), Le(le=3)] = 2, neighbor_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.4, path_decay: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.7, enable_message_passing: bool = False, message_passing: Optional[Dict[str, Any]] = None, weight_ged: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.5, weight_ig: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.5, temperature: Annotated[float, Ge(ge=0.1), Le(le=10.0)] = 1.0, structural_similarity: insightspike.config.models.StructuralSimilarityConfig = <factory>) -> None",
        "docstring": "Graph processing & spike detection",
        "full_name": "insightspike.config.normalizer.GraphConfig",
        "tags": []
      },
      {
        "name": "InsightSpikeConfig",
        "module": "insightspike.config.normalizer",
        "type": "class",
        "signature": "(*, environment: Literal['development', 'experiment', 'production', 'research', 'test', 'testing', 'custom'] = 'development', pre_warm_models: bool = True, llm: insightspike.config.models.LLMConfig = <factory>, embedding: insightspike.config.models.EmbeddingConfig = <factory>, memory: insightspike.config.models.MemoryConfig = <factory>, graph: insightspike.config.models.GraphConfig = <factory>, monitoring: insightspike.config.models.MonitoringConfig = <factory>, logging: insightspike.config.models.LoggingConfig = <factory>, paths: insightspike.config.models.PathsConfig = <factory>, processing: insightspike.config.models.ProcessingConfig = <factory>, output: insightspike.config.models.OutputConfig = <factory>, datastore: insightspike.config.models.DataStoreConfig = <factory>, metrics: insightspike.config.models.MetricsConfig = <factory>, reasoning: insightspike.config.models.ReasoningConfig = <factory>, performance: insightspike.config.models.PerformanceConfig = <factory>, vector_search: insightspike.config.models.VectorSearchConfig = <factory>, wake_sleep: insightspike.config.wake_sleep_config.WakeSleepConfig = <factory>) -> None",
        "docstring": "Complete InsightSpike configuration - clean structure without backward compatibility",
        "full_name": "insightspike.config.normalizer.InsightSpikeConfig",
        "tags": []
      },
      {
        "name": "LLMConfig",
        "module": "insightspike.config.normalizer",
        "type": "class",
        "signature": "(*, provider: Literal['local', 'openai', 'anthropic', 'ollama', 'mock'] = 'local', model: str = 'distilgpt2', max_tokens: Annotated[int, Ge(ge=1), Le(le=4096)] = 256, temperature: Annotated[float, Ge(ge=0.0), Le(le=2.0)] = 0.3, top_p: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.9, timeout: Annotated[int, Ge(ge=1)] = 30, api_key: Optional[str] = None, api_base: Optional[str] = None, organization: Optional[str] = None, device: str = 'cpu', load_in_8bit: bool = False, system_prompt: Optional[str] = None, prompt_style: Literal['standard', 'detailed', 'minimal', 'association', 'association_extended'] = 'standard', max_context_docs: Annotated[int, Ge(ge=1), Le(le=20)] = 5, use_simple_prompt: bool = False, include_metadata: bool = False, branching_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.8, branching_min_branches: Annotated[int, Ge(ge=2), Le(le=10)] = 2, branching_max_gap: Annotated[float, Ge(ge=0.0), Le(le=0.5)] = 0.15) -> None",
        "docstring": "Language Model configuration",
        "full_name": "insightspike.config.normalizer.LLMConfig",
        "tags": []
      },
      {
        "name": "MemoryConfig",
        "module": "insightspike.config.normalizer",
        "type": "class",
        "signature": "(*, max_retrieved_docs: Annotated[int, Ge(ge=1)] = 15, short_term_capacity: Annotated[int, Ge(ge=1)] = 10, working_memory_capacity: Annotated[int, Ge(ge=1)] = 20, episodic_memory_capacity: Annotated[int, Ge(ge=1)] = 60, pattern_cache_capacity: Annotated[int, Ge(ge=1)] = 15, faiss_index_type: str = 'FlatL2', metric: str = 'l2', similarity_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.3, use_c_values: bool = True, use_graph_integration: bool = False, use_scalable_indexing: bool = True, batch_size: Annotated[int, Ge(ge=1)] = 32, cache_embeddings: bool = True, vector_search_backend: str = 'auto', defaults_applied: list[str] = <factory>) -> None",
        "docstring": "Memory system configuration",
        "full_name": "insightspike.config.normalizer.MemoryConfig",
        "tags": []
      },
      {
        "name": "ProcessingConfig",
        "module": "insightspike.config.normalizer",
        "type": "class",
        "signature": "(*, batch_size: Annotated[int, Ge(ge=1)] = 32, max_workers: Annotated[int, Ge(ge=1)] = 4, chunk_size: Annotated[int, Ge(ge=50)] = 500, overlap: Annotated[int, Ge(ge=0)] = 50, min_chunk_size: Annotated[int, Ge(ge=10)] = 100, max_cycles: Annotated[int, Ge(ge=1)] = 10, convergence_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.8, min_quality_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.7, use_advanced_metrics: bool = True, enable_layer1_bypass: bool = False, bypass_uncertainty_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.2, bypass_known_ratio_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.9, enable_insight_registration: bool = True, enable_insight_search: bool = True, max_insights_per_query: Annotated[int, Ge(ge=0), Le(le=20)] = 5, dynamic_doc_adjustment: bool = True, max_docs_with_insights: Annotated[int, Ge(ge=1), Le(le=20)] = 5, insight_relevance_boost: Annotated[float, Ge(ge=0.0), Le(le=0.5)] = 0.2, enable_learning: bool = False, learning_rate: Annotated[float, Ge(ge=0.01), Le(le=0.5)] = 0.1, exploration_rate: Annotated[float, Ge(ge=0.01), Le(le=0.3)] = 0.1) -> None",
        "docstring": "Processing configuration",
        "full_name": "insightspike.config.normalizer.ProcessingConfig",
        "tags": []
      },
      {
        "name": "ConfigPresets",
        "module": "insightspike.config.presets",
        "type": "class",
        "signature": "()",
        "docstring": "Configuration presets for different environments and use cases",
        "full_name": "insightspike.config.presets.ConfigPresets",
        "tags": []
      },
      {
        "name": "EmbeddingConfig",
        "module": "insightspike.config.presets",
        "type": "class",
        "signature": "(*, model_name: str = 'sentence-transformers/all-MiniLM-L6-v2', dimension: Annotated[int, Ge(ge=1)] = 384, device: str = 'cpu') -> None",
        "docstring": "Embedding configuration",
        "full_name": "insightspike.config.presets.EmbeddingConfig",
        "tags": []
      },
      {
        "name": "GraphConfig",
        "module": "insightspike.config.presets",
        "type": "class",
        "signature": "(*, spike_ged_threshold: Annotated[float, Ge(ge=-1.0), Le(le=1.0)] = -0.5, spike_ig_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.2, similarity_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.3, conflict_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.5, use_gnn: bool = False, gnn_hidden_dim: Annotated[int, Ge(ge=1)] = 64, ged_algorithm: Literal['simple', 'advanced', 'networkx', 'hybrid'] = 'advanced', ig_algorithm: Literal['simple', 'advanced', 'entropy', 'hybrid'] = 'advanced', hybrid_weights: insightspike.config.models.HybridWeightsConfig = <factory>, sp_scope_mode: Literal['auto', 'union'] = 'auto', sp_eval_mode: Literal['connected', 'fixed_before_pairs'] = 'connected', sp_hop_expand: Annotated[int, Ge(ge=0), Le(le=5)] = 0, sp_boundary_mode: Literal['induced', 'trim', 'nodes'] = 'induced', ig_source_mode: Literal['graph', 'linkset', 'hybrid', 'paper', 'strict'] = 'graph', ged_norm_scheme: Literal['edges_after', 'candidate_base'] = 'edges_after', linkset_query_weight: Annotated[float, Ge(ge=0.0), Le(le=10.0)] = 1.0, lambda_weight: Annotated[float, Ge(ge=0.0), Le(le=10.0)] = 1.0, sp_beta: Annotated[float, Ge(ge=0.0), Le(le=10.0)] = 0.2, enable_graph_search: bool = False, hop_limit: Annotated[int, Ge(ge=1), Le(le=3)] = 2, neighbor_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.4, path_decay: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.7, enable_message_passing: bool = False, message_passing: Optional[Dict[str, Any]] = None, weight_ged: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.5, weight_ig: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.5, temperature: Annotated[float, Ge(ge=0.1), Le(le=10.0)] = 1.0, structural_similarity: insightspike.config.models.StructuralSimilarityConfig = <factory>) -> None",
        "docstring": "Graph processing & spike detection",
        "full_name": "insightspike.config.presets.GraphConfig",
        "tags": []
      },
      {
        "name": "InsightSpikeConfig",
        "module": "insightspike.config.presets",
        "type": "class",
        "signature": "(*, environment: Literal['development', 'experiment', 'production', 'research', 'test', 'testing', 'custom'] = 'development', pre_warm_models: bool = True, llm: insightspike.config.models.LLMConfig = <factory>, embedding: insightspike.config.models.EmbeddingConfig = <factory>, memory: insightspike.config.models.MemoryConfig = <factory>, graph: insightspike.config.models.GraphConfig = <factory>, monitoring: insightspike.config.models.MonitoringConfig = <factory>, logging: insightspike.config.models.LoggingConfig = <factory>, paths: insightspike.config.models.PathsConfig = <factory>, processing: insightspike.config.models.ProcessingConfig = <factory>, output: insightspike.config.models.OutputConfig = <factory>, datastore: insightspike.config.models.DataStoreConfig = <factory>, metrics: insightspike.config.models.MetricsConfig = <factory>, reasoning: insightspike.config.models.ReasoningConfig = <factory>, performance: insightspike.config.models.PerformanceConfig = <factory>, vector_search: insightspike.config.models.VectorSearchConfig = <factory>, wake_sleep: insightspike.config.wake_sleep_config.WakeSleepConfig = <factory>) -> None",
        "docstring": "Complete InsightSpike configuration - clean structure without backward compatibility",
        "full_name": "insightspike.config.presets.InsightSpikeConfig",
        "tags": []
      },
      {
        "name": "LLMConfig",
        "module": "insightspike.config.presets",
        "type": "class",
        "signature": "(*, provider: Literal['local', 'openai', 'anthropic', 'ollama', 'mock'] = 'local', model: str = 'distilgpt2', max_tokens: Annotated[int, Ge(ge=1), Le(le=4096)] = 256, temperature: Annotated[float, Ge(ge=0.0), Le(le=2.0)] = 0.3, top_p: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.9, timeout: Annotated[int, Ge(ge=1)] = 30, api_key: Optional[str] = None, api_base: Optional[str] = None, organization: Optional[str] = None, device: str = 'cpu', load_in_8bit: bool = False, system_prompt: Optional[str] = None, prompt_style: Literal['standard', 'detailed', 'minimal', 'association', 'association_extended'] = 'standard', max_context_docs: Annotated[int, Ge(ge=1), Le(le=20)] = 5, use_simple_prompt: bool = False, include_metadata: bool = False, branching_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.8, branching_min_branches: Annotated[int, Ge(ge=2), Le(le=10)] = 2, branching_max_gap: Annotated[float, Ge(ge=0.0), Le(le=0.5)] = 0.15) -> None",
        "docstring": "Language Model configuration",
        "full_name": "insightspike.config.presets.LLMConfig",
        "tags": []
      },
      {
        "name": "LoggingConfig",
        "module": "insightspike.config.presets",
        "type": "class",
        "signature": "(*, level: Literal['DEBUG', 'INFO', 'WARNING', 'ERROR'] = 'INFO', file_path: str = '/Users/miyauchikazuyoshi/.insightspike/logs', log_to_console: bool = False, max_size_mb: int = 50, backup_count: int = 3) -> None",
        "docstring": "Logging configuration",
        "full_name": "insightspike.config.presets.LoggingConfig",
        "tags": []
      },
      {
        "name": "MemoryConfig",
        "module": "insightspike.config.presets",
        "type": "class",
        "signature": "(*, max_retrieved_docs: Annotated[int, Ge(ge=1)] = 15, short_term_capacity: Annotated[int, Ge(ge=1)] = 10, working_memory_capacity: Annotated[int, Ge(ge=1)] = 20, episodic_memory_capacity: Annotated[int, Ge(ge=1)] = 60, pattern_cache_capacity: Annotated[int, Ge(ge=1)] = 15, faiss_index_type: str = 'FlatL2', metric: str = 'l2', similarity_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.3, use_c_values: bool = True, use_graph_integration: bool = False, use_scalable_indexing: bool = True, batch_size: Annotated[int, Ge(ge=1)] = 32, cache_embeddings: bool = True, vector_search_backend: str = 'auto', defaults_applied: list[str] = <factory>) -> None",
        "docstring": "Memory system configuration",
        "full_name": "insightspike.config.presets.MemoryConfig",
        "tags": []
      },
      {
        "name": "MonitoringConfig",
        "module": "insightspike.config.presets",
        "type": "class",
        "signature": "(*, enabled: bool = False, performance_tracking: bool = False, detailed_tracing: bool = False, metrics_port: int = 9090) -> None",
        "docstring": "Monitoring configuration",
        "full_name": "insightspike.config.presets.MonitoringConfig",
        "tags": []
      },
      {
        "name": "summarize_config",
        "module": "insightspike.config.summary",
        "type": "function",
        "signature": "(config: 'Any') -> 'Dict[str, Any]'",
        "docstring": "High-level summary for an InsightSpikeConfig or legacy wrapper.",
        "full_name": "insightspike.config.summary.summarize_config",
        "tags": []
      },
      {
        "name": "summarize_memory_config",
        "module": "insightspike.config.summary",
        "type": "function",
        "signature": "(mem_cfg: 'Any') -> 'Dict[str, Any]'",
        "docstring": "Return a dict summary of memory config including defaults_applied.",
        "full_name": "insightspike.config.summary.summarize_memory_config",
        "tags": []
      },
      {
        "name": "VectorWeightConfig",
        "module": "insightspike.config.vector_weights",
        "type": "class",
        "signature": "(*, enabled: bool = False, weights: Optional[List[float]] = None, presets: Dict[str, Optional[List[float]]] = <factory>, active_preset: Optional[str] = None) -> None",
        "docstring": "Simple vector weight configuration.",
        "full_name": "insightspike.config.vector_weights.VectorWeightConfig",
        "tags": []
      },
      {
        "name": "SleepModeConfig",
        "module": "insightspike.config.wake_sleep_config",
        "type": "class",
        "signature": "(*, objective: Literal['maximize_reward', 'minimize_cost'] = 'maximize_reward', contradiction_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.8, merge_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.9, prune_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.1, lambda_weight: Annotated[float, Ge(ge=0)] = 1.0, mu_weight: Annotated[float, Ge(ge=0)] = 0.5) -> None",
        "docstring": "Configuration for sleep mode (consolidation).",
        "full_name": "insightspike.config.wake_sleep_config.SleepModeConfig",
        "tags": []
      },
      {
        "name": "SphereSearchConfig",
        "module": "insightspike.config.wake_sleep_config",
        "type": "class",
        "signature": "(*, method: Literal['cosine', 'sphere', 'donut'] = 'sphere', radius: Annotated[float, Ge(ge=0.1), Le(le=2.0)] = 0.995, intuitive_radius: Annotated[float, Ge(ge=0.1), Le(le=1.0)] = 0.5, inner_radius: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.2, intuitive_inner_radius: Annotated[float, Ge(ge=0.0), Le(le=0.5)] = 0.2, intuitive_outer_radius: Annotated[float, Ge(ge=0.2), Le(le=1.0)] = 0.6, max_neighbors: Annotated[int, Ge(ge=1), Le(le=100)] = 20, use_faiss: bool = True, use_dimension_aware_scaling: bool = True) -> None",
        "docstring": "Configuration for sphere/donut search in wake mode.",
        "full_name": "insightspike.config.wake_sleep_config.SphereSearchConfig",
        "tags": []
      },
      {
        "name": "WakeModeConfig",
        "module": "insightspike.config.wake_sleep_config",
        "type": "class",
        "signature": "(*, objective: Literal['minimize_cost', 'maximize_reward'] = 'minimize_cost', search: insightspike.config.wake_sleep_config.SphereSearchConfig = <factory>, node_cost: Annotated[float, Ge(ge=0)] = 1.0, edge_cost: Annotated[float, Ge(ge=0)] = 0.5, combination_search_method: Literal['exhaustive', 'beam', 'greedy'] = 'beam', beam_width: Annotated[int, Ge(ge=1), Le(le=20)] = 5) -> None",
        "docstring": "Configuration for wake mode (query processing).",
        "full_name": "insightspike.config.wake_sleep_config.WakeModeConfig",
        "tags": []
      },
      {
        "name": "WakeSleepConfig",
        "module": "insightspike.config.wake_sleep_config",
        "type": "class",
        "signature": "(*, mode: Literal['wake', 'sleep', 'auto'] = 'wake', wake: insightspike.config.wake_sleep_config.WakeModeConfig = <factory>, sleep: insightspike.config.wake_sleep_config.SleepModeConfig = <factory>, wake_duration: Annotated[int, Ge(ge=1)] = 100, sleep_duration: Annotated[int, Ge(ge=1)] = 20, switch_on_low_performance: bool = True, performance_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.5) -> None",
        "docstring": "Complete wake-sleep cycle configuration.",
        "full_name": "insightspike.config.wake_sleep_config.WakeSleepConfig",
        "tags": []
      },
      {
        "name": "CycleResult",
        "module": "insightspike.core",
        "type": "class",
        "signature": "(response: str, reasoning_trace: str, memory_used: List[Dict[str, Any]], spike_detected: bool, graph_metrics: Dict[str, float], reasoning_quality: float, convergence_score: float, has_spike: bool) -> None",
        "docstring": "Result from a single reasoning cycle.",
        "full_name": "insightspike.core.CycleResult",
        "tags": []
      },
      {
        "name": "Episode",
        "module": "insightspike.core",
        "type": "class",
        "signature": "(text: str, vec: numpy.ndarray, c: float = 0.5, timestamp: float = <factory>, metadata: Dict[str, Any] = <factory>, episode_type: str = 'experience', selection_count: int = 0, creation_time: float = <factory>, confidence: Optional[float] = None) -> None",
        "docstring": "Single memory entry with vector embedding, text, and C-value.",
        "full_name": "insightspike.core.Episode",
        "tags": []
      },
      {
        "name": "GraphMetrics",
        "module": "insightspike.core",
        "type": "class",
        "signature": "(ged_value: float = 0.0, ig_value: float = 0.0, entropy: float = 0.0, clustering_coefficient: float = 0.0, node_count: int = 0, edge_count: int = 0) -> None",
        "docstring": "Metrics from graph analysis.",
        "full_name": "insightspike.core.GraphMetrics",
        "tags": []
      },
      {
        "name": "ActionSpace",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "(action_type: str, action_dim: int, action_bounds: Optional[Dict[str, Tuple[float, float]]] = None, discrete_actions: Optional[List[str]] = None) -> None",
        "docstring": "Generic action space definition",
        "full_name": "insightspike.core.base.ActionSpace",
        "tags": []
      },
      {
        "name": "AgentInterface",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "(agent_id: str, layers: Dict[str, insightspike.core.base.LayerInterface])",
        "docstring": "Base interface for agents that coordinate layers",
        "full_name": "insightspike.core.base.AgentInterface",
        "tags": []
      },
      {
        "name": "EnvironmentInterface",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "()",
        "docstring": "Generic environment interface for any domain",
        "full_name": "insightspike.core.base.EnvironmentInterface",
        "tags": []
      },
      {
        "name": "EnvironmentState",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "(state_data: Union[numpy.ndarray, Dict[str, Any], List, Tuple], environment_type: str, task_type: insightspike.core.base.generic_interfaces.TaskType, state_shape: Optional[Tuple[int, ...]] = None, state_bounds: Optional[Dict[str, Tuple[float, float]]] = None, step_count: int = 0, episode_count: int = 0, metadata: Optional[Dict[str, Any]] = None) -> None",
        "docstring": "Generic state representation for any environment",
        "full_name": "insightspike.core.base.EnvironmentState",
        "tags": []
      },
      {
        "name": "GenericAgentInterface",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "(agent_id: str, environment: insightspike.core.base.generic_interfaces.EnvironmentInterface, insight_detector: insightspike.core.base.generic_interfaces.InsightDetectorInterface, state_encoder: insightspike.core.base.generic_interfaces.StateEncoder, reward_normalizer: insightspike.core.base.generic_interfaces.RewardNormalizer)",
        "docstring": "Generic agent interface that can work with any environment",
        "full_name": "insightspike.core.base.GenericAgentInterface",
        "tags": []
      },
      {
        "name": "InsightDetectorInterface",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "(task_type: insightspike.core.base.generic_interfaces.TaskType, config: Optional[Dict[str, Any]] = None)",
        "docstring": "Generic interface for insight detection across domains",
        "full_name": "insightspike.core.base.InsightDetectorInterface",
        "tags": []
      },
      {
        "name": "InsightMoment",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "(episode: int, step: int, insight_type: str, description: str, dged_value: float, dig_value: float, confidence: float = 0.0, performance_impact: float = 0.0, state: Optional[insightspike.core.base.generic_interfaces.EnvironmentState] = None, action: Optional[Any] = None, reward: Optional[float] = None, detection_method: str = 'default', timestamp: Optional[float] = None, metadata: Optional[Dict[str, Any]] = None) -> None",
        "docstring": "Generic insight moment representation",
        "full_name": "insightspike.core.base.InsightMoment",
        "tags": []
      },
      {
        "name": "L1ErrorMonitorInterface",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "(layer_id: str, config: Dict[str, Any] = None)",
        "docstring": "Layer 1: Error Monitor (Cerebellum analog)",
        "full_name": "insightspike.core.base.L1ErrorMonitorInterface",
        "tags": []
      },
      {
        "name": "L2MemoryInterface",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "(layer_id: str, config: Dict[str, Any] = None)",
        "docstring": "Layer 2: Memory Manager (LC + Hippocampus analog)",
        "full_name": "insightspike.core.base.L2MemoryInterface",
        "tags": []
      },
      {
        "name": "L3GraphReasonerInterface",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "(layer_id: str, config: Dict[str, Any] = None)",
        "docstring": "Layer 3: Graph Reasoner (PFC analog)",
        "full_name": "insightspike.core.base.L3GraphReasonerInterface",
        "tags": []
      },
      {
        "name": "L4LLMInterface",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "(layer_id: str, config: Dict[str, Any] = None)",
        "docstring": "Layer 4: Language Model Interface",
        "full_name": "insightspike.core.base.L4LLMInterface",
        "tags": []
      },
      {
        "name": "LayerInput",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "(data: Any, metadata: Dict[str, Any] = None, context: Optional[Dict[str, Any]] = None) -> None",
        "docstring": "Standard input format for all layers",
        "full_name": "insightspike.core.base.LayerInput",
        "tags": []
      },
      {
        "name": "LayerInterface",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "(layer_id: str, config: Dict[str, Any] = None)",
        "docstring": "Base interface for all InsightSpike layers",
        "full_name": "insightspike.core.base.LayerInterface",
        "tags": []
      },
      {
        "name": "LayerOutput",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "(result: Any, confidence: float = 0.0, metadata: Dict[str, Any] = None, metrics: Dict[str, float] = None) -> None",
        "docstring": "Standard output format for all layers",
        "full_name": "insightspike.core.base.LayerOutput",
        "tags": []
      },
      {
        "name": "MazeEnvironmentAdapter",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "(maze_size: int = 10, wall_density: float = 0.25)",
        "docstring": "Adapter for existing maze environments to generic interface",
        "full_name": "insightspike.core.base.MazeEnvironmentAdapter",
        "tags": []
      },
      {
        "name": "MazeInsightDetector",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "(maze_size: int, config: Optional[Dict[str, Any]] = None)",
        "docstring": "Insight detector for maze navigation",
        "full_name": "insightspike.core.base.MazeInsightDetector",
        "tags": []
      },
      {
        "name": "MazeRewardNormalizer",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "(maze_size: int)",
        "docstring": "Reward normalizer for maze environments",
        "full_name": "insightspike.core.base.MazeRewardNormalizer",
        "tags": []
      },
      {
        "name": "MazeStateEncoder",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "(maze_size: int)",
        "docstring": "State encoder for maze environments",
        "full_name": "insightspike.core.base.MazeStateEncoder",
        "tags": []
      },
      {
        "name": "MemoryManagerInterface",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "()",
        "docstring": "Generic memory manager interface",
        "full_name": "insightspike.core.base.MemoryManagerInterface",
        "tags": []
      },
      {
        "name": "ReasonerInterface",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "()",
        "docstring": "Generic reasoner interface for insight analysis",
        "full_name": "insightspike.core.base.ReasonerInterface",
        "tags": []
      },
      {
        "name": "RewardNormalizer",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract reward normalizer for different environments",
        "full_name": "insightspike.core.base.RewardNormalizer",
        "tags": []
      },
      {
        "name": "StateEncoder",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract state encoder for different state representations",
        "full_name": "insightspike.core.base.StateEncoder",
        "tags": []
      },
      {
        "name": "TaskType",
        "module": "insightspike.core.base",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Supported task types for insight detection",
        "full_name": "insightspike.core.base.TaskType",
        "tags": []
      },
      {
        "name": "AsyncDataStore",
        "module": "insightspike.core.base.async_datastore",
        "type": "class",
        "signature": "()",
        "docstring": "Extended DataStore interface with async operations for scalability",
        "full_name": "insightspike.core.base.async_datastore.AsyncDataStore",
        "tags": []
      },
      {
        "name": "DataStore",
        "module": "insightspike.core.base.async_datastore",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for data persistence",
        "full_name": "insightspike.core.base.async_datastore.DataStore",
        "tags": []
      },
      {
        "name": "DataStore",
        "module": "insightspike.core.base.datastore",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for data persistence",
        "full_name": "insightspike.core.base.datastore.DataStore",
        "tags": []
      },
      {
        "name": "VectorIndex",
        "module": "insightspike.core.base.datastore",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for vector indexing",
        "full_name": "insightspike.core.base.datastore.VectorIndex",
        "tags": []
      },
      {
        "name": "ActionSpace",
        "module": "insightspike.core.base.generic_interfaces",
        "type": "class",
        "signature": "(action_type: str, action_dim: int, action_bounds: Optional[Dict[str, Tuple[float, float]]] = None, discrete_actions: Optional[List[str]] = None) -> None",
        "docstring": "Generic action space definition",
        "full_name": "insightspike.core.base.generic_interfaces.ActionSpace",
        "tags": []
      },
      {
        "name": "EnvironmentInterface",
        "module": "insightspike.core.base.generic_interfaces",
        "type": "class",
        "signature": "()",
        "docstring": "Generic environment interface for any domain",
        "full_name": "insightspike.core.base.generic_interfaces.EnvironmentInterface",
        "tags": []
      },
      {
        "name": "EnvironmentState",
        "module": "insightspike.core.base.generic_interfaces",
        "type": "class",
        "signature": "(state_data: Union[numpy.ndarray, Dict[str, Any], List, Tuple], environment_type: str, task_type: insightspike.core.base.generic_interfaces.TaskType, state_shape: Optional[Tuple[int, ...]] = None, state_bounds: Optional[Dict[str, Tuple[float, float]]] = None, step_count: int = 0, episode_count: int = 0, metadata: Optional[Dict[str, Any]] = None) -> None",
        "docstring": "Generic state representation for any environment",
        "full_name": "insightspike.core.base.generic_interfaces.EnvironmentState",
        "tags": []
      },
      {
        "name": "GenericAgentInterface",
        "module": "insightspike.core.base.generic_interfaces",
        "type": "class",
        "signature": "(agent_id: str, environment: insightspike.core.base.generic_interfaces.EnvironmentInterface, insight_detector: insightspike.core.base.generic_interfaces.InsightDetectorInterface, state_encoder: insightspike.core.base.generic_interfaces.StateEncoder, reward_normalizer: insightspike.core.base.generic_interfaces.RewardNormalizer)",
        "docstring": "Generic agent interface that can work with any environment",
        "full_name": "insightspike.core.base.generic_interfaces.GenericAgentInterface",
        "tags": []
      },
      {
        "name": "InsightDetectorInterface",
        "module": "insightspike.core.base.generic_interfaces",
        "type": "class",
        "signature": "(task_type: insightspike.core.base.generic_interfaces.TaskType, config: Optional[Dict[str, Any]] = None)",
        "docstring": "Generic interface for insight detection across domains",
        "full_name": "insightspike.core.base.generic_interfaces.InsightDetectorInterface",
        "tags": []
      },
      {
        "name": "InsightMoment",
        "module": "insightspike.core.base.generic_interfaces",
        "type": "class",
        "signature": "(episode: int, step: int, insight_type: str, description: str, dged_value: float, dig_value: float, confidence: float = 0.0, performance_impact: float = 0.0, state: Optional[insightspike.core.base.generic_interfaces.EnvironmentState] = None, action: Optional[Any] = None, reward: Optional[float] = None, detection_method: str = 'default', timestamp: Optional[float] = None, metadata: Optional[Dict[str, Any]] = None) -> None",
        "docstring": "Generic insight moment representation",
        "full_name": "insightspike.core.base.generic_interfaces.InsightMoment",
        "tags": []
      },
      {
        "name": "MemoryManagerInterface",
        "module": "insightspike.core.base.generic_interfaces",
        "type": "class",
        "signature": "()",
        "docstring": "Generic memory manager interface",
        "full_name": "insightspike.core.base.generic_interfaces.MemoryManagerInterface",
        "tags": []
      },
      {
        "name": "ReasonerInterface",
        "module": "insightspike.core.base.generic_interfaces",
        "type": "class",
        "signature": "()",
        "docstring": "Generic reasoner interface for insight analysis",
        "full_name": "insightspike.core.base.generic_interfaces.ReasonerInterface",
        "tags": []
      },
      {
        "name": "RewardNormalizer",
        "module": "insightspike.core.base.generic_interfaces",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract reward normalizer for different environments",
        "full_name": "insightspike.core.base.generic_interfaces.RewardNormalizer",
        "tags": []
      },
      {
        "name": "StateEncoder",
        "module": "insightspike.core.base.generic_interfaces",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract state encoder for different state representations",
        "full_name": "insightspike.core.base.generic_interfaces.StateEncoder",
        "tags": []
      },
      {
        "name": "TaskType",
        "module": "insightspike.core.base.generic_interfaces",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Supported task types for insight detection",
        "full_name": "insightspike.core.base.generic_interfaces.TaskType",
        "tags": []
      },
      {
        "name": "L4Interface",
        "module": "insightspike.core.base.layer4_interface",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for Layer 4 components.",
        "full_name": "insightspike.core.base.layer4_interface.L4Interface",
        "tags": []
      },
      {
        "name": "L4_1Interface",
        "module": "insightspike.core.base.layer4_interface",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for Layer 4.1 (Optional LLM Polish) components.",
        "full_name": "insightspike.core.base.layer4_interface.L4_1Interface",
        "tags": []
      },
      {
        "name": "ActionSpace",
        "module": "insightspike.core.base.maze_implementation",
        "type": "class",
        "signature": "(action_type: str, action_dim: int, action_bounds: Optional[Dict[str, Tuple[float, float]]] = None, discrete_actions: Optional[List[str]] = None) -> None",
        "docstring": "Generic action space definition",
        "full_name": "insightspike.core.base.maze_implementation.ActionSpace",
        "tags": []
      },
      {
        "name": "EnvironmentInterface",
        "module": "insightspike.core.base.maze_implementation",
        "type": "class",
        "signature": "()",
        "docstring": "Generic environment interface for any domain",
        "full_name": "insightspike.core.base.maze_implementation.EnvironmentInterface",
        "tags": []
      },
      {
        "name": "EnvironmentState",
        "module": "insightspike.core.base.maze_implementation",
        "type": "class",
        "signature": "(state_data: Union[numpy.ndarray, Dict[str, Any], List, Tuple], environment_type: str, task_type: insightspike.core.base.generic_interfaces.TaskType, state_shape: Optional[Tuple[int, ...]] = None, state_bounds: Optional[Dict[str, Tuple[float, float]]] = None, step_count: int = 0, episode_count: int = 0, metadata: Optional[Dict[str, Any]] = None) -> None",
        "docstring": "Generic state representation for any environment",
        "full_name": "insightspike.core.base.maze_implementation.EnvironmentState",
        "tags": []
      },
      {
        "name": "InsightDetectorInterface",
        "module": "insightspike.core.base.maze_implementation",
        "type": "class",
        "signature": "(task_type: insightspike.core.base.generic_interfaces.TaskType, config: Optional[Dict[str, Any]] = None)",
        "docstring": "Generic interface for insight detection across domains",
        "full_name": "insightspike.core.base.maze_implementation.InsightDetectorInterface",
        "tags": []
      },
      {
        "name": "InsightMoment",
        "module": "insightspike.core.base.maze_implementation",
        "type": "class",
        "signature": "(episode: int, step: int, insight_type: str, description: str, dged_value: float, dig_value: float, confidence: float = 0.0, performance_impact: float = 0.0, state: Optional[insightspike.core.base.generic_interfaces.EnvironmentState] = None, action: Optional[Any] = None, reward: Optional[float] = None, detection_method: str = 'default', timestamp: Optional[float] = None, metadata: Optional[Dict[str, Any]] = None) -> None",
        "docstring": "Generic insight moment representation",
        "full_name": "insightspike.core.base.maze_implementation.InsightMoment",
        "tags": []
      },
      {
        "name": "MazeEnvironmentAdapter",
        "module": "insightspike.core.base.maze_implementation",
        "type": "class",
        "signature": "(maze_size: int = 10, wall_density: float = 0.25)",
        "docstring": "Adapter for existing maze environments to generic interface",
        "full_name": "insightspike.core.base.maze_implementation.MazeEnvironmentAdapter",
        "tags": []
      },
      {
        "name": "MazeInsightDetector",
        "module": "insightspike.core.base.maze_implementation",
        "type": "class",
        "signature": "(maze_size: int, config: Optional[Dict[str, Any]] = None)",
        "docstring": "Insight detector for maze navigation",
        "full_name": "insightspike.core.base.maze_implementation.MazeInsightDetector",
        "tags": []
      },
      {
        "name": "MazeRewardNormalizer",
        "module": "insightspike.core.base.maze_implementation",
        "type": "class",
        "signature": "(maze_size: int)",
        "docstring": "Reward normalizer for maze environments",
        "full_name": "insightspike.core.base.maze_implementation.MazeRewardNormalizer",
        "tags": []
      },
      {
        "name": "MazeStateEncoder",
        "module": "insightspike.core.base.maze_implementation",
        "type": "class",
        "signature": "(maze_size: int)",
        "docstring": "State encoder for maze environments",
        "full_name": "insightspike.core.base.maze_implementation.MazeStateEncoder",
        "tags": []
      },
      {
        "name": "RewardNormalizer",
        "module": "insightspike.core.base.maze_implementation",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract reward normalizer for different environments",
        "full_name": "insightspike.core.base.maze_implementation.RewardNormalizer",
        "tags": []
      },
      {
        "name": "StateEncoder",
        "module": "insightspike.core.base.maze_implementation",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract state encoder for different state representations",
        "full_name": "insightspike.core.base.maze_implementation.StateEncoder",
        "tags": []
      },
      {
        "name": "TaskType",
        "module": "insightspike.core.base.maze_implementation",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Supported task types for insight detection",
        "full_name": "insightspike.core.base.maze_implementation.TaskType",
        "tags": []
      },
      {
        "name": "EdgeInfo",
        "module": "insightspike.core.enhanced_episode",
        "type": "class",
        "signature": "(source: int, target: int, weight: float = 1.0, edge_type: str = 'similarity', last_updated: float = <factory>) -> None",
        "docstring": "Edge information for graph connections.",
        "full_name": "insightspike.core.enhanced_episode.EdgeInfo",
        "tags": []
      },
      {
        "name": "EnhancedEpisode",
        "module": "insightspike.core.enhanced_episode",
        "type": "class",
        "signature": "(text: str, vec: numpy.ndarray, c: float = 0.5, timestamp: float = <factory>, metadata: Dict[str, Any] = <factory>, episode_type: str = 'experience', selection_count: int = 0, creation_time: float = <factory>, confidence: Optional[float] = None, access_count: int = 0, last_access_time: float = <factory>, token_count: int = 0, byte_size: int = 0, information_gain: float = 0.0, is_compressed: bool = False, compression_ratio: float = 1.0) -> None",
        "docstring": "Extended episode with geDIG memory management features.",
        "full_name": "insightspike.core.enhanced_episode.EnhancedEpisode",
        "tags": []
      },
      {
        "name": "Episode",
        "module": "insightspike.core.enhanced_episode",
        "type": "class",
        "signature": "(text: str, vec: numpy.ndarray, c: float = 0.5, timestamp: float = <factory>, metadata: Dict[str, Any] = <factory>, episode_type: str = 'experience', selection_count: int = 0, creation_time: float = <factory>, confidence: Optional[float] = None) -> None",
        "docstring": "Single memory entry with vector embedding, text, and C-value.",
        "full_name": "insightspike.core.enhanced_episode.Episode",
        "tags": []
      },
      {
        "name": "MemoryStatistics",
        "module": "insightspike.core.enhanced_episode",
        "type": "class",
        "signature": "()",
        "docstring": "Track memory usage statistics for monitoring",
        "full_name": "insightspike.core.enhanced_episode.MemoryStatistics",
        "tags": []
      },
      {
        "name": "Episode",
        "module": "insightspike.core.episode",
        "type": "class",
        "signature": "(text: str, vec: numpy.ndarray, c: float = 0.5, timestamp: float = <factory>, metadata: Dict[str, Any] = <factory>, episode_type: str = 'experience', selection_count: int = 0, creation_time: float = <factory>, confidence: Optional[float] = None) -> None",
        "docstring": "Single memory entry with vector embedding, text, and C-value.",
        "full_name": "insightspike.core.episode.Episode",
        "tags": []
      },
      {
        "name": "create_episode",
        "module": "insightspike.core.episode",
        "type": "function",
        "signature": "(vec: numpy.ndarray, text: str, c: float = 0.5, metadata: Optional[Dict] = None, episode_type: str = 'experience') -> insightspike.core.episode.Episode",
        "docstring": "Legacy function to create episode (for backward compatibility)",
        "full_name": "insightspike.core.episode.create_episode",
        "tags": []
      },
      {
        "name": "ConfigurationError",
        "module": "insightspike.core.error_handler",
        "type": "class",
        "signature": "()",
        "docstring": "\u8a2d\u5b9a\u95a2\u9023\u306e\u30a8\u30e9\u30fc",
        "full_name": "insightspike.core.error_handler.ConfigurationError",
        "tags": []
      },
      {
        "name": "InitializationError",
        "module": "insightspike.core.error_handler",
        "type": "class",
        "signature": "()",
        "docstring": "\u521d\u671f\u5316\u30a8\u30e9\u30fc",
        "full_name": "insightspike.core.error_handler.InitializationError",
        "tags": []
      },
      {
        "name": "InsightSpikeError",
        "module": "insightspike.core.error_handler",
        "type": "class",
        "signature": "()",
        "docstring": "InsightSpike\u57fa\u5e95\u4f8b\u5916",
        "full_name": "insightspike.core.error_handler.InsightSpikeError",
        "tags": []
      },
      {
        "name": "InsightSpikeLogger",
        "module": "insightspike.core.error_handler",
        "type": "class",
        "signature": "()",
        "docstring": "\u7d71\u4e00\u30ed\u30ae\u30f3\u30b0\u30af\u30e9\u30b9",
        "full_name": "insightspike.core.error_handler.InsightSpikeLogger",
        "tags": []
      },
      {
        "name": "ModelNotFoundError",
        "module": "insightspike.core.error_handler",
        "type": "class",
        "signature": "()",
        "docstring": "\u30e2\u30c7\u30eb\u304c\u898b\u3064\u304b\u3089\u306a\u3044",
        "full_name": "insightspike.core.error_handler.ModelNotFoundError",
        "tags": []
      },
      {
        "name": "ProcessingError",
        "module": "insightspike.core.error_handler",
        "type": "class",
        "signature": "()",
        "docstring": "\u51e6\u7406\u4e2d\u306e\u30a8\u30e9\u30fc",
        "full_name": "insightspike.core.error_handler.ProcessingError",
        "tags": []
      },
      {
        "name": "get_logger",
        "module": "insightspike.core.error_handler",
        "type": "function",
        "signature": "(name: str) -> logging.Logger",
        "docstring": "\u30ed\u30ac\u30fc\u3092\u53d6\u5f97\u3059\u308b\u4fbf\u5229\u95a2\u6570",
        "full_name": "insightspike.core.error_handler.get_logger",
        "tags": []
      },
      {
        "name": "handle_error",
        "module": "insightspike.core.error_handler",
        "type": "function",
        "signature": "(error: Exception, context: Optional[Dict[str, Any]] = None, logger: Optional[logging.Logger] = None, user_message: Optional[str] = None) -> Dict[str, Any]",
        "docstring": "\u30a8\u30e9\u30fc\u3092\u51e6\u7406\u3057\u3066\u69cb\u9020\u5316\u3055\u308c\u305f\u5fdc\u7b54\u3092\u8fd4\u3059",
        "full_name": "insightspike.core.error_handler.handle_error",
        "tags": []
      },
      {
        "name": "setup_debug_mode",
        "module": "insightspike.core.error_handler",
        "type": "function",
        "signature": "()",
        "docstring": "\u30c7\u30d0\u30c3\u30b0\u30e2\u30fc\u30c9\u306e\u8a2d\u5b9a",
        "full_name": "insightspike.core.error_handler.setup_debug_mode",
        "tags": []
      },
      {
        "name": "validate_config",
        "module": "insightspike.core.error_handler",
        "type": "function",
        "signature": "(config: Dict[str, Any], required_fields: Dict[str, type]) -> None",
        "docstring": "\u8a2d\u5b9a\u306e\u691c\u8a3c\u3092\u884c\u3046",
        "full_name": "insightspike.core.error_handler.validate_config",
        "tags": []
      },
      {
        "name": "with_error_handling",
        "module": "insightspike.core.error_handler",
        "type": "function",
        "signature": "(default_return: Any = None, error_class: type = <class 'insightspike.core.error_handler.ProcessingError'>, log_errors: bool = True)",
        "docstring": "\u30a8\u30e9\u30fc\u30cf\u30f3\u30c9\u30ea\u30f3\u30b0\u30c7\u30b3\u30ec\u30fc\u30bf\u30fc",
        "full_name": "insightspike.core.error_handler.with_error_handling",
        "tags": []
      },
      {
        "name": "AgentError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Base exception for agent operations.",
        "full_name": "insightspike.core.exceptions.AgentError",
        "tags": []
      },
      {
        "name": "AgentInitializationError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when agent initialization fails.",
        "full_name": "insightspike.core.exceptions.AgentInitializationError",
        "tags": []
      },
      {
        "name": "AgentProcessingError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when agent processing encounters an error.",
        "full_name": "insightspike.core.exceptions.AgentProcessingError",
        "tags": []
      },
      {
        "name": "ConfigNotFoundError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when configuration file is not found.",
        "full_name": "insightspike.core.exceptions.ConfigNotFoundError",
        "tags": []
      },
      {
        "name": "ConfigurationError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Base exception for configuration issues.",
        "full_name": "insightspike.core.exceptions.ConfigurationError",
        "tags": []
      },
      {
        "name": "DataStoreError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Base exception for DataStore operations.",
        "full_name": "insightspike.core.exceptions.DataStoreError",
        "tags": []
      },
      {
        "name": "DataStoreLoadError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when loading data fails.",
        "full_name": "insightspike.core.exceptions.DataStoreLoadError",
        "tags": []
      },
      {
        "name": "DataStoreNotFoundError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when requested data is not found.",
        "full_name": "insightspike.core.exceptions.DataStoreNotFoundError",
        "tags": []
      },
      {
        "name": "DataStorePermissionError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when there are permission issues accessing storage.",
        "full_name": "insightspike.core.exceptions.DataStorePermissionError",
        "tags": []
      },
      {
        "name": "DataStoreSaveError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when saving data fails.",
        "full_name": "insightspike.core.exceptions.DataStoreSaveError",
        "tags": []
      },
      {
        "name": "GraphAnalysisError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when graph analysis fails.",
        "full_name": "insightspike.core.exceptions.GraphAnalysisError",
        "tags": []
      },
      {
        "name": "GraphBuildError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when graph construction fails.",
        "full_name": "insightspike.core.exceptions.GraphBuildError",
        "tags": []
      },
      {
        "name": "GraphError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Base exception for graph operations.",
        "full_name": "insightspike.core.exceptions.GraphError",
        "tags": []
      },
      {
        "name": "InsightSpikeException",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Base exception for all InsightSpike errors.",
        "full_name": "insightspike.core.exceptions.InsightSpikeException",
        "tags": []
      },
      {
        "name": "InvalidConfigError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when configuration is invalid or malformed.",
        "full_name": "insightspike.core.exceptions.InvalidConfigError",
        "tags": []
      },
      {
        "name": "LLMConnectionError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when connection to LLM service fails.",
        "full_name": "insightspike.core.exceptions.LLMConnectionError",
        "tags": []
      },
      {
        "name": "LLMError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Base exception for LLM operations.",
        "full_name": "insightspike.core.exceptions.LLMError",
        "tags": []
      },
      {
        "name": "LLMGenerationError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when LLM text generation fails.",
        "full_name": "insightspike.core.exceptions.LLMGenerationError",
        "tags": []
      },
      {
        "name": "LLMTokenLimitError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when token limit is exceeded.",
        "full_name": "insightspike.core.exceptions.LLMTokenLimitError",
        "tags": []
      },
      {
        "name": "MemoryCapacityError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when memory capacity is exceeded.",
        "full_name": "insightspike.core.exceptions.MemoryCapacityError",
        "tags": []
      },
      {
        "name": "MemoryError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Base exception for memory operations.",
        "full_name": "insightspike.core.exceptions.MemoryError",
        "tags": []
      },
      {
        "name": "MemorySearchError",
        "module": "insightspike.core.exceptions",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when memory search fails.",
        "full_name": "insightspike.core.exceptions.MemorySearchError",
        "tags": []
      },
      {
        "name": "CycleResult",
        "module": "insightspike.core.structures",
        "type": "class",
        "signature": "(response: str, reasoning_trace: str, memory_used: List[Dict[str, Any]], spike_detected: bool, graph_metrics: Dict[str, float], reasoning_quality: float, convergence_score: float, has_spike: bool) -> None",
        "docstring": "Result from a single reasoning cycle.",
        "full_name": "insightspike.core.structures.CycleResult",
        "tags": []
      },
      {
        "name": "GraphMetrics",
        "module": "insightspike.core.structures",
        "type": "class",
        "signature": "(ged_value: float = 0.0, ig_value: float = 0.0, entropy: float = 0.0, clustering_coefficient: float = 0.0, node_count: int = 0, edge_count: int = 0) -> None",
        "docstring": "Metrics from graph analysis.",
        "full_name": "insightspike.core.structures.GraphMetrics",
        "tags": []
      },
      {
        "name": "VectorIntegrator",
        "module": "insightspike.core.vector_integrator",
        "type": "class",
        "signature": "(weight_manager=None)",
        "docstring": "Unified vector integration for various InsightSpike operations.",
        "full_name": "insightspike.core.vector_integrator.VectorIntegrator",
        "tags": []
      },
      {
        "name": "VectorWeightConfig",
        "module": "insightspike.core.weight_vector_manager",
        "type": "class",
        "signature": "(*, enabled: bool = False, weights: Optional[List[float]] = None, presets: Dict[str, Optional[List[float]]] = <factory>, active_preset: Optional[str] = None) -> None",
        "docstring": "Simple vector weight configuration.",
        "full_name": "insightspike.core.weight_vector_manager.VectorWeightConfig",
        "tags": []
      },
      {
        "name": "WeightVectorManager",
        "module": "insightspike.core.weight_vector_manager",
        "type": "class",
        "signature": "(config: Optional[insightspike.config.vector_weights.VectorWeightConfig] = None)",
        "docstring": "Simple vector weight manager.",
        "full_name": "insightspike.core.weight_vector_manager.WeightVectorManager",
        "tags": []
      },
      {
        "name": "VectorDecoder",
        "module": "insightspike.decoder",
        "type": "class",
        "signature": "(llm_interface=None, cache_size: int = 1000, cache_ttl: int = 3600, similarity_threshold: float = 0.9)",
        "docstring": "Enhanced vector decoder with multiple strategies:",
        "full_name": "insightspike.decoder.VectorDecoder",
        "tags": []
      },
      {
        "name": "VectorDecoder",
        "module": "insightspike.decoder.vector_decoder",
        "type": "class",
        "signature": "(llm_interface=None, cache_size: int = 1000, cache_ttl: int = 3600, similarity_threshold: float = 0.9)",
        "docstring": "Enhanced vector decoder with multiple strategies:",
        "full_name": "insightspike.decoder.vector_decoder.VectorDecoder",
        "tags": []
      },
      {
        "name": "EurekaDetector",
        "module": "insightspike.detection",
        "type": "class",
        "signature": "(ged_threshold: 'float' = 0.5, ig_threshold: 'float' = 0.2, eta_spike: 'float' = 0.2)",
        "docstring": "Detects insight spikes based on \u0394GED and \u0394IG patterns.",
        "full_name": "insightspike.detection.EurekaDetector",
        "tags": []
      },
      {
        "name": "InsightFactRegistry",
        "module": "insightspike.detection",
        "type": "class",
        "signature": "(db_path: Optional[pathlib._local.Path] = None)",
        "docstring": "Manages registration, evaluation, and utilization of discovered insights.",
        "full_name": "insightspike.detection.InsightFactRegistry",
        "tags": []
      },
      {
        "name": "detect_eureka_spike",
        "module": "insightspike.detection",
        "type": "function",
        "signature": "(delta_ged: 'float', delta_ig: 'float', **kwargs) -> 'bool'",
        "docstring": "Simple function to detect EurekaSpike.",
        "full_name": "insightspike.detection.detect_eureka_spike",
        "tags": []
      },
      {
        "name": "EurekaDetector",
        "module": "insightspike.detection.eureka_spike",
        "type": "class",
        "signature": "(ged_threshold: 'float' = 0.5, ig_threshold: 'float' = 0.2, eta_spike: 'float' = 0.2)",
        "docstring": "Detects insight spikes based on \u0394GED and \u0394IG patterns.",
        "full_name": "insightspike.detection.eureka_spike.EurekaDetector",
        "tags": []
      },
      {
        "name": "detect_eureka_spike",
        "module": "insightspike.detection.eureka_spike",
        "type": "function",
        "signature": "(delta_ged: 'float', delta_ig: 'float', **kwargs) -> 'bool'",
        "docstring": "Simple function to detect EurekaSpike.",
        "full_name": "insightspike.detection.eureka_spike.detect_eureka_spike",
        "tags": []
      },
      {
        "name": "get_config",
        "module": "insightspike.detection.eureka_spike",
        "type": "function",
        "signature": "() -> insightspike.config.models.InsightSpikeConfig",
        "docstring": "Get current configuration or load defaults",
        "full_name": "insightspike.detection.eureka_spike.get_config",
        "tags": []
      },
      {
        "name": "GraphOptimizationResult",
        "module": "insightspike.detection.insight_registry",
        "type": "class",
        "signature": "(before_ged: float, after_ged: float, ged_improvement: float, before_ig: float, after_ig: float, ig_improvement: float, structural_efficiency: float, connectivity_improvement: float) -> None",
        "docstring": "Results of graph optimization analysis",
        "full_name": "insightspike.detection.insight_registry.GraphOptimizationResult",
        "tags": []
      },
      {
        "name": "InsightFact",
        "module": "insightspike.detection.insight_registry",
        "type": "class",
        "signature": "(id: str, text: str, source_concepts: List[str], target_concepts: List[str], confidence: float, quality_score: float, ged_optimization: float, ig_improvement: float, discovery_context: str, generated_at: float, validation_status: str, relationship_type: str, usage_count: int = 0, last_accessed: float = 0.0) -> None",
        "docstring": "Represents a discovered insight fact",
        "full_name": "insightspike.detection.insight_registry.InsightFact",
        "tags": []
      },
      {
        "name": "InsightFactRegistry",
        "module": "insightspike.detection.insight_registry",
        "type": "class",
        "signature": "(db_path: Optional[pathlib._local.Path] = None)",
        "docstring": "Manages registration, evaluation, and utilization of discovered insights.",
        "full_name": "insightspike.detection.insight_registry.InsightFactRegistry",
        "tags": []
      },
      {
        "name": "get_insight_registry",
        "module": "insightspike.detection.insight_registry",
        "type": "function",
        "signature": "() -> insightspike.detection.insight_registry.InsightFactRegistry",
        "docstring": "Get or create global insight registry instance",
        "full_name": "insightspike.detection.insight_registry.get_insight_registry",
        "tags": []
      },
      {
        "name": "shutdown_insight_registry",
        "module": "insightspike.detection.insight_registry",
        "type": "function",
        "signature": "()",
        "docstring": "Shutdown global insight registry",
        "full_name": "insightspike.detection.insight_registry.shutdown_insight_registry",
        "tags": []
      },
      {
        "name": "ComplexMazeGenerator",
        "module": "insightspike.environments.complex_maze",
        "type": "class",
        "signature": "()",
        "docstring": "Generate complex mazes using recursive backtracking algorithm.",
        "full_name": "insightspike.environments.complex_maze.ComplexMazeGenerator",
        "tags": []
      },
      {
        "name": "CellType",
        "module": "insightspike.environments.maze",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Types of cells in the maze.",
        "full_name": "insightspike.environments.maze.CellType",
        "tags": []
      },
      {
        "name": "ComplexMazeGenerator",
        "module": "insightspike.environments.maze",
        "type": "class",
        "signature": "()",
        "docstring": "Generate complex mazes using recursive backtracking algorithm.",
        "full_name": "insightspike.environments.maze.ComplexMazeGenerator",
        "tags": []
      },
      {
        "name": "MazeObservation",
        "module": "insightspike.environments.maze",
        "type": "class",
        "signature": "(position: Tuple[int, int], cell_type: insightspike.environments.maze.CellType, num_paths: int, possible_moves: List[int], hit_wall: bool = False, is_junction: bool = False, is_dead_end: bool = False, is_goal: bool = False) -> None",
        "docstring": "Observation from the maze environment.",
        "full_name": "insightspike.environments.maze.MazeObservation",
        "tags": []
      },
      {
        "name": "ProperMazeGenerator",
        "module": "insightspike.environments.maze",
        "type": "class",
        "signature": "()",
        "docstring": "Generate proper mazes using various algorithms.",
        "full_name": "insightspike.environments.maze.ProperMazeGenerator",
        "tags": []
      },
      {
        "name": "SimpleMaze",
        "module": "insightspike.environments.maze",
        "type": "class",
        "signature": "(size: Tuple[int, int] = (20, 20), maze_layout: Optional[numpy.ndarray] = None, start_pos: Optional[Tuple[int, int]] = None, goal_pos: Optional[Tuple[int, int]] = None, maze_type: str = 'simple')",
        "docstring": "Simple 2D maze environment for InsightSpike experiments.",
        "full_name": "insightspike.environments.maze.SimpleMaze",
        "tags": []
      },
      {
        "name": "ProperMazeGenerator",
        "module": "insightspike.environments.proper_maze_generator",
        "type": "class",
        "signature": "()",
        "docstring": "Generate proper mazes using various algorithms.",
        "full_name": "insightspike.environments.proper_maze_generator.ProperMazeGenerator",
        "tags": []
      },
      {
        "name": "GraphAnalyzer",
        "module": "insightspike.features.graph_reasoning",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Analyzes graph structures and calculates metrics.",
        "full_name": "insightspike.features.graph_reasoning.GraphAnalyzer",
        "tags": []
      },
      {
        "name": "RewardCalculator",
        "module": "insightspike.features.graph_reasoning",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Calculates reward signals for memory updates.",
        "full_name": "insightspike.features.graph_reasoning.RewardCalculator",
        "tags": []
      },
      {
        "name": "GraphAnalyzer",
        "module": "insightspike.features.graph_reasoning.graph_analyzer",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Analyzes graph structures and calculates metrics.",
        "full_name": "insightspike.features.graph_reasoning.graph_analyzer.GraphAnalyzer",
        "tags": []
      },
      {
        "name": "RewardCalculator",
        "module": "insightspike.features.graph_reasoning.reward_calculator",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Calculates reward signals for memory updates.",
        "full_name": "insightspike.features.graph_reasoning.reward_calculator.RewardCalculator",
        "tags": []
      },
      {
        "name": "GraphBuilder",
        "module": "insightspike.graph.construction",
        "type": "class",
        "signature": "(embedding_model_name: str = 'all-MiniLM-L6-v2')",
        "docstring": "Build knowledge graphs from documents",
        "full_name": "insightspike.graph.construction.GraphBuilder",
        "tags": []
      },
      {
        "name": "GraphTypeAdapter",
        "module": "insightspike.graph.type_adapter",
        "type": "class",
        "signature": "()",
        "docstring": "Adapter for converting between NetworkX and PyTorch Geometric graph formats.",
        "full_name": "insightspike.graph.type_adapter.GraphTypeAdapter",
        "tags": []
      },
      {
        "name": "AgentConfig",
        "module": "insightspike.implementations.agents",
        "type": "class",
        "signature": "(mode: insightspike.implementations.agents.configurable_agent.AgentMode = <AgentMode.BASIC: 'basic'>, max_cycles: int = 3, verbose: bool = False, enable_query_transform: bool = False, enable_graph_aware_memory: bool = False, enable_multi_hop: bool = False, enable_query_branching: bool = False, enable_caching: bool = False, enable_async_processing: bool = False, enable_gpu_acceleration: bool = False, enable_evolution_tracking: bool = False, llm_config: Optional[Dict[str, Any]] = None, memory_config: Optional[Dict[str, Any]] = None, graph_config: Optional[Dict[str, Any]] = None, cache_size: int = 1000, parallel_branches: int = 4, embedding_batch_size: int = 32) -> None",
        "docstring": "Unified configuration for all agent features",
        "full_name": "insightspike.implementations.agents.AgentConfig",
        "tags": []
      },
      {
        "name": "AgentConfigBuilder",
        "module": "insightspike.implementations.agents",
        "type": "class",
        "signature": "()",
        "docstring": "Builder pattern for agent configuration",
        "full_name": "insightspike.implementations.agents.AgentConfigBuilder",
        "tags": []
      },
      {
        "name": "AgentMode",
        "module": "insightspike.implementations.agents",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Different operation modes for the agent",
        "full_name": "insightspike.implementations.agents.AgentMode",
        "tags": []
      },
      {
        "name": "ConfigurableAgent",
        "module": "insightspike.implementations.agents",
        "type": "class",
        "signature": "(config: Optional[insightspike.implementations.agents.configurable_agent.AgentConfig] = None)",
        "docstring": "Configurable Q&A Agent with multiple operation modes.",
        "full_name": "insightspike.implementations.agents.ConfigurableAgent",
        "tags": []
      },
      {
        "name": "CycleResult",
        "module": "insightspike.implementations.agents",
        "type": "class",
        "signature": "(question: str, retrieved_documents: List[Dict[str, Any]], graph_analysis: Dict[str, Any], response: str, reasoning_quality: float, spike_detected: bool, error_state: Dict[str, Any], cycle_number: int, success: bool = True, query_id: Optional[str] = None) -> None",
        "docstring": "Result from one reasoning cycle",
        "full_name": "insightspike.implementations.agents.CycleResult",
        "tags": []
      },
      {
        "name": "GenericInsightSpikeAgent",
        "module": "insightspike.implementations.agents",
        "type": "class",
        "signature": "(agent_id: str, environment: insightspike.core.base.generic_interfaces.EnvironmentInterface, insight_detector: insightspike.core.base.generic_interfaces.InsightDetectorInterface, state_encoder: insightspike.core.base.generic_interfaces.StateEncoder, reward_normalizer: insightspike.core.base.generic_interfaces.RewardNormalizer, config: Optional[Dict[str, Any]] = None)",
        "docstring": "Generic InsightSpike agent that works with any environment",
        "full_name": "insightspike.implementations.agents.GenericInsightSpikeAgent",
        "tags": []
      },
      {
        "name": "InsightSpikeAgentFactory",
        "module": "insightspike.implementations.agents",
        "type": "class",
        "signature": "()",
        "docstring": "Factory for creating InsightSpike agents for different domains",
        "full_name": "insightspike.implementations.agents.InsightSpikeAgentFactory",
        "tags": []
      },
      {
        "name": "MainAgent",
        "module": "insightspike.implementations.agents",
        "type": "class",
        "signature": "(config=None, datastore: Optional[insightspike.core.base.datastore.DataStore] = None)",
        "docstring": "Main orchestrating agent that coordinates all layers.",
        "full_name": "insightspike.implementations.agents.MainAgent",
        "tags": []
      },
      {
        "name": "create_maze_agent",
        "module": "insightspike.implementations.agents",
        "type": "function",
        "signature": "(maze_size: int = 10, agent_config: Optional[Dict[str, Any]] = None) -> insightspike.implementations.agents.generic_agent.GenericInsightSpikeAgent",
        "docstring": "Quick function to create a maze agent",
        "full_name": "insightspike.implementations.agents.create_maze_agent",
        "tags": []
      },
      {
        "name": "create_qa_agent",
        "module": "insightspike.implementations.agents",
        "type": "function",
        "signature": "(mode: str = 'basic', **kwargs)",
        "docstring": "Create a Q&A agent using ConfigurableAgent",
        "full_name": "insightspike.implementations.agents.create_qa_agent",
        "tags": []
      },
      {
        "name": "AgentConfigBuilder",
        "module": "insightspike.implementations.agents.agent_factory",
        "type": "class",
        "signature": "()",
        "docstring": "Builder pattern for agent configuration",
        "full_name": "insightspike.implementations.agents.agent_factory.AgentConfigBuilder",
        "tags": []
      },
      {
        "name": "GenericInsightSpikeAgent",
        "module": "insightspike.implementations.agents.agent_factory",
        "type": "class",
        "signature": "(agent_id: str, environment: insightspike.core.base.generic_interfaces.EnvironmentInterface, insight_detector: insightspike.core.base.generic_interfaces.InsightDetectorInterface, state_encoder: insightspike.core.base.generic_interfaces.StateEncoder, reward_normalizer: insightspike.core.base.generic_interfaces.RewardNormalizer, config: Optional[Dict[str, Any]] = None)",
        "docstring": "Generic InsightSpike agent that works with any environment",
        "full_name": "insightspike.implementations.agents.agent_factory.GenericInsightSpikeAgent",
        "tags": []
      },
      {
        "name": "InsightSpikeAgentFactory",
        "module": "insightspike.implementations.agents.agent_factory",
        "type": "class",
        "signature": "()",
        "docstring": "Factory for creating InsightSpike agents for different domains",
        "full_name": "insightspike.implementations.agents.agent_factory.InsightSpikeAgentFactory",
        "tags": []
      },
      {
        "name": "MazeEnvironmentAdapter",
        "module": "insightspike.implementations.agents.agent_factory",
        "type": "class",
        "signature": "(maze_size: int = 10, wall_density: float = 0.25)",
        "docstring": "Adapter for existing maze environments to generic interface",
        "full_name": "insightspike.implementations.agents.agent_factory.MazeEnvironmentAdapter",
        "tags": []
      },
      {
        "name": "MazeInsightDetector",
        "module": "insightspike.implementations.agents.agent_factory",
        "type": "class",
        "signature": "(maze_size: int, config: Optional[Dict[str, Any]] = None)",
        "docstring": "Insight detector for maze navigation",
        "full_name": "insightspike.implementations.agents.agent_factory.MazeInsightDetector",
        "tags": []
      },
      {
        "name": "MazeRewardNormalizer",
        "module": "insightspike.implementations.agents.agent_factory",
        "type": "class",
        "signature": "(maze_size: int)",
        "docstring": "Reward normalizer for maze environments",
        "full_name": "insightspike.implementations.agents.agent_factory.MazeRewardNormalizer",
        "tags": []
      },
      {
        "name": "MazeStateEncoder",
        "module": "insightspike.implementations.agents.agent_factory",
        "type": "class",
        "signature": "(maze_size: int)",
        "docstring": "State encoder for maze environments",
        "full_name": "insightspike.implementations.agents.agent_factory.MazeStateEncoder",
        "tags": []
      },
      {
        "name": "TaskType",
        "module": "insightspike.implementations.agents.agent_factory",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Supported task types for insight detection",
        "full_name": "insightspike.implementations.agents.agent_factory.TaskType",
        "tags": []
      },
      {
        "name": "create_configured_maze_agent",
        "module": "insightspike.implementations.agents.agent_factory",
        "type": "function",
        "signature": "(maze_size: int = 10, learning_rate: float = 0.15, exploration_rate: float = 0.4, dged_threshold: float = -0.3, dig_threshold: float = 1.0) -> insightspike.implementations.agents.generic_agent.GenericInsightSpikeAgent",
        "docstring": "Create maze agent with specific parameters",
        "full_name": "insightspike.implementations.agents.agent_factory.create_configured_maze_agent",
        "tags": []
      },
      {
        "name": "create_maze_agent",
        "module": "insightspike.implementations.agents.agent_factory",
        "type": "function",
        "signature": "(maze_size: int = 10, agent_config: Optional[Dict[str, Any]] = None) -> insightspike.implementations.agents.generic_agent.GenericInsightSpikeAgent",
        "docstring": "Quick function to create a maze agent",
        "full_name": "insightspike.implementations.agents.agent_factory.create_maze_agent",
        "tags": []
      },
      {
        "name": "create_qa_agent",
        "module": "insightspike.implementations.agents.agent_factory",
        "type": "function",
        "signature": "(mode: str = 'basic', **kwargs)",
        "docstring": "Create a Q&A agent using ConfigurableAgent",
        "full_name": "insightspike.implementations.agents.agent_factory.create_qa_agent",
        "tags": []
      },
      {
        "name": "AgentConfig",
        "module": "insightspike.implementations.agents.configurable_agent",
        "type": "class",
        "signature": "(mode: insightspike.implementations.agents.configurable_agent.AgentMode = <AgentMode.BASIC: 'basic'>, max_cycles: int = 3, verbose: bool = False, enable_query_transform: bool = False, enable_graph_aware_memory: bool = False, enable_multi_hop: bool = False, enable_query_branching: bool = False, enable_caching: bool = False, enable_async_processing: bool = False, enable_gpu_acceleration: bool = False, enable_evolution_tracking: bool = False, llm_config: Optional[Dict[str, Any]] = None, memory_config: Optional[Dict[str, Any]] = None, graph_config: Optional[Dict[str, Any]] = None, cache_size: int = 1000, parallel_branches: int = 4, embedding_batch_size: int = 32) -> None",
        "docstring": "Unified configuration for all agent features",
        "full_name": "insightspike.implementations.agents.configurable_agent.AgentConfig",
        "tags": []
      },
      {
        "name": "AgentMode",
        "module": "insightspike.implementations.agents.configurable_agent",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Different operation modes for the agent",
        "full_name": "insightspike.implementations.agents.configurable_agent.AgentMode",
        "tags": []
      },
      {
        "name": "ConfigurableAgent",
        "module": "insightspike.implementations.agents.configurable_agent",
        "type": "class",
        "signature": "(config: Optional[insightspike.implementations.agents.configurable_agent.AgentConfig] = None)",
        "docstring": "Configurable Q&A Agent with multiple operation modes.",
        "full_name": "insightspike.implementations.agents.configurable_agent.ConfigurableAgent",
        "tags": []
      },
      {
        "name": "MainAgent",
        "module": "insightspike.implementations.agents.configurable_agent",
        "type": "class",
        "signature": "(config: Optional[insightspike.implementations.agents.configurable_agent.AgentConfig] = None)",
        "docstring": "Configurable Q&A Agent with multiple operation modes.",
        "full_name": "insightspike.implementations.agents.configurable_agent.MainAgent",
        "tags": []
      },
      {
        "name": "QueryCache",
        "module": "insightspike.implementations.agents.configurable_agent",
        "type": "class",
        "signature": "(max_size: int = 1000)",
        "docstring": "Simple LRU cache for query results",
        "full_name": "insightspike.implementations.agents.configurable_agent.QueryCache",
        "tags": []
      },
      {
        "name": "UnifiedCycleResult",
        "module": "insightspike.implementations.agents.configurable_agent",
        "type": "class",
        "signature": "(question: str, response: str, retrieved_documents: List[Dict[str, Any]], reasoning_quality: float, spike_detected: bool, cycle_number: int, success: bool = True, graph_analysis: Optional[Dict[str, Any]] = None, error_state: Optional[Dict[str, Any]] = None, query_state: Optional[Any] = None, transformation_history: Optional[List[Dict[str, Any]]] = None, reasoning_paths: Optional[List[Dict[str, Any]]] = None, branch_results: Optional[List[Dict[str, Any]]] = None, multi_hop_trace: Optional[List[str]] = None, cached: bool = False, processing_time: float = 0.0, gpu_accelerated: bool = False) -> None",
        "docstring": "Unified result structure that supports all agent variants",
        "full_name": "insightspike.implementations.agents.configurable_agent.UnifiedCycleResult",
        "tags": []
      },
      {
        "name": "UnifiedMainAgent",
        "module": "insightspike.implementations.agents.configurable_agent",
        "type": "class",
        "signature": "(config: Optional[insightspike.implementations.agents.configurable_agent.AgentConfig] = None)",
        "docstring": "Configurable Q&A Agent with multiple operation modes.",
        "full_name": "insightspike.implementations.agents.configurable_agent.UnifiedMainAgent",
        "tags": []
      },
      {
        "name": "create_agent",
        "module": "insightspike.implementations.agents.configurable_agent",
        "type": "function",
        "signature": "(mode: str = 'basic', **kwargs) -> insightspike.implementations.agents.configurable_agent.ConfigurableAgent",
        "docstring": "Create agent with specified mode",
        "full_name": "insightspike.implementations.agents.configurable_agent.create_agent",
        "tags": []
      },
      {
        "name": "DataStore",
        "module": "insightspike.implementations.agents.datastore_agent",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for data persistence",
        "full_name": "insightspike.implementations.agents.datastore_agent.DataStore",
        "tags": []
      },
      {
        "name": "DataStoreMainAgent",
        "module": "insightspike.implementations.agents.datastore_agent",
        "type": "class",
        "signature": "(datastore: insightspike.core.base.datastore.DataStore, config: Union[Dict, insightspike.config.models.InsightSpikeConfig, NoneType] = None, **kwargs)",
        "docstring": "DataStore-centric implementation of the InsightSpike main agent.",
        "full_name": "insightspike.implementations.agents.datastore_agent.DataStoreMainAgent",
        "tags": []
      },
      {
        "name": "EmbeddingManager",
        "module": "insightspike.implementations.agents.datastore_agent",
        "type": "class",
        "signature": "(model_name: str = None, config=None, weight_manager=None)",
        "docstring": "Manages text embedding models with caching and fallback support.",
        "full_name": "insightspike.implementations.agents.datastore_agent.EmbeddingManager",
        "tags": []
      },
      {
        "name": "Episode",
        "module": "insightspike.implementations.agents.datastore_agent",
        "type": "class",
        "signature": "(text: str, vec: numpy.ndarray, c: float = 0.5, timestamp: float = <factory>, metadata: Dict[str, Any] = <factory>, episode_type: str = 'experience', selection_count: int = 0, creation_time: float = <factory>, confidence: Optional[float] = None) -> None",
        "docstring": "Single memory entry with vector embedding, text, and C-value.",
        "full_name": "insightspike.implementations.agents.datastore_agent.Episode",
        "tags": []
      },
      {
        "name": "EurekaDetector",
        "module": "insightspike.implementations.agents.datastore_agent",
        "type": "class",
        "signature": "(ged_threshold: 'float' = 0.5, ig_threshold: 'float' = 0.2, eta_spike: 'float' = 0.2)",
        "docstring": "Detects insight spikes based on \u0394GED and \u0394IG patterns.",
        "full_name": "insightspike.implementations.agents.datastore_agent.EurekaDetector",
        "tags": []
      },
      {
        "name": "InsightSpikeConfig",
        "module": "insightspike.implementations.agents.datastore_agent",
        "type": "class",
        "signature": "(*, environment: Literal['development', 'experiment', 'production', 'research', 'test', 'testing', 'custom'] = 'development', pre_warm_models: bool = True, llm: insightspike.config.models.LLMConfig = <factory>, embedding: insightspike.config.models.EmbeddingConfig = <factory>, memory: insightspike.config.models.MemoryConfig = <factory>, graph: insightspike.config.models.GraphConfig = <factory>, monitoring: insightspike.config.models.MonitoringConfig = <factory>, logging: insightspike.config.models.LoggingConfig = <factory>, paths: insightspike.config.models.PathsConfig = <factory>, processing: insightspike.config.models.ProcessingConfig = <factory>, output: insightspike.config.models.OutputConfig = <factory>, datastore: insightspike.config.models.DataStoreConfig = <factory>, metrics: insightspike.config.models.MetricsConfig = <factory>, reasoning: insightspike.config.models.ReasoningConfig = <factory>, performance: insightspike.config.models.PerformanceConfig = <factory>, vector_search: insightspike.config.models.VectorSearchConfig = <factory>, wake_sleep: insightspike.config.wake_sleep_config.WakeSleepConfig = <factory>) -> None",
        "docstring": "Complete InsightSpike configuration - clean structure without backward compatibility",
        "full_name": "insightspike.implementations.agents.datastore_agent.InsightSpikeConfig",
        "tags": []
      },
      {
        "name": "L2WorkingMemoryManager",
        "module": "insightspike.implementations.agents.datastore_agent",
        "type": "class",
        "signature": "(datastore: insightspike.core.base.datastore.DataStore, config: Union[insightspike.implementations.layers.layer2_working_memory.WorkingMemoryConfig, Any, NoneType] = None, embedding_manager: Optional[insightspike.processing.embedder.EmbeddingManager] = None)",
        "docstring": "Working memory based memory manager using DataStore.",
        "full_name": "insightspike.implementations.agents.datastore_agent.L2WorkingMemoryManager",
        "tags": []
      },
      {
        "name": "L4LLMInterface",
        "module": "insightspike.implementations.agents.datastore_agent",
        "type": "class",
        "signature": "(config: Union[insightspike.implementations.layers.layer4_llm_interface.LLMConfig, ForwardRef('InsightSpikeConfig'), Dict[str, Any], NoneType] = None)",
        "docstring": "Layer 4 Language Interface - Natural language synthesis.",
        "full_name": "insightspike.implementations.agents.datastore_agent.L4LLMInterface",
        "tags": []
      },
      {
        "name": "WorkingMemoryConfig",
        "module": "insightspike.implementations.agents.datastore_agent",
        "type": "class",
        "signature": "(working_memory_size: int = 100, search_k: int = 20, cache_embeddings: bool = True, embedding_cache_size: int = 1000, batch_size: int = 32, similarity_threshold: float = 0.7, datastore_namespace: str = 'episodes') -> None",
        "docstring": "Configuration for working memory manager",
        "full_name": "insightspike.implementations.agents.datastore_agent.WorkingMemoryConfig",
        "tags": []
      },
      {
        "name": "Decision",
        "module": "insightspike.implementations.agents.decision_controller",
        "type": "class",
        "signature": "(mode: 'str', params: 'Dict[str, Any]') -> None",
        "docstring": "Decision(mode: 'str', params: 'Dict[str, Any]')",
        "full_name": "insightspike.implementations.agents.decision_controller.Decision",
        "tags": []
      },
      {
        "name": "DecisionController",
        "module": "insightspike.implementations.agents.decision_controller",
        "type": "class",
        "signature": "(*, hop_cap: 'int' = 3) -> 'None'",
        "docstring": "Lightweight decision module for MainAgent.",
        "full_name": "insightspike.implementations.agents.decision_controller.DecisionController",
        "tags": []
      },
      {
        "name": "EnvironmentInterface",
        "module": "insightspike.implementations.agents.generic_agent",
        "type": "class",
        "signature": "()",
        "docstring": "Generic environment interface for any domain",
        "full_name": "insightspike.implementations.agents.generic_agent.EnvironmentInterface",
        "tags": []
      },
      {
        "name": "EnvironmentState",
        "module": "insightspike.implementations.agents.generic_agent",
        "type": "class",
        "signature": "(state_data: Union[numpy.ndarray, Dict[str, Any], List, Tuple], environment_type: str, task_type: insightspike.core.base.generic_interfaces.TaskType, state_shape: Optional[Tuple[int, ...]] = None, state_bounds: Optional[Dict[str, Tuple[float, float]]] = None, step_count: int = 0, episode_count: int = 0, metadata: Optional[Dict[str, Any]] = None) -> None",
        "docstring": "Generic state representation for any environment",
        "full_name": "insightspike.implementations.agents.generic_agent.EnvironmentState",
        "tags": []
      },
      {
        "name": "GenericAgentInterface",
        "module": "insightspike.implementations.agents.generic_agent",
        "type": "class",
        "signature": "(agent_id: str, environment: insightspike.core.base.generic_interfaces.EnvironmentInterface, insight_detector: insightspike.core.base.generic_interfaces.InsightDetectorInterface, state_encoder: insightspike.core.base.generic_interfaces.StateEncoder, reward_normalizer: insightspike.core.base.generic_interfaces.RewardNormalizer)",
        "docstring": "Generic agent interface that can work with any environment",
        "full_name": "insightspike.implementations.agents.generic_agent.GenericAgentInterface",
        "tags": []
      },
      {
        "name": "GenericInsightSpikeAgent",
        "module": "insightspike.implementations.agents.generic_agent",
        "type": "class",
        "signature": "(agent_id: str, environment: insightspike.core.base.generic_interfaces.EnvironmentInterface, insight_detector: insightspike.core.base.generic_interfaces.InsightDetectorInterface, state_encoder: insightspike.core.base.generic_interfaces.StateEncoder, reward_normalizer: insightspike.core.base.generic_interfaces.RewardNormalizer, config: Optional[Dict[str, Any]] = None)",
        "docstring": "Generic InsightSpike agent that works with any environment",
        "full_name": "insightspike.implementations.agents.generic_agent.GenericInsightSpikeAgent",
        "tags": []
      },
      {
        "name": "GenericMemoryManager",
        "module": "insightspike.implementations.agents.generic_agent",
        "type": "class",
        "signature": "(max_capacity: int = 10000)",
        "docstring": "Generic memory manager implementation",
        "full_name": "insightspike.implementations.agents.generic_agent.GenericMemoryManager",
        "tags": []
      },
      {
        "name": "GenericReasoner",
        "module": "insightspike.implementations.agents.generic_agent",
        "type": "class",
        "signature": "()",
        "docstring": "Generic reasoner for insight analysis",
        "full_name": "insightspike.implementations.agents.generic_agent.GenericReasoner",
        "tags": []
      },
      {
        "name": "InsightDetectorInterface",
        "module": "insightspike.implementations.agents.generic_agent",
        "type": "class",
        "signature": "(task_type: insightspike.core.base.generic_interfaces.TaskType, config: Optional[Dict[str, Any]] = None)",
        "docstring": "Generic interface for insight detection across domains",
        "full_name": "insightspike.implementations.agents.generic_agent.InsightDetectorInterface",
        "tags": []
      },
      {
        "name": "InsightMoment",
        "module": "insightspike.implementations.agents.generic_agent",
        "type": "class",
        "signature": "(episode: int, step: int, insight_type: str, description: str, dged_value: float, dig_value: float, confidence: float = 0.0, performance_impact: float = 0.0, state: Optional[insightspike.core.base.generic_interfaces.EnvironmentState] = None, action: Optional[Any] = None, reward: Optional[float] = None, detection_method: str = 'default', timestamp: Optional[float] = None, metadata: Optional[Dict[str, Any]] = None) -> None",
        "docstring": "Generic insight moment representation",
        "full_name": "insightspike.implementations.agents.generic_agent.InsightMoment",
        "tags": []
      },
      {
        "name": "MemoryManagerInterface",
        "module": "insightspike.implementations.agents.generic_agent",
        "type": "class",
        "signature": "()",
        "docstring": "Generic memory manager interface",
        "full_name": "insightspike.implementations.agents.generic_agent.MemoryManagerInterface",
        "tags": []
      },
      {
        "name": "ReasonerInterface",
        "module": "insightspike.implementations.agents.generic_agent",
        "type": "class",
        "signature": "()",
        "docstring": "Generic reasoner interface for insight analysis",
        "full_name": "insightspike.implementations.agents.generic_agent.ReasonerInterface",
        "tags": []
      },
      {
        "name": "RewardNormalizer",
        "module": "insightspike.implementations.agents.generic_agent",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract reward normalizer for different environments",
        "full_name": "insightspike.implementations.agents.generic_agent.RewardNormalizer",
        "tags": []
      },
      {
        "name": "StateEncoder",
        "module": "insightspike.implementations.agents.generic_agent",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract state encoder for different state representations",
        "full_name": "insightspike.implementations.agents.generic_agent.StateEncoder",
        "tags": []
      },
      {
        "name": "TaskType",
        "module": "insightspike.implementations.agents.generic_agent",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Supported task types for insight detection",
        "full_name": "insightspike.implementations.agents.generic_agent.TaskType",
        "tags": []
      },
      {
        "name": "AgentConfig",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "class",
        "signature": "(mode: insightspike.implementations.agents.configurable_agent.AgentMode = <AgentMode.BASIC: 'basic'>, max_cycles: int = 3, verbose: bool = False, enable_query_transform: bool = False, enable_graph_aware_memory: bool = False, enable_multi_hop: bool = False, enable_query_branching: bool = False, enable_caching: bool = False, enable_async_processing: bool = False, enable_gpu_acceleration: bool = False, enable_evolution_tracking: bool = False, llm_config: Optional[Dict[str, Any]] = None, memory_config: Optional[Dict[str, Any]] = None, graph_config: Optional[Dict[str, Any]] = None, cache_size: int = 1000, parallel_branches: int = 4, embedding_batch_size: int = 32) -> None",
        "docstring": "Unified configuration for all agent features",
        "full_name": "insightspike.implementations.agents.main_agent.AgentConfig",
        "tags": []
      },
      {
        "name": "AgentMode",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Different operation modes for the agent",
        "full_name": "insightspike.implementations.agents.main_agent.AgentMode",
        "tags": []
      },
      {
        "name": "ConfigurableAgent",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "class",
        "signature": "(config: Optional[insightspike.implementations.agents.configurable_agent.AgentConfig] = None)",
        "docstring": "Configurable Q&A Agent with multiple operation modes.",
        "full_name": "insightspike.implementations.agents.main_agent.ConfigurableAgent",
        "tags": []
      },
      {
        "name": "CycleResult",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "class",
        "signature": "(question: str, retrieved_documents: List[Dict[str, Any]], graph_analysis: Dict[str, Any], response: str, reasoning_quality: float, spike_detected: bool, error_state: Dict[str, Any], cycle_number: int, success: bool = True, query_id: Optional[str] = None) -> None",
        "docstring": "Result from one reasoning cycle",
        "full_name": "insightspike.implementations.agents.main_agent.CycleResult",
        "tags": []
      },
      {
        "name": "DataStore",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for data persistence",
        "full_name": "insightspike.implementations.agents.main_agent.DataStore",
        "tags": []
      },
      {
        "name": "Episode",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "class",
        "signature": "(text: str, vec: numpy.ndarray, c: float = 0.5, timestamp: float = <factory>, metadata: Dict[str, Any] = <factory>, episode_type: str = 'experience', selection_count: int = 0, creation_time: float = <factory>, confidence: Optional[float] = None) -> None",
        "docstring": "Single memory entry with vector embedding, text, and C-value.",
        "full_name": "insightspike.implementations.agents.main_agent.Episode",
        "tags": []
      },
      {
        "name": "ErrorMonitor",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "class",
        "signature": "(layer_id: str = 'L1_ErrorMonitor', config: Dict[str, Any] = None)",
        "docstring": "Layer 1 implementation for error monitoring and uncertainty calculation.",
        "full_name": "insightspike.implementations.agents.main_agent.ErrorMonitor",
        "tags": []
      },
      {
        "name": "GeDIGABLogger",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "class",
        "signature": "(window: 'int' = 100, threshold: 'float' = 0.85, min_pairs: 'int' = 30, flush_every: 'int' = 50) -> 'None'",
        "docstring": "",
        "full_name": "insightspike.implementations.agents.main_agent.GeDIGABLogger",
        "tags": []
      },
      {
        "name": "GeDIGFallbackTracker",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "class",
        "signature": "(events: 'List[GeDIGFallbackEvent]' = <factory>, total: 'int' = 0) -> None",
        "docstring": "GeDIGFallbackTracker(events: 'List[GeDIGFallbackEvent]' = <factory>, total: 'int' = 0)",
        "full_name": "insightspike.implementations.agents.main_agent.GeDIGFallbackTracker",
        "tags": []
      },
      {
        "name": "GraphMemorySearch",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Enhanced memory search using graph traversal.",
        "full_name": "insightspike.implementations.agents.main_agent.GraphMemorySearch",
        "tags": []
      },
      {
        "name": "InsightSpikeConfig",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "class",
        "signature": "(*, environment: Literal['development', 'experiment', 'production', 'research', 'test', 'testing', 'custom'] = 'development', pre_warm_models: bool = True, llm: insightspike.config.models.LLMConfig = <factory>, embedding: insightspike.config.models.EmbeddingConfig = <factory>, memory: insightspike.config.models.MemoryConfig = <factory>, graph: insightspike.config.models.GraphConfig = <factory>, monitoring: insightspike.config.models.MonitoringConfig = <factory>, logging: insightspike.config.models.LoggingConfig = <factory>, paths: insightspike.config.models.PathsConfig = <factory>, processing: insightspike.config.models.ProcessingConfig = <factory>, output: insightspike.config.models.OutputConfig = <factory>, datastore: insightspike.config.models.DataStoreConfig = <factory>, metrics: insightspike.config.models.MetricsConfig = <factory>, reasoning: insightspike.config.models.ReasoningConfig = <factory>, performance: insightspike.config.models.PerformanceConfig = <factory>, vector_search: insightspike.config.models.VectorSearchConfig = <factory>, wake_sleep: insightspike.config.wake_sleep_config.WakeSleepConfig = <factory>) -> None",
        "docstring": "Complete InsightSpike configuration - clean structure without backward compatibility",
        "full_name": "insightspike.implementations.agents.main_agent.InsightSpikeConfig",
        "tags": []
      },
      {
        "name": "L3GraphReasoner",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Enhanced graph reasoning layer with GNN processing and spike detection.",
        "full_name": "insightspike.implementations.agents.main_agent.L3GraphReasoner",
        "tags": []
      },
      {
        "name": "MainAgent",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "class",
        "signature": "(config=None, datastore: Optional[insightspike.core.base.datastore.DataStore] = None)",
        "docstring": "Main orchestrating agent that coordinates all layers.",
        "full_name": "insightspike.implementations.agents.main_agent.MainAgent",
        "tags": []
      },
      {
        "name": "Memory",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "class",
        "signature": "(dim: int = 384, config=None)",
        "docstring": "Backward-compatible Layer 2 Memory Manager.",
        "full_name": "insightspike.implementations.agents.main_agent.Memory",
        "tags": []
      },
      {
        "name": "TwoThresholdCandidateSelector",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "class",
        "signature": "(theta_cand: 'float', theta_link: 'float', k_cap: 'int', *, top_m: 'Optional[int]' = None, score_key: 'str' = 'similarity', radius_cand: 'Optional[float]' = None, radius_link: 'Optional[float]' = None, higher_is_better: 'bool' = True, prefilter_fn: 'Optional[Callable[[Iterable[Dict[str, Any]]], Iterable[Dict[str, Any]]]]' = None) -> 'None'",
        "docstring": "Selects candidates using \u03b8_cand and \u03b8_link thresholds.",
        "full_name": "insightspike.implementations.agents.main_agent.TwoThresholdCandidateSelector",
        "tags": []
      },
      {
        "name": "cycle",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "function",
        "signature": "(memory, question: str, previous_graph=None, **kwargs) -> Dict[str, Any]",
        "docstring": "Backward compatible cycle function.",
        "full_name": "insightspike.implementations.agents.main_agent.cycle",
        "tags": []
      },
      {
        "name": "get_insight_registry",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "function",
        "signature": "() -> insightspike.detection.insight_registry.InsightFactRegistry",
        "docstring": "Get or create global insight registry instance",
        "full_name": "insightspike.implementations.agents.main_agent.get_insight_registry",
        "tags": []
      },
      {
        "name": "get_llm_provider",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "function",
        "signature": "(config=None, safe_mode: bool = False)",
        "docstring": "",
        "full_name": "insightspike.implementations.agents.main_agent.get_llm_provider",
        "tags": []
      },
      {
        "name": "safe_attr",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "function",
        "signature": "(obj, path, default=None)",
        "docstring": "",
        "full_name": "insightspike.implementations.agents.main_agent.safe_attr",
        "tags": []
      },
      {
        "name": "safe_has",
        "module": "insightspike.implementations.agents.main_agent",
        "type": "function",
        "signature": "(obj, path)",
        "docstring": "",
        "full_name": "insightspike.implementations.agents.main_agent.safe_has",
        "tags": []
      },
      {
        "name": "CycleResult",
        "module": "insightspike.implementations.agents.slim_main_agent",
        "type": "class",
        "signature": "(question: str, retrieved_documents: List[Dict[str, Any]], graph_analysis: Dict[str, Any], response: str, reasoning_quality: float, spike_detected: bool, error_state: Dict[str, Any], has_spike: bool = False, confidence: float = 0.0) -> None",
        "docstring": "Result from one reasoning cycle - simplified version.",
        "full_name": "insightspike.implementations.agents.slim_main_agent.CycleResult",
        "tags": []
      },
      {
        "name": "DataStore",
        "module": "insightspike.implementations.agents.slim_main_agent",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for data persistence",
        "full_name": "insightspike.implementations.agents.slim_main_agent.DataStore",
        "tags": []
      },
      {
        "name": "Episode",
        "module": "insightspike.implementations.agents.slim_main_agent",
        "type": "class",
        "signature": "(text: str, vec: numpy.ndarray, c: float = 0.5, timestamp: float = <factory>, metadata: Dict[str, Any] = <factory>, episode_type: str = 'experience', selection_count: int = 0, creation_time: float = <factory>, confidence: Optional[float] = None) -> None",
        "docstring": "Single memory entry with vector embedding, text, and C-value.",
        "full_name": "insightspike.implementations.agents.slim_main_agent.Episode",
        "tags": []
      },
      {
        "name": "ErrorMonitor",
        "module": "insightspike.implementations.agents.slim_main_agent",
        "type": "class",
        "signature": "(layer_id: str = 'L1_ErrorMonitor', config: Dict[str, Any] = None)",
        "docstring": "Layer 1 implementation for error monitoring and uncertainty calculation.",
        "full_name": "insightspike.implementations.agents.slim_main_agent.ErrorMonitor",
        "tags": []
      },
      {
        "name": "FallbackReason",
        "module": "insightspike.implementations.agents.slim_main_agent",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Reasons for fallback activation.",
        "full_name": "insightspike.implementations.agents.slim_main_agent.FallbackReason",
        "tags": []
      },
      {
        "name": "GraphMemorySearch",
        "module": "insightspike.implementations.agents.slim_main_agent",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Enhanced memory search using graph traversal.",
        "full_name": "insightspike.implementations.agents.slim_main_agent.GraphMemorySearch",
        "tags": []
      },
      {
        "name": "L3GraphReasoner",
        "module": "insightspike.implementations.agents.slim_main_agent",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Enhanced graph reasoning layer with GNN processing and spike detection.",
        "full_name": "insightspike.implementations.agents.slim_main_agent.L3GraphReasoner",
        "tags": []
      },
      {
        "name": "Memory",
        "module": "insightspike.implementations.agents.slim_main_agent",
        "type": "class",
        "signature": "(dim: int = 384, config=None)",
        "docstring": "Backward-compatible Layer 2 Memory Manager.",
        "full_name": "insightspike.implementations.agents.slim_main_agent.Memory",
        "tags": []
      },
      {
        "name": "SlimMainAgent",
        "module": "insightspike.implementations.agents.slim_main_agent",
        "type": "class",
        "signature": "(config=None, datastore: Optional[insightspike.core.base.datastore.DataStore] = None)",
        "docstring": "Streamlined main agent with modular architecture.",
        "full_name": "insightspike.implementations.agents.slim_main_agent.SlimMainAgent",
        "tags": []
      },
      {
        "name": "SpikeDecisionMode",
        "module": "insightspike.implementations.agents.slim_main_agent",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Different modes for spike decision making.",
        "full_name": "insightspike.implementations.agents.slim_main_agent.SpikeDecisionMode",
        "tags": []
      },
      {
        "name": "SpikePipeline",
        "module": "insightspike.implementations.agents.slim_main_agent",
        "type": "class",
        "signature": "(config=None, decision_mode: insightspike.spike_pipeline.detector.SpikeDecisionMode = <SpikeDecisionMode.WEIGHTED: 'weighted'>, enable_history: bool = True)",
        "docstring": "Complete spike detection pipeline.",
        "full_name": "insightspike.implementations.agents.slim_main_agent.SpikePipeline",
        "tags": []
      },
      {
        "name": "create_slim_agent",
        "module": "insightspike.implementations.agents.slim_main_agent",
        "type": "function",
        "signature": "(config=None, datastore=None) -> insightspike.implementations.agents.slim_main_agent.SlimMainAgent",
        "docstring": "Create a SlimMainAgent instance.",
        "full_name": "insightspike.implementations.agents.slim_main_agent.create_slim_agent",
        "tags": []
      },
      {
        "name": "execute_fallback",
        "module": "insightspike.implementations.agents.slim_main_agent",
        "type": "function",
        "signature": "(reason: insightspike.fallback.registry.FallbackReason, exception: Exception, context: Dict[str, Any]) -> Dict[str, Any]",
        "docstring": "Execute fallback using the global registry.",
        "full_name": "insightspike.implementations.agents.slim_main_agent.execute_fallback",
        "tags": []
      },
      {
        "name": "get_fallback_registry",
        "module": "insightspike.implementations.agents.slim_main_agent",
        "type": "function",
        "signature": "() -> insightspike.fallback.registry.FallbackRegistry",
        "docstring": "Get the global fallback registry.",
        "full_name": "insightspike.implementations.agents.slim_main_agent.get_fallback_registry",
        "tags": []
      },
      {
        "name": "get_insight_registry",
        "module": "insightspike.implementations.agents.slim_main_agent",
        "type": "function",
        "signature": "() -> insightspike.detection.insight_registry.InsightFactRegistry",
        "docstring": "Get or create global insight registry instance",
        "full_name": "insightspike.implementations.agents.slim_main_agent.get_insight_registry",
        "tags": []
      },
      {
        "name": "DataStoreFactory",
        "module": "insightspike.implementations.datastore",
        "type": "class",
        "signature": "()",
        "docstring": "Factory for creating DataStore instances",
        "full_name": "insightspike.implementations.datastore.DataStoreFactory",
        "tags": []
      },
      {
        "name": "FileSystemDataStore",
        "module": "insightspike.implementations.datastore",
        "type": "class",
        "signature": "(base_path: str = 'data', root_path: Optional[str] = None)",
        "docstring": "File system based data store implementation",
        "full_name": "insightspike.implementations.datastore.FileSystemDataStore",
        "tags": []
      },
      {
        "name": "InMemoryDataStore",
        "module": "insightspike.implementations.datastore",
        "type": "class",
        "signature": "()",
        "docstring": "In-memory data store implementation",
        "full_name": "insightspike.implementations.datastore.InMemoryDataStore",
        "tags": []
      },
      {
        "name": "DataStore",
        "module": "insightspike.implementations.datastore.adapters",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for data persistence",
        "full_name": "insightspike.implementations.datastore.adapters.DataStore",
        "tags": []
      },
      {
        "name": "Episode",
        "module": "insightspike.implementations.datastore.adapters",
        "type": "class",
        "signature": "(text: str, vec: numpy.ndarray, c: float = 0.5, timestamp: float = <factory>, metadata: Dict[str, Any] = <factory>, episode_type: str = 'experience', selection_count: int = 0, creation_time: float = <factory>, confidence: Optional[float] = None) -> None",
        "docstring": "Single memory entry with vector embedding, text, and C-value.",
        "full_name": "insightspike.implementations.datastore.adapters.Episode",
        "tags": []
      },
      {
        "name": "L2MemoryAdapter",
        "module": "insightspike.implementations.datastore.adapters",
        "type": "class",
        "signature": "(datastore: insightspike.core.base.datastore.DataStore)",
        "docstring": "Adapter to make L2MemoryManager use DataStore",
        "full_name": "insightspike.implementations.datastore.adapters.L2MemoryAdapter",
        "tags": []
      },
      {
        "name": "L3GraphAdapter",
        "module": "insightspike.implementations.datastore.adapters",
        "type": "class",
        "signature": "(datastore: insightspike.core.base.datastore.DataStore)",
        "docstring": "Adapter to make L3GraphReasoner use DataStore",
        "full_name": "insightspike.implementations.datastore.adapters.L3GraphAdapter",
        "tags": []
      },
      {
        "name": "ConfigurableVectorIndex",
        "module": "insightspike.implementations.datastore.configurable_vector_index",
        "type": "class",
        "signature": "(dimension: int, index_type: str = 'auto', **kwargs)",
        "docstring": "Vector index implementation using configurable backend.",
        "full_name": "insightspike.implementations.datastore.configurable_vector_index.ConfigurableVectorIndex",
        "tags": []
      },
      {
        "name": "VectorIndex",
        "module": "insightspike.implementations.datastore.configurable_vector_index",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for vector indexing",
        "full_name": "insightspike.implementations.datastore.configurable_vector_index.VectorIndex",
        "tags": []
      },
      {
        "name": "VectorIndexFactory",
        "module": "insightspike.implementations.datastore.configurable_vector_index",
        "type": "class",
        "signature": "()",
        "docstring": "Factory for creating vector indices.",
        "full_name": "insightspike.implementations.datastore.configurable_vector_index.VectorIndexFactory",
        "tags": []
      },
      {
        "name": "BackwardCompatibleWrapper",
        "module": "insightspike.implementations.datastore.enhanced_filesystem_store",
        "type": "class",
        "signature": "(index_or_dimension: 'Any' = 384)",
        "docstring": "",
        "full_name": "insightspike.implementations.datastore.enhanced_filesystem_store.BackwardCompatibleWrapper",
        "tags": []
      },
      {
        "name": "DataStore",
        "module": "insightspike.implementations.datastore.enhanced_filesystem_store",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for data persistence",
        "full_name": "insightspike.implementations.datastore.enhanced_filesystem_store.DataStore",
        "tags": []
      },
      {
        "name": "EnhancedFileSystemDataStore",
        "module": "insightspike.implementations.datastore.enhanced_filesystem_store",
        "type": "class",
        "signature": "(base_path: str, config: Optional[Dict] = None)",
        "docstring": "\u7d71\u5408\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3092\u5185\u90e8\u3067\u4f7f\u7528\u3059\u308bFileSystemDataStore",
        "full_name": "insightspike.implementations.datastore.enhanced_filesystem_store.EnhancedFileSystemDataStore",
        "tags": []
      },
      {
        "name": "FileSystemDataStore",
        "module": "insightspike.implementations.datastore.enhanced_filesystem_store",
        "type": "class",
        "signature": "(base_path: str = 'data', root_path: Optional[str] = None)",
        "docstring": "File system based data store implementation",
        "full_name": "insightspike.implementations.datastore.enhanced_filesystem_store.FileSystemDataStore",
        "tags": []
      },
      {
        "name": "IntegratedVectorGraphIndex",
        "module": "insightspike.implementations.datastore.enhanced_filesystem_store",
        "type": "class",
        "signature": "(dimension: 'int' = 384)",
        "docstring": "",
        "full_name": "insightspike.implementations.datastore.enhanced_filesystem_store.IntegratedVectorGraphIndex",
        "tags": []
      },
      {
        "name": "DataStore",
        "module": "insightspike.implementations.datastore.factory",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for data persistence",
        "full_name": "insightspike.implementations.datastore.factory.DataStore",
        "tags": []
      },
      {
        "name": "DataStoreFactory",
        "module": "insightspike.implementations.datastore.factory",
        "type": "class",
        "signature": "()",
        "docstring": "Factory for creating DataStore instances",
        "full_name": "insightspike.implementations.datastore.factory.DataStoreFactory",
        "tags": []
      },
      {
        "name": "FileSystemDataStore",
        "module": "insightspike.implementations.datastore.factory",
        "type": "class",
        "signature": "(base_path: str = 'data', root_path: Optional[str] = None)",
        "docstring": "File system based data store implementation",
        "full_name": "insightspike.implementations.datastore.factory.FileSystemDataStore",
        "tags": []
      },
      {
        "name": "InMemoryDataStore",
        "module": "insightspike.implementations.datastore.factory",
        "type": "class",
        "signature": "()",
        "docstring": "In-memory data store implementation",
        "full_name": "insightspike.implementations.datastore.factory.InMemoryDataStore",
        "tags": []
      },
      {
        "name": "SQLiteDataStore",
        "module": "insightspike.implementations.datastore.factory",
        "type": "class",
        "signature": "(db_path: str, vector_dim: int = 384)",
        "docstring": "SQLite implementation of AsyncDataStore",
        "full_name": "insightspike.implementations.datastore.factory.SQLiteDataStore",
        "tags": []
      },
      {
        "name": "DataStore",
        "module": "insightspike.implementations.datastore.filesystem_store",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for data persistence",
        "full_name": "insightspike.implementations.datastore.filesystem_store.DataStore",
        "tags": []
      },
      {
        "name": "DataStoreLoadError",
        "module": "insightspike.implementations.datastore.filesystem_store",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when loading data fails.",
        "full_name": "insightspike.implementations.datastore.filesystem_store.DataStoreLoadError",
        "tags": []
      },
      {
        "name": "DataStoreNotFoundError",
        "module": "insightspike.implementations.datastore.filesystem_store",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when requested data is not found.",
        "full_name": "insightspike.implementations.datastore.filesystem_store.DataStoreNotFoundError",
        "tags": []
      },
      {
        "name": "DataStorePermissionError",
        "module": "insightspike.implementations.datastore.filesystem_store",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when there are permission issues accessing storage.",
        "full_name": "insightspike.implementations.datastore.filesystem_store.DataStorePermissionError",
        "tags": []
      },
      {
        "name": "DataStoreSaveError",
        "module": "insightspike.implementations.datastore.filesystem_store",
        "type": "class",
        "signature": "(message: str, details: Optional[Any] = None)",
        "docstring": "Raised when saving data fails.",
        "full_name": "insightspike.implementations.datastore.filesystem_store.DataStoreSaveError",
        "tags": []
      },
      {
        "name": "DataType",
        "module": "insightspike.implementations.datastore.filesystem_store",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Types of data stored by the system.",
        "full_name": "insightspike.implementations.datastore.filesystem_store.DataType",
        "tags": []
      },
      {
        "name": "FAISSVectorIndex",
        "module": "insightspike.implementations.datastore.filesystem_store",
        "type": "class",
        "signature": "(dimension: int)",
        "docstring": "FAISS-based vector index implementation",
        "full_name": "insightspike.implementations.datastore.filesystem_store.FAISSVectorIndex",
        "tags": []
      },
      {
        "name": "FileFormat",
        "module": "insightspike.implementations.datastore.filesystem_store",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Supported file formats for data storage.",
        "full_name": "insightspike.implementations.datastore.filesystem_store.FileFormat",
        "tags": []
      },
      {
        "name": "FileSystemDataStore",
        "module": "insightspike.implementations.datastore.filesystem_store",
        "type": "class",
        "signature": "(base_path: str = 'data', root_path: Optional[str] = None)",
        "docstring": "File system based data store implementation",
        "full_name": "insightspike.implementations.datastore.filesystem_store.FileSystemDataStore",
        "tags": []
      },
      {
        "name": "VectorIndex",
        "module": "insightspike.implementations.datastore.filesystem_store",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for vector indexing",
        "full_name": "insightspike.implementations.datastore.filesystem_store.VectorIndex",
        "tags": []
      },
      {
        "name": "resolve_project_relative",
        "module": "insightspike.implementations.datastore.filesystem_store",
        "type": "function",
        "signature": "(path_like: 'Union[str, Path]') -> 'str'",
        "docstring": "Resolve a path relative to the project root if it's not absolute.",
        "full_name": "insightspike.implementations.datastore.filesystem_store.resolve_project_relative",
        "tags": []
      },
      {
        "name": "DataStore",
        "module": "insightspike.implementations.datastore.memory_store",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for data persistence",
        "full_name": "insightspike.implementations.datastore.memory_store.DataStore",
        "tags": []
      },
      {
        "name": "InMemoryDataStore",
        "module": "insightspike.implementations.datastore.memory_store",
        "type": "class",
        "signature": "()",
        "docstring": "In-memory data store implementation",
        "full_name": "insightspike.implementations.datastore.memory_store.InMemoryDataStore",
        "tags": []
      },
      {
        "name": "AsyncDataStore",
        "module": "insightspike.implementations.datastore.sqlite_store",
        "type": "class",
        "signature": "()",
        "docstring": "Extended DataStore interface with async operations for scalability",
        "full_name": "insightspike.implementations.datastore.sqlite_store.AsyncDataStore",
        "tags": []
      },
      {
        "name": "ConfigurableVectorIndex",
        "module": "insightspike.implementations.datastore.sqlite_store",
        "type": "class",
        "signature": "(dimension: int, index_type: str = 'Flat')",
        "docstring": "Vector index implementation using VectorIndexFactory",
        "full_name": "insightspike.implementations.datastore.sqlite_store.ConfigurableVectorIndex",
        "tags": []
      },
      {
        "name": "FAISSVectorIndex",
        "module": "insightspike.implementations.datastore.sqlite_store",
        "type": "class",
        "signature": "(dimension: int, index_type: str = 'Flat')",
        "docstring": "Alias to maintain compatibility with older FAISSVectorIndex references.",
        "full_name": "insightspike.implementations.datastore.sqlite_store.FAISSVectorIndex",
        "tags": []
      },
      {
        "name": "SQLiteDataStore",
        "module": "insightspike.implementations.datastore.sqlite_store",
        "type": "class",
        "signature": "(db_path: str, vector_dim: int = 384)",
        "docstring": "SQLite implementation of AsyncDataStore",
        "full_name": "insightspike.implementations.datastore.sqlite_store.SQLiteDataStore",
        "tags": []
      },
      {
        "name": "VectorIndex",
        "module": "insightspike.implementations.datastore.sqlite_store",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for vector indexing",
        "full_name": "insightspike.implementations.datastore.sqlite_store.VectorIndex",
        "tags": []
      },
      {
        "name": "VectorIndexFactory",
        "module": "insightspike.implementations.datastore.sqlite_store",
        "type": "class",
        "signature": "()",
        "docstring": "Factory for creating vector indices.",
        "full_name": "insightspike.implementations.datastore.sqlite_store.VectorIndexFactory",
        "tags": []
      },
      {
        "name": "SQLiteDataStoreGraphMixin",
        "module": "insightspike.implementations.datastore.sqlite_store_graph",
        "type": "class",
        "signature": "()",
        "docstring": "Mixin for graph operations in SQLiteDataStore",
        "full_name": "insightspike.implementations.datastore.sqlite_store_graph.SQLiteDataStoreGraphMixin",
        "tags": []
      },
      {
        "name": "CompatibleL2MemoryManager",
        "module": "insightspike.implementations.layers",
        "type": "class",
        "signature": "(dim: int = 384, config=None)",
        "docstring": "Backward-compatible Layer 2 Memory Manager.",
        "full_name": "insightspike.implementations.layers.CompatibleL2MemoryManager",
        "tags": []
      },
      {
        "name": "ErrorMonitor",
        "module": "insightspike.implementations.layers",
        "type": "class",
        "signature": "(layer_id: str = 'L1_ErrorMonitor', config: Dict[str, Any] = None)",
        "docstring": "Layer 1 implementation for error monitoring and uncertainty calculation.",
        "full_name": "insightspike.implementations.layers.ErrorMonitor",
        "tags": []
      },
      {
        "name": "L2MemoryManager",
        "module": "insightspike.implementations.layers",
        "type": "class",
        "signature": "(config: Union[insightspike.implementations.layers.layer2_memory_manager.MemoryConfig, Dict[str, Any], Any, NoneType] = None)",
        "docstring": "Layer 2 Memory Manager - Graph-centric episodic memory.",
        "full_name": "insightspike.implementations.layers.L2MemoryManager",
        "tags": []
      },
      {
        "name": "L3GraphReasoner",
        "module": "insightspike.implementations.layers",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Enhanced graph reasoning layer with GNN processing and spike detection.",
        "full_name": "insightspike.implementations.layers.L3GraphReasoner",
        "tags": []
      },
      {
        "name": "MemoryConfig",
        "module": "insightspike.implementations.layers",
        "type": "class",
        "signature": "(mode: insightspike.implementations.layers.layer2_memory_manager.MemoryMode = <MemoryMode.SCALABLE: 'scalable'>, embedding_dim: int = 384, max_episodes: int = 10000, enable_aging: bool = True, aging_factor: float = 0.95, min_age_days: int = 7, max_age_days: int = 90, prune_on_overflow: bool = True, use_c_values: bool = True, use_graph_integration: bool = False, use_conflict_detection: bool = False, use_importance_scoring: bool = False, use_scalable_indexing: bool = True, use_hierarchical_graph: bool = False, vector_search_backend: str = 'auto', similarity_threshold: float = 0.7, max_graph_edges: int = 10000, batch_size: int = 32, cache_embeddings: bool = True) -> None",
        "docstring": "Unified configuration for memory manager",
        "full_name": "insightspike.implementations.layers.MemoryConfig",
        "tags": []
      },
      {
        "name": "MemoryMode",
        "module": "insightspike.implementations.layers",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Different operation modes for memory management",
        "full_name": "insightspike.implementations.layers.MemoryMode",
        "tags": []
      },
      {
        "name": "ScalableGraphBuilder",
        "module": "insightspike.implementations.layers",
        "type": "class",
        "signature": "(config=None, monitor: Optional[insightspike.monitoring.graph_monitor.GraphOperationMonitor] = None)",
        "docstring": "Build graphs efficiently using FAISS for nearest neighbor search.",
        "full_name": "insightspike.implementations.layers.ScalableGraphBuilder",
        "tags": []
      },
      {
        "name": "CachedMemoryManager",
        "module": "insightspike.implementations.layers.cached_memory_manager",
        "type": "class",
        "signature": "(datastore: insightspike.core.base.datastore.DataStore, cache_size: int = 100, embedder: Optional[insightspike.processing.embedder.EmbeddingManager] = None)",
        "docstring": "Memory manager with DataStore backend and LRU cache.",
        "full_name": "insightspike.implementations.layers.cached_memory_manager.CachedMemoryManager",
        "tags": []
      },
      {
        "name": "DataStore",
        "module": "insightspike.implementations.layers.cached_memory_manager",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for data persistence",
        "full_name": "insightspike.implementations.layers.cached_memory_manager.DataStore",
        "tags": []
      },
      {
        "name": "EmbeddingManager",
        "module": "insightspike.implementations.layers.cached_memory_manager",
        "type": "class",
        "signature": "(model_name: str = None, config=None, weight_manager=None)",
        "docstring": "Manages text embedding models with caching and fallback support.",
        "full_name": "insightspike.implementations.layers.cached_memory_manager.EmbeddingManager",
        "tags": []
      },
      {
        "name": "Episode",
        "module": "insightspike.implementations.layers.cached_memory_manager",
        "type": "class",
        "signature": "(text: str, vec: numpy.ndarray, c: float = 0.5, timestamp: float = <factory>, metadata: Dict[str, Any] = <factory>, episode_type: str = 'experience', selection_count: int = 0, creation_time: float = <factory>, confidence: Optional[float] = None) -> None",
        "docstring": "Single memory entry with vector embedding, text, and C-value.",
        "full_name": "insightspike.implementations.layers.cached_memory_manager.Episode",
        "tags": []
      },
      {
        "name": "get_memory_monitor",
        "module": "insightspike.implementations.layers.cached_memory_manager",
        "type": "function",
        "signature": "() -> insightspike.monitoring.memory_monitor.MemoryMonitor",
        "docstring": "Get or create global memory monitor",
        "full_name": "insightspike.implementations.layers.cached_memory_manager.get_memory_monitor",
        "tags": []
      },
      {
        "name": "L1Conductor",
        "module": "insightspike.implementations.layers.layer1_conductor",
        "type": "class",
        "signature": "(config: 'Any | None' = None) -> 'None'",
        "docstring": "Layer1 conductor for centers/Ecand orchestration (bridge for experiments).",
        "full_name": "insightspike.implementations.layers.layer1_conductor.L1Conductor",
        "tags": []
      },
      {
        "name": "ErrorMonitor",
        "module": "insightspike.implementations.layers.layer1_error_monitor",
        "type": "class",
        "signature": "(layer_id: str = 'L1_ErrorMonitor', config: Dict[str, Any] = None)",
        "docstring": "Layer 1 implementation for error monitoring and uncertainty calculation.",
        "full_name": "insightspike.implementations.layers.layer1_error_monitor.ErrorMonitor",
        "tags": []
      },
      {
        "name": "KnownUnknownAnalysis",
        "module": "insightspike.implementations.layers.layer1_error_monitor",
        "type": "class",
        "signature": "(known_elements: List[str], unknown_elements: List[str], certainty_scores: Dict[str, float], query_complexity: float, requires_synthesis: bool, error_threshold: float, analysis_confidence: float) -> None",
        "docstring": "Analysis result separating known and unknown information components",
        "full_name": "insightspike.implementations.layers.layer1_error_monitor.KnownUnknownAnalysis",
        "tags": []
      },
      {
        "name": "L1ErrorMonitorInterface",
        "module": "insightspike.implementations.layers.layer1_error_monitor",
        "type": "class",
        "signature": "(layer_id: str, config: Dict[str, Any] = None)",
        "docstring": "Layer 1: Error Monitor (Cerebellum analog)",
        "full_name": "insightspike.implementations.layers.layer1_error_monitor.L1ErrorMonitorInterface",
        "tags": []
      },
      {
        "name": "LayerInput",
        "module": "insightspike.implementations.layers.layer1_error_monitor",
        "type": "class",
        "signature": "(data: Any, metadata: Dict[str, Any] = None, context: Optional[Dict[str, Any]] = None) -> None",
        "docstring": "Standard input format for all layers",
        "full_name": "insightspike.implementations.layers.layer1_error_monitor.LayerInput",
        "tags": []
      },
      {
        "name": "LayerOutput",
        "module": "insightspike.implementations.layers.layer1_error_monitor",
        "type": "class",
        "signature": "(result: Any, confidence: float = 0.0, metadata: Dict[str, Any] = None, metrics: Dict[str, float] = None) -> None",
        "docstring": "Standard output format for all layers",
        "full_name": "insightspike.implementations.layers.layer1_error_monitor.LayerOutput",
        "tags": []
      },
      {
        "name": "analyze_input",
        "module": "insightspike.implementations.layers.layer1_error_monitor",
        "type": "function",
        "signature": "(query: str, context_documents: List[str] = None, knowledge_base_stats: Dict[str, Any] = None, unknown_learner: Optional[Any] = None) -> insightspike.implementations.layers.layer1_error_monitor.KnownUnknownAnalysis",
        "docstring": "Analyze input query to separate known vs unknown information components.",
        "full_name": "insightspike.implementations.layers.layer1_error_monitor.analyze_input",
        "tags": []
      },
      {
        "name": "get_config",
        "module": "insightspike.implementations.layers.layer1_error_monitor",
        "type": "function",
        "signature": "() -> insightspike.config.models.InsightSpikeConfig",
        "docstring": "Get current configuration or load defaults",
        "full_name": "insightspike.implementations.layers.layer1_error_monitor.get_config",
        "tags": []
      },
      {
        "name": "uncertainty",
        "module": "insightspike.implementations.layers.layer1_error_monitor",
        "type": "function",
        "signature": "(scores: Sequence[float]) -> float",
        "docstring": "Legacy uncertainty function for backward compatibility",
        "full_name": "insightspike.implementations.layers.layer1_error_monitor.uncertainty",
        "tags": []
      },
      {
        "name": "BoundaryDetector",
        "module": "insightspike.implementations.layers.layer1_stream_processor",
        "type": "class",
        "signature": "(config: insightspike.implementations.layers.layer1_stream_processor.Layer1Config)",
        "docstring": "Detects episode boundaries in text stream",
        "full_name": "insightspike.implementations.layers.layer1_stream_processor.BoundaryDetector",
        "tags": []
      },
      {
        "name": "EmbeddingManager",
        "module": "insightspike.implementations.layers.layer1_stream_processor",
        "type": "class",
        "signature": "(model_name: str = None, config=None, weight_manager=None)",
        "docstring": "Manages text embedding models with caching and fallback support.",
        "full_name": "insightspike.implementations.layers.layer1_stream_processor.EmbeddingManager",
        "tags": []
      },
      {
        "name": "Episode",
        "module": "insightspike.implementations.layers.layer1_stream_processor",
        "type": "class",
        "signature": "(text: str, vec: numpy.ndarray, c: float = 0.5, timestamp: float = <factory>, metadata: Dict[str, Any] = <factory>, episode_type: str = 'experience', selection_count: int = 0, creation_time: float = <factory>, confidence: Optional[float] = None) -> None",
        "docstring": "Single memory entry with vector embedding, text, and C-value.",
        "full_name": "insightspike.implementations.layers.layer1_stream_processor.Episode",
        "tags": []
      },
      {
        "name": "L1Episode",
        "module": "insightspike.implementations.layers.layer1_stream_processor",
        "type": "class",
        "signature": "(embedding: numpy.ndarray, text: str, token_count: int, timestamp: float, entropy_score: float, boundary_type: str, entity_graph: Optional[Any] = None) -> None",
        "docstring": "Episode generated by Layer1 stream processor",
        "full_name": "insightspike.implementations.layers.layer1_stream_processor.L1Episode",
        "tags": []
      },
      {
        "name": "L1IntegratedMemory",
        "module": "insightspike.implementations.layers.layer1_stream_processor",
        "type": "class",
        "signature": "(l2_memory, layer1_config: Optional[insightspike.implementations.layers.layer1_stream_processor.Layer1Config] = None)",
        "docstring": "Helper class to integrate L1 with existing L2MemoryManager",
        "full_name": "insightspike.implementations.layers.layer1_stream_processor.L1IntegratedMemory",
        "tags": []
      },
      {
        "name": "Layer1Config",
        "module": "insightspike.implementations.layers.layer1_stream_processor",
        "type": "class",
        "signature": "(buffer_size: int = 4096, chunk_size: int = 256, flush_threshold: int = 512, embedding_dim: int = 768, use_fp16: bool = True, ssm_model: str = 'sentence-transformer', enable_ner: bool = False, max_entities: int = 10, batch_timeout: float = 0.1, async_processing: bool = True) -> None",
        "docstring": "Configuration for Layer1 stream processor",
        "full_name": "insightspike.implementations.layers.layer1_stream_processor.Layer1Config",
        "tags": []
      },
      {
        "name": "Layer1StreamProcessor",
        "module": "insightspike.implementations.layers.layer1_stream_processor",
        "type": "class",
        "signature": "(config: Optional[insightspike.implementations.layers.layer1_stream_processor.Layer1Config] = None)",
        "docstring": "Stream processor for converting raw input into episodes.",
        "full_name": "insightspike.implementations.layers.layer1_stream_processor.Layer1StreamProcessor",
        "tags": []
      },
      {
        "name": "CompatibleL2MemoryManager",
        "module": "insightspike.implementations.layers.layer2_compatibility",
        "type": "class",
        "signature": "(dim: int = 384, config=None)",
        "docstring": "Backward-compatible Layer 2 Memory Manager.",
        "full_name": "insightspike.implementations.layers.layer2_compatibility.CompatibleL2MemoryManager",
        "tags": []
      },
      {
        "name": "L2MemoryManager",
        "module": "insightspike.implementations.layers.layer2_compatibility",
        "type": "class",
        "signature": "(config: Union[insightspike.implementations.layers.layer2_memory_manager.MemoryConfig, Dict[str, Any], Any, NoneType] = None)",
        "docstring": "Layer 2 Memory Manager - Graph-centric episodic memory.",
        "full_name": "insightspike.implementations.layers.layer2_compatibility.L2MemoryManager",
        "tags": []
      },
      {
        "name": "MemoryConfig",
        "module": "insightspike.implementations.layers.layer2_compatibility",
        "type": "class",
        "signature": "(mode: insightspike.implementations.layers.layer2_memory_manager.MemoryMode = <MemoryMode.SCALABLE: 'scalable'>, embedding_dim: int = 384, max_episodes: int = 10000, enable_aging: bool = True, aging_factor: float = 0.95, min_age_days: int = 7, max_age_days: int = 90, prune_on_overflow: bool = True, use_c_values: bool = True, use_graph_integration: bool = False, use_conflict_detection: bool = False, use_importance_scoring: bool = False, use_scalable_indexing: bool = True, use_hierarchical_graph: bool = False, vector_search_backend: str = 'auto', similarity_threshold: float = 0.7, max_graph_edges: int = 10000, batch_size: int = 32, cache_embeddings: bool = True) -> None",
        "docstring": "Unified configuration for memory manager",
        "full_name": "insightspike.implementations.layers.layer2_compatibility.MemoryConfig",
        "tags": []
      },
      {
        "name": "MemoryMode",
        "module": "insightspike.implementations.layers.layer2_compatibility",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Different operation modes for memory management",
        "full_name": "insightspike.implementations.layers.layer2_compatibility.MemoryMode",
        "tags": []
      },
      {
        "name": "create_compatible_memory",
        "module": "insightspike.implementations.layers.layer2_compatibility",
        "type": "function",
        "signature": "(dim: int = 384, config=None) -> insightspike.implementations.layers.layer2_compatibility.CompatibleL2MemoryManager",
        "docstring": "Create backward-compatible memory manager",
        "full_name": "insightspike.implementations.layers.layer2_compatibility.create_compatible_memory",
        "tags": []
      },
      {
        "name": "EmbeddingManager",
        "module": "insightspike.implementations.layers.layer2_memory_manager",
        "type": "class",
        "signature": "(model_name: str = None, config=None, weight_manager=None)",
        "docstring": "Manages text embedding models with caching and fallback support.",
        "full_name": "insightspike.implementations.layers.layer2_memory_manager.EmbeddingManager",
        "tags": []
      },
      {
        "name": "EnhancedL2MemoryManager",
        "module": "insightspike.implementations.layers.layer2_memory_manager",
        "type": "class",
        "signature": "(config: Union[insightspike.implementations.layers.layer2_memory_manager.MemoryConfig, Dict[str, Any], Any, NoneType] = None)",
        "docstring": "Layer 2 Memory Manager - Graph-centric episodic memory.",
        "full_name": "insightspike.implementations.layers.layer2_memory_manager.EnhancedL2MemoryManager",
        "tags": []
      },
      {
        "name": "Episode",
        "module": "insightspike.implementations.layers.layer2_memory_manager",
        "type": "class",
        "signature": "(text: str, vec: numpy.ndarray, c: float = 0.5, timestamp: float = <factory>, metadata: Dict[str, Any] = <factory>, episode_type: str = 'experience', selection_count: int = 0, creation_time: float = <factory>, confidence: Optional[float] = None) -> None",
        "docstring": "Single memory entry with vector embedding, text, and C-value.",
        "full_name": "insightspike.implementations.layers.layer2_memory_manager.Episode",
        "tags": []
      },
      {
        "name": "GraphCentricMemoryManager",
        "module": "insightspike.implementations.layers.layer2_memory_manager",
        "type": "class",
        "signature": "(config: Union[insightspike.implementations.layers.layer2_memory_manager.MemoryConfig, Dict[str, Any], Any, NoneType] = None)",
        "docstring": "Layer 2 Memory Manager - Graph-centric episodic memory.",
        "full_name": "insightspike.implementations.layers.layer2_memory_manager.GraphCentricMemoryManager",
        "tags": []
      },
      {
        "name": "L2EnhancedScalableMemory",
        "module": "insightspike.implementations.layers.layer2_memory_manager",
        "type": "class",
        "signature": "(config: Union[insightspike.implementations.layers.layer2_memory_manager.MemoryConfig, Dict[str, Any], Any, NoneType] = None)",
        "docstring": "Layer 2 Memory Manager - Graph-centric episodic memory.",
        "full_name": "insightspike.implementations.layers.layer2_memory_manager.L2EnhancedScalableMemory",
        "tags": []
      },
      {
        "name": "L2MemoryManager",
        "module": "insightspike.implementations.layers.layer2_memory_manager",
        "type": "class",
        "signature": "(config: Union[insightspike.implementations.layers.layer2_memory_manager.MemoryConfig, Dict[str, Any], Any, NoneType] = None)",
        "docstring": "Layer 2 Memory Manager - Graph-centric episodic memory.",
        "full_name": "insightspike.implementations.layers.layer2_memory_manager.L2MemoryManager",
        "tags": []
      },
      {
        "name": "Memory",
        "module": "insightspike.implementations.layers.layer2_memory_manager",
        "type": "class",
        "signature": "(config: Union[insightspike.implementations.layers.layer2_memory_manager.MemoryConfig, Dict[str, Any], Any, NoneType] = None)",
        "docstring": "Layer 2 Memory Manager - Graph-centric episodic memory.",
        "full_name": "insightspike.implementations.layers.layer2_memory_manager.Memory",
        "tags": []
      },
      {
        "name": "MemoryConfig",
        "module": "insightspike.implementations.layers.layer2_memory_manager",
        "type": "class",
        "signature": "(mode: insightspike.implementations.layers.layer2_memory_manager.MemoryMode = <MemoryMode.SCALABLE: 'scalable'>, embedding_dim: int = 384, max_episodes: int = 10000, enable_aging: bool = True, aging_factor: float = 0.95, min_age_days: int = 7, max_age_days: int = 90, prune_on_overflow: bool = True, use_c_values: bool = True, use_graph_integration: bool = False, use_conflict_detection: bool = False, use_importance_scoring: bool = False, use_scalable_indexing: bool = True, use_hierarchical_graph: bool = False, vector_search_backend: str = 'auto', similarity_threshold: float = 0.7, max_graph_edges: int = 10000, batch_size: int = 32, cache_embeddings: bool = True) -> None",
        "docstring": "Unified configuration for memory manager",
        "full_name": "insightspike.implementations.layers.layer2_memory_manager.MemoryConfig",
        "tags": []
      },
      {
        "name": "MemoryMode",
        "module": "insightspike.implementations.layers.layer2_memory_manager",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Different operation modes for memory management",
        "full_name": "insightspike.implementations.layers.layer2_memory_manager.MemoryMode",
        "tags": []
      },
      {
        "name": "ScalableGraphBuilder",
        "module": "insightspike.implementations.layers.layer2_memory_manager",
        "type": "class",
        "signature": "(config=None, monitor: Optional[insightspike.monitoring.graph_monitor.GraphOperationMonitor] = None)",
        "docstring": "Build graphs efficiently using FAISS for nearest neighbor search.",
        "full_name": "insightspike.implementations.layers.layer2_memory_manager.ScalableGraphBuilder",
        "tags": []
      },
      {
        "name": "VectorIndexFactory",
        "module": "insightspike.implementations.layers.layer2_memory_manager",
        "type": "class",
        "signature": "()",
        "docstring": "Factory for creating vector indices.",
        "full_name": "insightspike.implementations.layers.layer2_memory_manager.VectorIndexFactory",
        "tags": []
      },
      {
        "name": "create_memory_manager",
        "module": "insightspike.implementations.layers.layer2_memory_manager",
        "type": "function",
        "signature": "(mode: str = 'scalable', **kwargs) -> insightspike.implementations.layers.layer2_memory_manager.L2MemoryManager",
        "docstring": "Create memory manager with specified mode",
        "full_name": "insightspike.implementations.layers.layer2_memory_manager.create_memory_manager",
        "tags": []
      },
      {
        "name": "get_config",
        "module": "insightspike.implementations.layers.layer2_memory_manager",
        "type": "function",
        "signature": "() -> insightspike.config.models.InsightSpikeConfig",
        "docstring": "Get current configuration or load defaults",
        "full_name": "insightspike.implementations.layers.layer2_memory_manager.get_config",
        "tags": []
      },
      {
        "name": "DataStore",
        "module": "insightspike.implementations.layers.layer2_working_memory",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for data persistence",
        "full_name": "insightspike.implementations.layers.layer2_working_memory.DataStore",
        "tags": []
      },
      {
        "name": "EmbeddingManager",
        "module": "insightspike.implementations.layers.layer2_working_memory",
        "type": "class",
        "signature": "(model_name: str = None, config=None, weight_manager=None)",
        "docstring": "Manages text embedding models with caching and fallback support.",
        "full_name": "insightspike.implementations.layers.layer2_working_memory.EmbeddingManager",
        "tags": []
      },
      {
        "name": "L2WorkingMemoryManager",
        "module": "insightspike.implementations.layers.layer2_working_memory",
        "type": "class",
        "signature": "(datastore: insightspike.core.base.datastore.DataStore, config: Union[insightspike.implementations.layers.layer2_working_memory.WorkingMemoryConfig, Any, NoneType] = None, embedding_manager: Optional[insightspike.processing.embedder.EmbeddingManager] = None)",
        "docstring": "Working memory based memory manager using DataStore.",
        "full_name": "insightspike.implementations.layers.layer2_working_memory.L2WorkingMemoryManager",
        "tags": []
      },
      {
        "name": "WorkingMemoryConfig",
        "module": "insightspike.implementations.layers.layer2_working_memory",
        "type": "class",
        "signature": "(working_memory_size: int = 100, search_k: int = 20, cache_embeddings: bool = True, embedding_cache_size: int = 1000, batch_size: int = 32, similarity_threshold: float = 0.7, datastore_namespace: str = 'episodes') -> None",
        "docstring": "Configuration for working memory manager",
        "full_name": "insightspike.implementations.layers.layer2_working_memory.WorkingMemoryConfig",
        "tags": []
      },
      {
        "name": "ConflictScore",
        "module": "insightspike.implementations.layers.layer3",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Conflict detection and scoring for graph reasoning.",
        "full_name": "insightspike.implementations.layers.layer3.ConflictScore",
        "tags": []
      },
      {
        "name": "EdgeReevaluator",
        "module": "insightspike.implementations.layers.layer3",
        "type": "class",
        "signature": "(*args, **kwargs) -> 'None'",
        "docstring": "No-op stub for edge reevaluation.",
        "full_name": "insightspike.implementations.layers.layer3.EdgeReevaluator",
        "tags": []
      },
      {
        "name": "GraphAnalyzer",
        "module": "insightspike.implementations.layers.layer3",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Analyzes graph structures and calculates metrics.",
        "full_name": "insightspike.implementations.layers.layer3.GraphAnalyzer",
        "tags": []
      },
      {
        "name": "GraphBuilder",
        "module": "insightspike.implementations.layers.layer3",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Build and manage PyTorch Geometric graphs from documents.",
        "full_name": "insightspike.implementations.layers.layer3.GraphBuilder",
        "tags": []
      },
      {
        "name": "L3GraphReasoner",
        "module": "insightspike.implementations.layers.layer3",
        "type": "class",
        "signature": "(*args, **kwargs)",
        "docstring": "Lazy proxy that instantiates the existing Layer3GraphReasoner.",
        "full_name": "insightspike.implementations.layers.layer3.L3GraphReasoner",
        "tags": []
      },
      {
        "name": "MessagePassing",
        "module": "insightspike.implementations.layers.layer3",
        "type": "class",
        "signature": "(*args, **kwargs) -> 'None'",
        "docstring": "No-op stub for environments without graph message passing.",
        "full_name": "insightspike.implementations.layers.layer3.MessagePassing",
        "tags": []
      },
      {
        "name": "MessagePassingController",
        "module": "insightspike.implementations.layers.layer3",
        "type": "class",
        "signature": "(config=None, original_config: 'Optional[Dict[str, Any]]' = None)",
        "docstring": "Initialize and hold message passing components based on config.",
        "full_name": "insightspike.implementations.layers.layer3.MessagePassingController",
        "tags": []
      },
      {
        "name": "MetricsController",
        "module": "insightspike.implementations.layers.layer3",
        "type": "class",
        "signature": "(config: 'Optional[Any]' = None)",
        "docstring": "Wrap MetricsSelector to expose delta_ged / delta_ig and info.",
        "full_name": "insightspike.implementations.layers.layer3.MetricsController",
        "tags": []
      },
      {
        "name": "RewardCalculator",
        "module": "insightspike.implementations.layers.layer3",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Calculates reward signals for memory updates.",
        "full_name": "insightspike.implementations.layers.layer3.RewardCalculator",
        "tags": []
      },
      {
        "name": "build_simple_gnn",
        "module": "insightspike.implementations.layers.layer3",
        "type": "function",
        "signature": "(input_dim: 'int', hidden_dim: 'int')",
        "docstring": "Return a simple 3-layer GCN or None if torch/PyG missing.",
        "full_name": "insightspike.implementations.layers.layer3.build_simple_gnn",
        "tags": []
      },
      {
        "name": "ConflictScore",
        "module": "insightspike.implementations.layers.layer3_graph_reasoner",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Conflict detection and scoring for graph reasoning.",
        "full_name": "insightspike.implementations.layers.layer3_graph_reasoner.ConflictScore",
        "tags": []
      },
      {
        "name": "Data",
        "module": "insightspike.implementations.layers.layer3_graph_reasoner",
        "type": "class",
        "signature": "(x=None, edge_index=None, **kw)",
        "docstring": "",
        "full_name": "insightspike.implementations.layers.layer3_graph_reasoner.Data",
        "tags": []
      },
      {
        "name": "Episode",
        "module": "insightspike.implementations.layers.layer3_graph_reasoner",
        "type": "class",
        "signature": "(text: str, vec: numpy.ndarray, c: float = 0.5, timestamp: float = <factory>, metadata: Dict[str, Any] = <factory>, episode_type: str = 'experience', selection_count: int = 0, creation_time: float = <factory>, confidence: Optional[float] = None) -> None",
        "docstring": "Single memory entry with vector embedding, text, and C-value.",
        "full_name": "insightspike.implementations.layers.layer3_graph_reasoner.Episode",
        "tags": []
      },
      {
        "name": "GCNConv",
        "module": "insightspike.implementations.layers.layer3_graph_reasoner",
        "type": "class",
        "signature": "(*a, **k)",
        "docstring": "",
        "full_name": "insightspike.implementations.layers.layer3_graph_reasoner.GCNConv",
        "tags": []
      },
      {
        "name": "GraphBuilder",
        "module": "insightspike.implementations.layers.layer3_graph_reasoner",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Build and manage PyTorch Geometric graphs from documents.",
        "full_name": "insightspike.implementations.layers.layer3_graph_reasoner.GraphBuilder",
        "tags": []
      },
      {
        "name": "L3GraphReasoner",
        "module": "insightspike.implementations.layers.layer3_graph_reasoner",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Enhanced graph reasoning layer with GNN processing and spike detection.",
        "full_name": "insightspike.implementations.layers.layer3_graph_reasoner.L3GraphReasoner",
        "tags": []
      },
      {
        "name": "L3GraphReasonerInterface",
        "module": "insightspike.implementations.layers.layer3_graph_reasoner",
        "type": "class",
        "signature": "(layer_id: str, config: Dict[str, Any] = None)",
        "docstring": "Layer 3: Graph Reasoner (PFC analog)",
        "full_name": "insightspike.implementations.layers.layer3_graph_reasoner.L3GraphReasonerInterface",
        "tags": []
      },
      {
        "name": "LayerInput",
        "module": "insightspike.implementations.layers.layer3_graph_reasoner",
        "type": "class",
        "signature": "(data: Any, metadata: Dict[str, Any] = None, context: Optional[Dict[str, Any]] = None) -> None",
        "docstring": "Standard input format for all layers",
        "full_name": "insightspike.implementations.layers.layer3_graph_reasoner.LayerInput",
        "tags": []
      },
      {
        "name": "LayerOutput",
        "module": "insightspike.implementations.layers.layer3_graph_reasoner",
        "type": "class",
        "signature": "(result: Any, confidence: float = 0.0, metadata: Dict[str, Any] = None, metrics: Dict[str, float] = None) -> None",
        "docstring": "Standard output format for all layers",
        "full_name": "insightspike.implementations.layers.layer3_graph_reasoner.LayerOutput",
        "tags": []
      },
      {
        "name": "LegacyConfigAdapter",
        "module": "insightspike.implementations.layers.layer3_graph_reasoner",
        "type": "class",
        "signature": "()",
        "docstring": "Adapter for converting legacy configurations to Pydantic models.",
        "full_name": "insightspike.implementations.layers.layer3_graph_reasoner.LegacyConfigAdapter",
        "tags": []
      },
      {
        "name": "ScalableGraphBuilder",
        "module": "insightspike.implementations.layers.layer3_graph_reasoner",
        "type": "class",
        "signature": "(config=None, monitor: Optional[insightspike.monitoring.graph_monitor.GraphOperationMonitor] = None)",
        "docstring": "Build graphs efficiently using FAISS for nearest neighbor search.",
        "full_name": "insightspike.implementations.layers.layer3_graph_reasoner.ScalableGraphBuilder",
        "tags": []
      },
      {
        "name": "advanced_delta_ged",
        "module": "insightspike.implementations.layers.layer3_graph_reasoner",
        "type": "function",
        "signature": "(g_old: networkx.classes.graph.Graph, g_new: networkx.classes.graph.Graph) -> float",
        "docstring": "Calculate graph edit distance delta.",
        "full_name": "insightspike.implementations.layers.layer3_graph_reasoner.advanced_delta_ged",
        "tags": []
      },
      {
        "name": "advanced_delta_ig",
        "module": "insightspike.implementations.layers.layer3_graph_reasoner",
        "type": "function",
        "signature": "(vecs_old: numpy.ndarray, vecs_new: numpy.ndarray, k: int = 8) -> float",
        "docstring": "Calculate information gain delta between two vector sets.",
        "full_name": "insightspike.implementations.layers.layer3_graph_reasoner.advanced_delta_ig",
        "tags": []
      },
      {
        "name": "cosine_similarity",
        "module": "insightspike.implementations.layers.layer3_graph_reasoner",
        "type": "function",
        "signature": "(a: numpy.ndarray, b: Optional[numpy.ndarray] = None)",
        "docstring": "",
        "full_name": "insightspike.implementations.layers.layer3_graph_reasoner.cosine_similarity",
        "tags": []
      },
      {
        "name": "get_config",
        "module": "insightspike.implementations.layers.layer3_graph_reasoner",
        "type": "function",
        "signature": "() -> insightspike.config.models.InsightSpikeConfig",
        "docstring": "Get current configuration or load defaults",
        "full_name": "insightspike.implementations.layers.layer3_graph_reasoner.get_config",
        "tags": []
      },
      {
        "name": "global_mean_pool",
        "module": "insightspike.implementations.layers.layer3_graph_reasoner",
        "type": "function",
        "signature": "(x, batch)",
        "docstring": "",
        "full_name": "insightspike.implementations.layers.layer3_graph_reasoner.global_mean_pool",
        "tags": []
      },
      {
        "name": "simple_delta_ged",
        "module": "insightspike.implementations.layers.layer3_graph_reasoner",
        "type": "function",
        "signature": "(g_old: networkx.classes.graph.Graph, g_new: networkx.classes.graph.Graph) -> float",
        "docstring": "Calculate graph edit distance delta.",
        "full_name": "insightspike.implementations.layers.layer3_graph_reasoner.simple_delta_ged",
        "tags": []
      },
      {
        "name": "simple_delta_ig",
        "module": "insightspike.implementations.layers.layer3_graph_reasoner",
        "type": "function",
        "signature": "(vecs_old: numpy.ndarray, vecs_new: numpy.ndarray, k: int = 8) -> float",
        "docstring": "Calculate information gain delta between two vector sets.",
        "full_name": "insightspike.implementations.layers.layer3_graph_reasoner.simple_delta_ig",
        "tags": []
      },
      {
        "name": "CleanLLMProvider",
        "module": "insightspike.implementations.layers.layer4_llm_interface",
        "type": "class",
        "signature": "(config: Union[insightspike.implementations.layers.layer4_llm_interface.LLMConfig, ForwardRef('InsightSpikeConfig'), Dict[str, Any], NoneType] = None)",
        "docstring": "Layer 4 Language Interface - Natural language synthesis.",
        "full_name": "insightspike.implementations.layers.layer4_llm_interface.CleanLLMProvider",
        "tags": []
      },
      {
        "name": "L4LLMInterface",
        "module": "insightspike.implementations.layers.layer4_llm_interface",
        "type": "class",
        "signature": "(config: Union[insightspike.implementations.layers.layer4_llm_interface.LLMConfig, ForwardRef('InsightSpikeConfig'), Dict[str, Any], NoneType] = None)",
        "docstring": "Layer 4 Language Interface - Natural language synthesis.",
        "full_name": "insightspike.implementations.layers.layer4_llm_interface.L4LLMInterface",
        "tags": []
      },
      {
        "name": "LLMConfig",
        "module": "insightspike.implementations.layers.layer4_llm_interface",
        "type": "class",
        "signature": "(provider: insightspike.implementations.layers.layer4_llm_interface.LLMProviderType = <LLMProviderType.CLEAN: 'clean'>, model_name: str = 'gpt-3.5-turbo', temperature: float = 0.7, max_tokens: int = 500, top_p: float = 0.9, api_key: Optional[str] = None, api_base: Optional[str] = None, timeout: int = 30, add_special_tokens: bool = True, use_system_prompt: bool = True, enable_caching: bool = False, enable_retry: bool = True, system_prompt: Optional[str] = None, prompt_template: Optional[str] = None, device: str = 'cpu', load_in_8bit: bool = False) -> None",
        "docstring": "Unified configuration for LLM providers",
        "full_name": "insightspike.implementations.layers.layer4_llm_interface.LLMConfig",
        "tags": []
      },
      {
        "name": "LLMProvider",
        "module": "insightspike.implementations.layers.layer4_llm_interface",
        "type": "class",
        "signature": "(config: Union[insightspike.implementations.layers.layer4_llm_interface.LLMConfig, ForwardRef('InsightSpikeConfig'), Dict[str, Any], NoneType] = None)",
        "docstring": "Layer 4 Language Interface - Natural language synthesis.",
        "full_name": "insightspike.implementations.layers.layer4_llm_interface.LLMProvider",
        "tags": []
      },
      {
        "name": "LLMProviderRegistry",
        "module": "insightspike.implementations.layers.layer4_llm_interface",
        "type": "class",
        "signature": "()",
        "docstring": "Registry for caching and reusing LLM provider instances.",
        "full_name": "insightspike.implementations.layers.layer4_llm_interface.LLMProviderRegistry",
        "tags": []
      },
      {
        "name": "LLMProviderType",
        "module": "insightspike.implementations.layers.layer4_llm_interface",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Available LLM provider types",
        "full_name": "insightspike.implementations.layers.layer4_llm_interface.LLMProviderType",
        "tags": []
      },
      {
        "name": "MockLLMProvider",
        "module": "insightspike.implementations.layers.layer4_llm_interface",
        "type": "class",
        "signature": "(config: Union[insightspike.implementations.layers.layer4_llm_interface.LLMConfig, ForwardRef('InsightSpikeConfig'), Dict[str, Any], NoneType] = None)",
        "docstring": "Layer 4 Language Interface - Natural language synthesis.",
        "full_name": "insightspike.implementations.layers.layer4_llm_interface.MockLLMProvider",
        "tags": []
      },
      {
        "name": "UnifiedLLMProvider",
        "module": "insightspike.implementations.layers.layer4_llm_interface",
        "type": "class",
        "signature": "(config: Union[insightspike.implementations.layers.layer4_llm_interface.LLMConfig, ForwardRef('InsightSpikeConfig'), Dict[str, Any], NoneType] = None)",
        "docstring": "Layer 4 Language Interface - Natural language synthesis.",
        "full_name": "insightspike.implementations.layers.layer4_llm_interface.UnifiedLLMProvider",
        "tags": []
      },
      {
        "name": "VectorIntegrator",
        "module": "insightspike.implementations.layers.layer4_llm_interface",
        "type": "class",
        "signature": "(weight_manager=None)",
        "docstring": "Unified vector integration for various InsightSpike operations.",
        "full_name": "insightspike.implementations.layers.layer4_llm_interface.VectorIntegrator",
        "tags": []
      },
      {
        "name": "get_llm_provider",
        "module": "insightspike.implementations.layers.layer4_llm_interface",
        "type": "function",
        "signature": "(config=None, safe_mode: bool = False, use_cache: bool = True) -> insightspike.implementations.layers.layer4_llm_interface.L4LLMInterface",
        "docstring": "Get LLM provider instance.",
        "full_name": "insightspike.implementations.layers.layer4_llm_interface.get_llm_provider",
        "tags": []
      },
      {
        "name": "L4Interface",
        "module": "insightspike.implementations.layers.layer4_prompt_builder",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for Layer 4 components.",
        "full_name": "insightspike.implementations.layers.layer4_prompt_builder.L4Interface",
        "tags": []
      },
      {
        "name": "L4PromptBuilder",
        "module": "insightspike.implementations.layers.layer4_prompt_builder",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Layer 4: Semantic Response Generation",
        "full_name": "insightspike.implementations.layers.layer4_prompt_builder.L4PromptBuilder",
        "tags": []
      },
      {
        "name": "Data",
        "module": "insightspike.implementations.layers.scalable_graph_builder",
        "type": "class",
        "signature": "(x, edge_index)",
        "docstring": "",
        "full_name": "insightspike.implementations.layers.scalable_graph_builder.Data",
        "tags": []
      },
      {
        "name": "GraphOperationMonitor",
        "module": "insightspike.implementations.layers.scalable_graph_builder",
        "type": "class",
        "signature": "(log_dir: Optional[pathlib._local.Path] = None, max_history: int = 1000, enable_file_logging: bool = True)",
        "docstring": "Monitor graph operations for performance and debugging.",
        "full_name": "insightspike.implementations.layers.scalable_graph_builder.GraphOperationMonitor",
        "tags": []
      },
      {
        "name": "LegacyConfigAdapter",
        "module": "insightspike.implementations.layers.scalable_graph_builder",
        "type": "class",
        "signature": "()",
        "docstring": "Adapter for converting legacy configurations to Pydantic models.",
        "full_name": "insightspike.implementations.layers.scalable_graph_builder.LegacyConfigAdapter",
        "tags": []
      },
      {
        "name": "MonitoredOperation",
        "module": "insightspike.implementations.layers.scalable_graph_builder",
        "type": "class",
        "signature": "(monitor: insightspike.monitoring.graph_monitor.GraphOperationMonitor, operation: str, graph_state_func: <built-in function callable>, metadata: Optional[Dict[str, Any]] = None)",
        "docstring": "Context manager for monitoring graph operations.",
        "full_name": "insightspike.implementations.layers.scalable_graph_builder.MonitoredOperation",
        "tags": []
      },
      {
        "name": "ScalableGraphBuilder",
        "module": "insightspike.implementations.layers.scalable_graph_builder",
        "type": "class",
        "signature": "(config=None, monitor: Optional[insightspike.monitoring.graph_monitor.GraphOperationMonitor] = None)",
        "docstring": "Build graphs efficiently using FAISS for nearest neighbor search.",
        "full_name": "insightspike.implementations.layers.scalable_graph_builder.ScalableGraphBuilder",
        "tags": []
      },
      {
        "name": "VectorIndexFactory",
        "module": "insightspike.implementations.layers.scalable_graph_builder",
        "type": "class",
        "signature": "()",
        "docstring": "Factory for creating vector indices.",
        "full_name": "insightspike.implementations.layers.scalable_graph_builder.VectorIndexFactory",
        "tags": []
      },
      {
        "name": "DataStore",
        "module": "insightspike.implementations.memory",
        "type": "class",
        "signature": "()",
        "docstring": "Abstract interface for data persistence",
        "full_name": "insightspike.implementations.memory.DataStore",
        "tags": []
      },
      {
        "name": "EmbeddingManager",
        "module": "insightspike.implementations.memory",
        "type": "class",
        "signature": "(model_name: str = None, config=None, weight_manager=None)",
        "docstring": "Manages text embedding models with caching and fallback support.",
        "full_name": "insightspike.implementations.memory.EmbeddingManager",
        "tags": []
      },
      {
        "name": "InMemoryDataStore",
        "module": "insightspike.implementations.memory",
        "type": "class",
        "signature": "()",
        "docstring": "In-memory data store implementation",
        "full_name": "insightspike.implementations.memory.InMemoryDataStore",
        "tags": []
      },
      {
        "name": "Memory",
        "module": "insightspike.implementations.memory",
        "type": "class",
        "signature": "(datastore: Optional[insightspike.core.base.datastore.DataStore] = None, namespace: str = 'episodes')",
        "docstring": "Legacy-compatible memory facade backed by a DataStore.",
        "full_name": "insightspike.implementations.memory.Memory",
        "tags": []
      },
      {
        "name": "GraphMemorySearch",
        "module": "insightspike.implementations.memory.graph_memory_search",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Enhanced memory search using graph traversal.",
        "full_name": "insightspike.implementations.memory.graph_memory_search.GraphMemorySearch",
        "tags": []
      },
      {
        "name": "Data",
        "module": "insightspike.implementations.memory.knowledge_graph_memory",
        "type": "class",
        "signature": "(x=None, edge_index=None)",
        "docstring": "Fallback Data class for basic graph functionality without torch-geometric.",
        "full_name": "insightspike.implementations.memory.knowledge_graph_memory.Data",
        "tags": []
      },
      {
        "name": "KnowledgeGraphMemory",
        "module": "insightspike.implementations.memory.knowledge_graph_memory",
        "type": "class",
        "signature": "(embedding_dim: 'int', similarity_threshold: 'float' = 0.2)",
        "docstring": "Persistent knowledge graph storing episode embeddings.",
        "full_name": "insightspike.implementations.memory.knowledge_graph_memory.KnowledgeGraphMemory",
        "tags": []
      },
      {
        "name": "subgraph",
        "module": "insightspike.implementations.memory.knowledge_graph_memory",
        "type": "function",
        "signature": "(node_tensor, edge_index, relabel_nodes=True, num_nodes=None)",
        "docstring": "Fallback subgraph function for basic functionality without torch-geometric.",
        "full_name": "insightspike.implementations.memory.knowledge_graph_memory.subgraph",
        "tags": []
      },
      {
        "name": "BackwardCompatibleWrapper",
        "module": "insightspike.index",
        "type": "class",
        "signature": "(index_or_dimension: 'Any' = 384)",
        "docstring": "",
        "full_name": "insightspike.index.BackwardCompatibleWrapper",
        "tags": []
      },
      {
        "name": "IntegratedVectorGraphIndex",
        "module": "insightspike.index",
        "type": "class",
        "signature": "(dimension: 'int' = 384)",
        "docstring": "",
        "full_name": "insightspike.index.IntegratedVectorGraphIndex",
        "tags": []
      },
      {
        "name": "MigrationHelper",
        "module": "insightspike.index",
        "type": "class",
        "signature": "()",
        "docstring": "\u65e2\u5b58\u30b7\u30b9\u30c6\u30e0\u304b\u3089\u7d71\u5408\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3078\u306e\u79fb\u884c\u3092\u652f\u63f4",
        "full_name": "insightspike.index.MigrationHelper",
        "tags": []
      },
      {
        "name": "BackwardCompatibleWrapper",
        "module": "insightspike.index.backward_compatible_wrapper",
        "type": "class",
        "signature": "(index_or_dimension: 'Any' = 384)",
        "docstring": "",
        "full_name": "insightspike.index.backward_compatible_wrapper.BackwardCompatibleWrapper",
        "tags": []
      },
      {
        "name": "IntegratedVectorGraphIndex",
        "module": "insightspike.index.backward_compatible_wrapper",
        "type": "class",
        "signature": "(dimension: 'int' = 384)",
        "docstring": "",
        "full_name": "insightspike.index.backward_compatible_wrapper.IntegratedVectorGraphIndex",
        "tags": []
      },
      {
        "name": "IntegratedVectorGraphIndex",
        "module": "insightspike.index.integrated_vector_graph_index",
        "type": "class",
        "signature": "(dimension: 'int' = 384)",
        "docstring": "",
        "full_name": "insightspike.index.integrated_vector_graph_index.IntegratedVectorGraphIndex",
        "tags": []
      },
      {
        "name": "IntegratedVectorGraphIndex",
        "module": "insightspike.index.migration_helper",
        "type": "class",
        "signature": "(dimension: 'int' = 384)",
        "docstring": "",
        "full_name": "insightspike.index.migration_helper.IntegratedVectorGraphIndex",
        "tags": []
      },
      {
        "name": "MigrationHelper",
        "module": "insightspike.index.migration_helper",
        "type": "class",
        "signature": "()",
        "docstring": "\u65e2\u5b58\u30b7\u30b9\u30c6\u30e0\u304b\u3089\u7d71\u5408\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3078\u306e\u79fb\u884c\u3092\u652f\u63f4",
        "full_name": "insightspike.index.migration_helper.MigrationHelper",
        "tags": []
      },
      {
        "name": "AssessmentResult",
        "module": "insightspike.integrations",
        "type": "class",
        "signature": "(student_id: str, concept: str, mastery_score: float, insight_moments: List[str], cross_domain_connections: List[str], recommendation: str, next_steps: List[str], timestamp: datetime.datetime) -> None",
        "docstring": "Assessment result with InsightSpike analysis",
        "full_name": "insightspike.integrations.AssessmentResult",
        "tags": []
      },
      {
        "name": "EducationalSystemIntegration",
        "module": "insightspike.integrations",
        "type": "class",
        "signature": "(system_name: str = 'InsightSpike-Educational-AI')",
        "docstring": "Integration framework for real educational systems",
        "full_name": "insightspike.integrations.EducationalSystemIntegration",
        "tags": []
      },
      {
        "name": "LearningPath",
        "module": "insightspike.integrations",
        "type": "class",
        "signature": "(student_id: str, subject: str, current_level: int, target_level: int, recommended_concepts: List[str], estimated_duration: int, success_probability: float, adaptive_checkpoints: List[Dict]) -> None",
        "docstring": "Personalized learning path generated by InsightSpike-AI",
        "full_name": "insightspike.integrations.LearningPath",
        "tags": []
      },
      {
        "name": "Student",
        "module": "insightspike.integrations",
        "type": "class",
        "signature": "(id: str, name: str, age: int, grade_level: int, learning_style: str, performance_history: List[Dict] = None, strengths: List[str] = None, challenges: List[str] = None) -> None",
        "docstring": "Student profile for personalized learning",
        "full_name": "insightspike.integrations.Student",
        "tags": []
      },
      {
        "name": "AssessmentResult",
        "module": "insightspike.integrations.educational",
        "type": "class",
        "signature": "(student_id: str, concept: str, mastery_score: float, insight_moments: List[str], cross_domain_connections: List[str], recommendation: str, next_steps: List[str], timestamp: datetime.datetime) -> None",
        "docstring": "Assessment result with InsightSpike analysis",
        "full_name": "insightspike.integrations.educational.AssessmentResult",
        "tags": []
      },
      {
        "name": "EducationalSystemIntegration",
        "module": "insightspike.integrations.educational",
        "type": "class",
        "signature": "(system_name: str = 'InsightSpike-Educational-AI')",
        "docstring": "Integration framework for real educational systems",
        "full_name": "insightspike.integrations.educational.EducationalSystemIntegration",
        "tags": []
      },
      {
        "name": "LearningPath",
        "module": "insightspike.integrations.educational",
        "type": "class",
        "signature": "(student_id: str, subject: str, current_level: int, target_level: int, recommended_concepts: List[str], estimated_duration: int, success_probability: float, adaptive_checkpoints: List[Dict]) -> None",
        "docstring": "Personalized learning path generated by InsightSpike-AI",
        "full_name": "insightspike.integrations.educational.LearningPath",
        "tags": []
      },
      {
        "name": "Student",
        "module": "insightspike.integrations.educational",
        "type": "class",
        "signature": "(id: str, name: str, age: int, grade_level: int, learning_style: str, performance_history: List[Dict] = None, strengths: List[str] = None, challenges: List[str] = None) -> None",
        "docstring": "Student profile for personalized learning",
        "full_name": "insightspike.integrations.educational.Student",
        "tags": []
      },
      {
        "name": "PatternLogger",
        "module": "insightspike.learning",
        "type": "class",
        "signature": "(config=None, log_dir: Optional[str] = None)",
        "docstring": "Logs and analyzes successful reasoning patterns for learning.",
        "full_name": "insightspike.learning.PatternLogger",
        "tags": []
      },
      {
        "name": "ReasoningPattern",
        "module": "insightspike.learning",
        "type": "class",
        "signature": "(question: str, question_embedding: Optional[List[float]], retrieved_docs: List[Dict[str, Any]], graph_metrics: Dict[str, float], reward: float, spike_detected: bool, response_quality: float, timestamp: float, similarity_threshold: float, hop_limit: int, path_decay: float, user_feedback: Optional[float] = None, concepts_discovered: List[str] = None, insights_generated: List[str] = None) -> None",
        "docstring": "Represents a successful reasoning pattern",
        "full_name": "insightspike.learning.ReasoningPattern",
        "tags": []
      },
      {
        "name": "StrategyOptimizer",
        "module": "insightspike.learning",
        "type": "class",
        "signature": "(config=None, pattern_logger: Optional[insightspike.learning.pattern_logger.PatternLogger] = None)",
        "docstring": "Optimizes system strategies based on learning from past patterns.",
        "full_name": "insightspike.learning.StrategyOptimizer",
        "tags": []
      },
      {
        "name": "PatternLogger",
        "module": "insightspike.learning.pattern_logger",
        "type": "class",
        "signature": "(config=None, log_dir: Optional[str] = None)",
        "docstring": "Logs and analyzes successful reasoning patterns for learning.",
        "full_name": "insightspike.learning.pattern_logger.PatternLogger",
        "tags": []
      },
      {
        "name": "ReasoningPattern",
        "module": "insightspike.learning.pattern_logger",
        "type": "class",
        "signature": "(question: str, question_embedding: Optional[List[float]], retrieved_docs: List[Dict[str, Any]], graph_metrics: Dict[str, float], reward: float, spike_detected: bool, response_quality: float, timestamp: float, similarity_threshold: float, hop_limit: int, path_decay: float, user_feedback: Optional[float] = None, concepts_discovered: List[str] = None, insights_generated: List[str] = None) -> None",
        "docstring": "Represents a successful reasoning pattern",
        "full_name": "insightspike.learning.pattern_logger.ReasoningPattern",
        "tags": []
      },
      {
        "name": "PatternLogger",
        "module": "insightspike.learning.strategy_optimizer",
        "type": "class",
        "signature": "(config=None, log_dir: Optional[str] = None)",
        "docstring": "Logs and analyzes successful reasoning patterns for learning.",
        "full_name": "insightspike.learning.strategy_optimizer.PatternLogger",
        "tags": []
      },
      {
        "name": "ReasoningPattern",
        "module": "insightspike.learning.strategy_optimizer",
        "type": "class",
        "signature": "(question: str, question_embedding: Optional[List[float]], retrieved_docs: List[Dict[str, Any]], graph_metrics: Dict[str, float], reward: float, spike_detected: bool, response_quality: float, timestamp: float, similarity_threshold: float, hop_limit: int, path_decay: float, user_feedback: Optional[float] = None, concepts_discovered: List[str] = None, insights_generated: List[str] = None) -> None",
        "docstring": "Represents a successful reasoning pattern",
        "full_name": "insightspike.learning.strategy_optimizer.ReasoningPattern",
        "tags": []
      },
      {
        "name": "StrategyOptimizer",
        "module": "insightspike.learning.strategy_optimizer",
        "type": "class",
        "signature": "(config=None, pattern_logger: Optional[insightspike.learning.pattern_logger.PatternLogger] = None)",
        "docstring": "Optimizes system strategies based on learning from past patterns.",
        "full_name": "insightspike.learning.strategy_optimizer.StrategyOptimizer",
        "tags": []
      },
      {
        "name": "analyze_insight",
        "module": "insightspike.metrics",
        "type": "function",
        "signature": "(before_state: Any, after_state: Any, weights: Optional[Dict[str, float]] = None, thresholds: Optional[Dict[str, float]] = None) -> Dict",
        "docstring": "Public API: Complete insight analysis between two states.",
        "full_name": "insightspike.metrics.analyze_insight",
        "tags": []
      },
      {
        "name": "apply_preset_configuration",
        "module": "insightspike.metrics",
        "type": "function",
        "signature": "(preset_name: str) -> Dict[str, Any]",
        "docstring": "Apply a preset configuration and return the configuration details.",
        "full_name": "insightspike.metrics.apply_preset_configuration",
        "tags": []
      },
      {
        "name": "compute_delta_ged",
        "module": "insightspike.metrics",
        "type": "function",
        "signature": "(graph_before: Any, graph_after: Any, **kwargs) -> float",
        "docstring": "Public API: Calculate Graph Edit Distance change between two knowledge states.",
        "full_name": "insightspike.metrics.compute_delta_ged",
        "tags": []
      },
      {
        "name": "compute_delta_ig",
        "module": "insightspike.metrics",
        "type": "function",
        "signature": "(state_before: Any, state_after: Any, **kwargs) -> float",
        "docstring": "Public API: Calculate Information Gain change between cognitive states.",
        "full_name": "insightspike.metrics.compute_delta_ig",
        "tags": []
      },
      {
        "name": "compute_fusion_reward",
        "module": "insightspike.metrics",
        "type": "function",
        "signature": "(delta_ged: float, delta_ig: float, conflict_score: float = 0.0, weights: Optional[Dict[str, float]] = None) -> float",
        "docstring": "Public API: Calculate combined insight reward using fusion scheme.",
        "full_name": "insightspike.metrics.compute_fusion_reward",
        "tags": []
      },
      {
        "name": "configure_default_weights",
        "module": "insightspike.metrics",
        "type": "function",
        "signature": "(ged_weight: float = 0.5, ig_weight: float = 0.5, conflict_weight: float = 0.0)",
        "docstring": "Configure default weights for fusion reward calculation.",
        "full_name": "insightspike.metrics.configure_default_weights",
        "tags": []
      },
      {
        "name": "delta_ged",
        "module": "insightspike.metrics",
        "type": "function",
        "signature": "(g_old: networkx.classes.graph.Graph, g_new: networkx.classes.graph.Graph) -> float",
        "docstring": "Calculate graph edit distance delta.",
        "full_name": "insightspike.metrics.delta_ged",
        "tags": []
      },
      {
        "name": "delta_ig",
        "module": "insightspike.metrics",
        "type": "function",
        "signature": "(vecs_old: numpy.ndarray, vecs_new: numpy.ndarray, k: int = 8) -> float",
        "docstring": "Calculate information gain delta between two vector sets.",
        "full_name": "insightspike.metrics.delta_ig",
        "tags": []
      },
      {
        "name": "get_algorithm_metadata",
        "module": "insightspike.metrics",
        "type": "function",
        "signature": "() -> Dict[str, Any]",
        "docstring": "Get comprehensive metadata about available algorithms and configurations.",
        "full_name": "insightspike.metrics.get_algorithm_metadata",
        "tags": []
      },
      {
        "name": "get_preset_configurations",
        "module": "insightspike.metrics",
        "type": "function",
        "signature": "() -> Dict[str, Dict]",
        "docstring": "Get preset configurations for different use cases.",
        "full_name": "insightspike.metrics.get_preset_configurations",
        "tags": []
      },
      {
        "name": "delta_ged",
        "module": "insightspike.metrics.graph_metrics",
        "type": "function",
        "signature": "(g_old: networkx.classes.graph.Graph, g_new: networkx.classes.graph.Graph) -> float",
        "docstring": "Calculate graph edit distance delta.",
        "full_name": "insightspike.metrics.graph_metrics.delta_ged",
        "tags": []
      },
      {
        "name": "delta_ig",
        "module": "insightspike.metrics.graph_metrics",
        "type": "function",
        "signature": "(vecs_old: numpy.ndarray, vecs_new: numpy.ndarray, k: int = 8) -> float",
        "docstring": "Calculate information gain delta between two vector sets.",
        "full_name": "insightspike.metrics.graph_metrics.delta_ig",
        "tags": []
      },
      {
        "name": "GEDIGMetrics",
        "module": "insightspike.metrics.improved_gedig_metrics",
        "type": "class",
        "signature": "(ged: float, ig: float, structural_improvement: float, knowledge_coherence: float, analogy_bonus: float = 0.0, is_analogy: bool = False, insight_score: float = 0.0, spike_detected: bool = False, spike_intensity: float = 0.0) -> None",
        "docstring": "Complete GEDIG metrics with clear semantics.",
        "full_name": "insightspike.metrics.improved_gedig_metrics.GEDIGMetrics",
        "tags": []
      },
      {
        "name": "ImprovedGEDIGCalculator",
        "module": "insightspike.metrics.improved_gedig_metrics",
        "type": "class",
        "signature": "(structure_weight: float = 0.5, knowledge_weight: float = 0.5, spike_threshold: float = 0.4, enable_similarity: bool = False, similarity_threshold: float = 0.7, similarity_weight: float = 0.5, cross_domain_only: bool = True, require_prototype: bool = True)",
        "docstring": "Calculates GEDIG metrics with proper separation of concerns.",
        "full_name": "insightspike.metrics.improved_gedig_metrics.ImprovedGEDIGCalculator",
        "tags": []
      },
      {
        "name": "calculate_gedig_metrics",
        "module": "insightspike.metrics.improved_gedig_metrics",
        "type": "function",
        "signature": "(graph_before: Any, graph_after: Any, vectors_before: Any = None, vectors_after: Any = None, config: Optional[Dict] = None, analogy_context: Optional[Dict] = None) -> insightspike.metrics.improved_gedig_metrics.GEDIGMetrics",
        "docstring": "Convenience function for GEDIG calculation.",
        "full_name": "insightspike.metrics.improved_gedig_metrics.calculate_gedig_metrics",
        "tags": []
      },
      {
        "name": "compute_gedig_legacy",
        "module": "insightspike.metrics.improved_gedig_metrics",
        "type": "function",
        "signature": "(delta_ged: float, delta_ig: float, weights: Optional[Dict[str, float]] = None) -> Dict[str, Any]",
        "docstring": "Legacy compatibility wrapper that works with negative GED.",
        "full_name": "insightspike.metrics.improved_gedig_metrics.compute_gedig_legacy",
        "tags": []
      },
      {
        "name": "PSZSummary",
        "module": "insightspike.metrics.psz",
        "type": "class",
        "signature": "(acceptance_rate: 'float', fmr: 'float', latency_p50_ms: 'float', inside_psz: 'bool') -> None",
        "docstring": "PSZSummary(acceptance_rate: 'float', fmr: 'float', latency_p50_ms: 'float', inside_psz: 'bool')",
        "full_name": "insightspike.metrics.psz.PSZSummary",
        "tags": []
      },
      {
        "name": "PSZThresholds",
        "module": "insightspike.metrics.psz",
        "type": "class",
        "signature": "(acceptance: 'float' = 0.95, fmr: 'float' = 0.02, latency_p50_ms: 'float' = 200.0) -> None",
        "docstring": "PSZThresholds(acceptance: 'float' = 0.95, fmr: 'float' = 0.02, latency_p50_ms: 'float' = 200.0)",
        "full_name": "insightspike.metrics.psz.PSZThresholds",
        "tags": []
      },
      {
        "name": "inside_psz",
        "module": "insightspike.metrics.psz",
        "type": "function",
        "signature": "(summary: 'PSZSummary', thresholds: 'PSZThresholds' = PSZThresholds(acceptance=0.95, fmr=0.02, latency_p50_ms=200.0)) -> 'bool'",
        "docstring": "",
        "full_name": "insightspike.metrics.psz.inside_psz",
        "tags": []
      },
      {
        "name": "summarize_accept_latency",
        "module": "insightspike.metrics.psz",
        "type": "function",
        "signature": "(samples: 'Iterable[Dict[str, Any]]') -> 'PSZSummary'",
        "docstring": "",
        "full_name": "insightspike.metrics.psz.summarize_accept_latency",
        "tags": []
      },
      {
        "name": "delta_ged_pyg",
        "module": "insightspike.metrics.pyg_compatible_metrics",
        "type": "function",
        "signature": "(g_old: Any, g_new: Any) -> float",
        "docstring": "Calculate \u0394GED for PyTorch Geometric graphs.",
        "full_name": "insightspike.metrics.pyg_compatible_metrics.delta_ged_pyg",
        "tags": []
      },
      {
        "name": "delta_ig_pyg",
        "module": "insightspike.metrics.pyg_compatible_metrics",
        "type": "function",
        "signature": "(g_old: Any, g_new: Any) -> float",
        "docstring": "Calculate \u0394IG for PyG graphs using variance proxy.",
        "full_name": "insightspike.metrics.pyg_compatible_metrics.delta_ig_pyg",
        "tags": []
      },
      {
        "name": "pyg_to_networkx",
        "module": "insightspike.metrics.pyg_compatible_metrics",
        "type": "function",
        "signature": "(pyg_graph: Any) -> networkx.classes.graph.Graph",
        "docstring": "Convert a minimal PyG-like Data object to NetworkX safely.",
        "full_name": "insightspike.metrics.pyg_compatible_metrics.pyg_to_networkx",
        "tags": []
      },
      {
        "name": "GeDIGNavigator",
        "module": "insightspike.metrics.validation_helpers",
        "type": "class",
        "signature": "(config: insightspike.maze_experimental.maze_config.MazeNavigatorConfig)",
        "docstring": "Navigator using geDIG principles for maze exploration.",
        "full_name": "insightspike.metrics.validation_helpers.GeDIGNavigator",
        "tags": []
      },
      {
        "name": "MazeNavigatorConfig",
        "module": "insightspike.metrics.validation_helpers",
        "type": "class",
        "signature": "(*, node_creation_cost: float = 0.0, search_radius: float = 5.0, donut_inner_radius: float = 0.0, donut_outer_radius: float = 3.0, exploration_epsilon: float = 0.1, wall_penalty: float = 0.0, unknown_bonus: float = 0.0, w_ged: float = 1.0, k_ig: float = 2.0, temperature: float = 1.0, ged_weight: float = 1.0, ig_weight: float = 2.0, sleep_interval: int = 10, sleep_optimization_steps: int = 50, feature_dim: int = 16, use_pretrained_embedder: bool = False, use_refactored_gedig: bool = True, enable_dual_evaluate: bool = False, dual_delta_threshold: float = 0.3, structural_improvement_weight: float = 0.5, spike_outcome_mode: str = 'mirror', tau_s: float = 0.15, tau_i: float = 0.25, spike_detection_mode: str = 'and') -> None",
        "docstring": "Configuration for maze navigation with geDIG.",
        "full_name": "insightspike.metrics.validation_helpers.MazeNavigatorConfig",
        "tags": []
      },
      {
        "name": "MazeObservation",
        "module": "insightspike.metrics.validation_helpers",
        "type": "class",
        "signature": "(position: Tuple[int, int], cell_type: insightspike.environments.maze.CellType, num_paths: int, possible_moves: List[int], hit_wall: bool = False, is_junction: bool = False, is_dead_end: bool = False, is_goal: bool = False) -> None",
        "docstring": "Observation from the maze environment.",
        "full_name": "insightspike.metrics.validation_helpers.MazeObservation",
        "tags": []
      },
      {
        "name": "SimpleMaze",
        "module": "insightspike.metrics.validation_helpers",
        "type": "class",
        "signature": "(size: Tuple[int, int] = (20, 20), maze_layout: Optional[numpy.ndarray] = None, start_pos: Optional[Tuple[int, int]] = None, goal_pos: Optional[Tuple[int, int]] = None, maze_type: str = 'simple')",
        "docstring": "Simple 2D maze environment for InsightSpike experiments.",
        "full_name": "insightspike.metrics.validation_helpers.SimpleMaze",
        "tags": []
      },
      {
        "name": "StabilityResult",
        "module": "insightspike.metrics.validation_helpers",
        "type": "class",
        "signature": "(rewards: 'List[float]', mean: 'float', std: 'float', cv: 'float', outlier_rate: 'float', nonzero_fraction: 'float', stable_via_primary: 'bool', stable_via_sparse_fallback: 'bool') -> None",
        "docstring": "StabilityResult(rewards: 'List[float]', mean: 'float', std: 'float', cv: 'float', outlier_rate: 'float', nonzero_fraction: 'float', stable_via_primary: 'bool', stable_via_sparse_fallback: 'bool')",
        "full_name": "insightspike.metrics.validation_helpers.StabilityResult",
        "tags": []
      },
      {
        "name": "run_small_maze_stability",
        "module": "insightspike.metrics.validation_helpers",
        "type": "function",
        "signature": "(seed: 'int' = 20250823, size: 'Tuple[int, int]' = (20, 20), steps: 'int' = 150, warmup: 'int' = 10, navigator_config: 'Dict[str, Any] | None' = None, filter_zero: 'bool' = True) -> 'StabilityResult'",
        "docstring": "Run a small maze stability episode and compute reward CV after warmup.",
        "full_name": "insightspike.metrics.validation_helpers.run_small_maze_stability",
        "tags": []
      },
      {
        "name": "run_spike_reproducibility",
        "module": "insightspike.metrics.validation_helpers",
        "type": "function",
        "signature": "(seeds: 'Sequence[int]', size: 'Tuple[int, int]' = (20, 20), max_steps: 'int' = 1200, navigator_config: 'Dict[str, Any] | None' = None) -> 'Dict[str, Any]'",
        "docstring": "Measure reproducibility of first spike occurrence across seeds.",
        "full_name": "insightspike.metrics.validation_helpers.run_spike_reproducibility",
        "tags": []
      },
      {
        "name": "GraphOperationMetric",
        "module": "insightspike.monitoring",
        "type": "class",
        "signature": "(operation: str, timestamp: float, duration: float, nodes_before: int, nodes_after: int, edges_before: int, edges_after: int, metadata: Dict[str, Any] = <factory>) -> None",
        "docstring": "Single metric for a graph operation.",
        "full_name": "insightspike.monitoring.GraphOperationMetric",
        "tags": []
      },
      {
        "name": "GraphOperationMonitor",
        "module": "insightspike.monitoring",
        "type": "class",
        "signature": "(log_dir: Optional[pathlib._local.Path] = None, max_history: int = 1000, enable_file_logging: bool = True)",
        "docstring": "Monitor graph operations for performance and debugging.",
        "full_name": "insightspike.monitoring.GraphOperationMonitor",
        "tags": []
      },
      {
        "name": "IndexMonitoringDecorator",
        "module": "insightspike.monitoring",
        "type": "class",
        "signature": "(index, monitor: Optional[insightspike.monitoring.index_monitor.IndexPerformanceMonitor] = None)",
        "docstring": "\u7d71\u5408\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306b\u30e2\u30cb\u30bf\u30ea\u30f3\u30b0\u6a5f\u80fd\u3092\u8ffd\u52a0\u3059\u308b\u30c7\u30b3\u30ec\u30fc\u30bf",
        "full_name": "insightspike.monitoring.IndexMonitoringDecorator",
        "tags": []
      },
      {
        "name": "IndexPerformanceMonitor",
        "module": "insightspike.monitoring",
        "type": "class",
        "signature": "(window_size: int = 1000)",
        "docstring": "\u7d71\u5408\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u76e3\u8996",
        "full_name": "insightspike.monitoring.IndexPerformanceMonitor",
        "tags": []
      },
      {
        "name": "MonitoredOperation",
        "module": "insightspike.monitoring",
        "type": "class",
        "signature": "(monitor: insightspike.monitoring.graph_monitor.GraphOperationMonitor, operation: str, graph_state_func: <built-in function callable>, metadata: Optional[Dict[str, Any]] = None)",
        "docstring": "Context manager for monitoring graph operations.",
        "full_name": "insightspike.monitoring.MonitoredOperation",
        "tags": []
      },
      {
        "name": "create_default_monitor",
        "module": "insightspike.monitoring",
        "type": "function",
        "signature": "() -> insightspike.monitoring.graph_monitor.GraphOperationMonitor",
        "docstring": "Create a monitor with default settings.",
        "full_name": "insightspike.monitoring.create_default_monitor",
        "tags": []
      },
      {
        "name": "GraphOperationMetric",
        "module": "insightspike.monitoring.graph_monitor",
        "type": "class",
        "signature": "(operation: str, timestamp: float, duration: float, nodes_before: int, nodes_after: int, edges_before: int, edges_after: int, metadata: Dict[str, Any] = <factory>) -> None",
        "docstring": "Single metric for a graph operation.",
        "full_name": "insightspike.monitoring.graph_monitor.GraphOperationMetric",
        "tags": []
      },
      {
        "name": "GraphOperationMonitor",
        "module": "insightspike.monitoring.graph_monitor",
        "type": "class",
        "signature": "(log_dir: Optional[pathlib._local.Path] = None, max_history: int = 1000, enable_file_logging: bool = True)",
        "docstring": "Monitor graph operations for performance and debugging.",
        "full_name": "insightspike.monitoring.graph_monitor.GraphOperationMonitor",
        "tags": []
      },
      {
        "name": "MonitoredOperation",
        "module": "insightspike.monitoring.graph_monitor",
        "type": "class",
        "signature": "(monitor: insightspike.monitoring.graph_monitor.GraphOperationMonitor, operation: str, graph_state_func: <built-in function callable>, metadata: Optional[Dict[str, Any]] = None)",
        "docstring": "Context manager for monitoring graph operations.",
        "full_name": "insightspike.monitoring.graph_monitor.MonitoredOperation",
        "tags": []
      },
      {
        "name": "create_default_monitor",
        "module": "insightspike.monitoring.graph_monitor",
        "type": "function",
        "signature": "() -> insightspike.monitoring.graph_monitor.GraphOperationMonitor",
        "docstring": "Create a monitor with default settings.",
        "full_name": "insightspike.monitoring.graph_monitor.create_default_monitor",
        "tags": []
      },
      {
        "name": "IndexMonitoringDecorator",
        "module": "insightspike.monitoring.index_monitor",
        "type": "class",
        "signature": "(index, monitor: Optional[insightspike.monitoring.index_monitor.IndexPerformanceMonitor] = None)",
        "docstring": "\u7d71\u5408\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306b\u30e2\u30cb\u30bf\u30ea\u30f3\u30b0\u6a5f\u80fd\u3092\u8ffd\u52a0\u3059\u308b\u30c7\u30b3\u30ec\u30fc\u30bf",
        "full_name": "insightspike.monitoring.index_monitor.IndexMonitoringDecorator",
        "tags": []
      },
      {
        "name": "IndexPerformanceMonitor",
        "module": "insightspike.monitoring.index_monitor",
        "type": "class",
        "signature": "(window_size: int = 1000)",
        "docstring": "\u7d71\u5408\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306e\u30d1\u30d5\u30a9\u30fc\u30de\u30f3\u30b9\u3092\u76e3\u8996",
        "full_name": "insightspike.monitoring.index_monitor.IndexPerformanceMonitor",
        "tags": []
      },
      {
        "name": "MemoryMonitor",
        "module": "insightspike.monitoring.memory_monitor",
        "type": "class",
        "signature": "(warning_threshold_mb: float = 2048, critical_threshold_mb: float = 4096, check_interval_seconds: float = 60)",
        "docstring": "Monitor memory usage and trigger warnings/actions when thresholds are exceeded.",
        "full_name": "insightspike.monitoring.memory_monitor.MemoryMonitor",
        "tags": []
      },
      {
        "name": "MemorySnapshot",
        "module": "insightspike.monitoring.memory_monitor",
        "type": "class",
        "signature": "(timestamp: float, memory_mb: float, episode_count: int, cache_size: int, details: Dict[str, float]) -> None",
        "docstring": "Memory usage snapshot",
        "full_name": "insightspike.monitoring.memory_monitor.MemorySnapshot",
        "tags": []
      },
      {
        "name": "check_memory_usage",
        "module": "insightspike.monitoring.memory_monitor",
        "type": "function",
        "signature": "(episode_count: int = 0, cache_size: int = 0) -> Optional[float]",
        "docstring": "Quick memory check helper",
        "full_name": "insightspike.monitoring.memory_monitor.check_memory_usage",
        "tags": []
      },
      {
        "name": "get_memory_monitor",
        "module": "insightspike.monitoring.memory_monitor",
        "type": "function",
        "signature": "() -> insightspike.monitoring.memory_monitor.MemoryMonitor",
        "docstring": "Get or create global memory monitor",
        "full_name": "insightspike.monitoring.memory_monitor.get_memory_monitor",
        "tags": []
      },
      {
        "name": "get_model",
        "module": "insightspike.processing",
        "type": "function",
        "signature": "(model_name: str = None)",
        "docstring": "Get global embedding model instance.",
        "full_name": "insightspike.processing.get_model",
        "tags": []
      },
      {
        "name": "load_corpus",
        "module": "insightspike.processing",
        "type": "function",
        "signature": "(path: pathlib._local.Path | None = None) -> List[str]",
        "docstring": "",
        "full_name": "insightspike.processing.load_corpus",
        "tags": []
      },
      {
        "name": "retrieve",
        "module": "insightspike.processing",
        "type": "function",
        "signature": "(query: str) -> List[str]",
        "docstring": "Placeholder retrieval function.",
        "full_name": "insightspike.processing.retrieve",
        "tags": []
      },
      {
        "name": "EmbeddingManager",
        "module": "insightspike.processing.embedder",
        "type": "class",
        "signature": "(model_name: str = None, config=None, weight_manager=None)",
        "docstring": "Manages text embedding models with caching and fallback support.",
        "full_name": "insightspike.processing.embedder.EmbeddingManager",
        "tags": []
      },
      {
        "name": "FallbackEmbedder",
        "module": "insightspike.processing.embedder",
        "type": "class",
        "signature": "(dimension: int = 384)",
        "docstring": "Simple fallback embedder for when sentence-transformers is unavailable.",
        "full_name": "insightspike.processing.embedder.FallbackEmbedder",
        "tags": []
      },
      {
        "name": "get_model",
        "module": "insightspike.processing.embedder",
        "type": "function",
        "signature": "(model_name: str = None)",
        "docstring": "Get global embedding model instance.",
        "full_name": "insightspike.processing.embedder.get_model",
        "tags": []
      },
      {
        "name": "normalize_batch_embeddings",
        "module": "insightspike.processing.embedder",
        "type": "function",
        "signature": "(embeddings: Union[numpy.ndarray, ForwardRef('torch.Tensor'), List]) -> numpy.ndarray",
        "docstring": "Normalize a batch of embeddings to shape (batch_size, dim).",
        "full_name": "insightspike.processing.embedder.normalize_batch_embeddings",
        "tags": []
      },
      {
        "name": "normalize_embedding_shape",
        "module": "insightspike.processing.embedder",
        "type": "function",
        "signature": "(embedding: Union[numpy.ndarray, ForwardRef('torch.Tensor'), List[float]]) -> numpy.ndarray",
        "docstring": "Normalize embedding to shape (dim,) instead of (1, dim).",
        "full_name": "insightspike.processing.embedder.normalize_embedding_shape",
        "tags": []
      },
      {
        "name": "clean_text",
        "module": "insightspike.processing.loader",
        "type": "function",
        "signature": "(text: str) -> str",
        "docstring": "Collapse whitespace and trim.",
        "full_name": "insightspike.processing.loader.clean_text",
        "tags": []
      },
      {
        "name": "get_config",
        "module": "insightspike.processing.loader",
        "type": "function",
        "signature": "() -> insightspike.config.models.InsightSpikeConfig",
        "docstring": "Get current configuration or load defaults",
        "full_name": "insightspike.processing.loader.get_config",
        "tags": []
      },
      {
        "name": "iter_text",
        "module": "insightspike.processing.loader",
        "type": "function",
        "signature": "(root: pathlib._local.Path, suffix: str = '.txt') -> Iterable[pathlib._local.Path]",
        "docstring": "Yield all text files under *root*.",
        "full_name": "insightspike.processing.loader.iter_text",
        "tags": []
      },
      {
        "name": "load_corpus",
        "module": "insightspike.processing.loader",
        "type": "function",
        "signature": "(path: pathlib._local.Path | None = None) -> List[str]",
        "docstring": "",
        "full_name": "insightspike.processing.loader.load_corpus",
        "tags": []
      },
      {
        "name": "retrieve",
        "module": "insightspike.processing.retrieval",
        "type": "function",
        "signature": "(query: str) -> List[str]",
        "docstring": "Placeholder retrieval function.",
        "full_name": "insightspike.processing.retrieval.retrieve",
        "tags": []
      },
      {
        "name": "StandardizedEmbedder",
        "module": "insightspike.processing.standardized_embedder",
        "type": "class",
        "signature": "(base_embedder)",
        "docstring": "Wrapper that ensures embeddings are always returned as 1D arrays of shape (dim,).",
        "full_name": "insightspike.processing.standardized_embedder.StandardizedEmbedder",
        "tags": []
      },
      {
        "name": "AnthropicProvider",
        "module": "insightspike.providers",
        "type": "class",
        "signature": "(config: Union[insightspike.config.models.LLMConfig, Dict[str, Any], NoneType] = None)",
        "docstring": "Anthropic Claude provider implementation",
        "full_name": "insightspike.providers.AnthropicProvider",
        "tags": []
      },
      {
        "name": "DistilGPT2Provider",
        "module": "insightspike.providers",
        "type": "class",
        "signature": "(config: Union[insightspike.config.models.LLMConfig, Dict[str, Any], NoneType] = None)",
        "docstring": "Simulated DistilGPT2 provider for experiments.",
        "full_name": "insightspike.providers.DistilGPT2Provider",
        "tags": []
      },
      {
        "name": "LLMProviderRegistry",
        "module": "insightspike.providers",
        "type": "class",
        "signature": "()",
        "docstring": "Registry for caching and reusing LLM provider instances.",
        "full_name": "insightspike.providers.LLMProviderRegistry",
        "tags": []
      },
      {
        "name": "LocalProvider",
        "module": "insightspike.providers",
        "type": "class",
        "signature": "(config: Union[insightspike.config.models.LLMConfig, Dict[str, Any], NoneType] = None)",
        "docstring": "Provider for local language models using Hugging Face transformers.",
        "full_name": "insightspike.providers.LocalProvider",
        "tags": []
      },
      {
        "name": "MockProvider",
        "module": "insightspike.providers",
        "type": "class",
        "signature": "(config: Union[insightspike.config.models.LLMConfig, Dict[str, Any], NoneType] = None)",
        "docstring": "Mock LLM provider for testing",
        "full_name": "insightspike.providers.MockProvider",
        "tags": []
      },
      {
        "name": "OpenAIProvider",
        "module": "insightspike.providers",
        "type": "class",
        "signature": "(config: Union[insightspike.config.models.LLMConfig, Dict[str, Any], NoneType] = None)",
        "docstring": "OpenAI LLM provider implementation",
        "full_name": "insightspike.providers.OpenAIProvider",
        "tags": []
      },
      {
        "name": "ProviderFactory",
        "module": "insightspike.providers",
        "type": "class",
        "signature": "()",
        "docstring": "Factory for creating LLM providers",
        "full_name": "insightspike.providers.ProviderFactory",
        "tags": []
      },
      {
        "name": "AnthropicProvider",
        "module": "insightspike.providers.anthropic_provider",
        "type": "class",
        "signature": "(config: Union[insightspike.config.models.LLMConfig, Dict[str, Any], NoneType] = None)",
        "docstring": "Anthropic Claude provider implementation",
        "full_name": "insightspike.providers.anthropic_provider.AnthropicProvider",
        "tags": []
      },
      {
        "name": "LLMConfig",
        "module": "insightspike.providers.anthropic_provider",
        "type": "class",
        "signature": "(*, provider: Literal['local', 'openai', 'anthropic', 'ollama', 'mock'] = 'local', model: str = 'distilgpt2', max_tokens: Annotated[int, Ge(ge=1), Le(le=4096)] = 256, temperature: Annotated[float, Ge(ge=0.0), Le(le=2.0)] = 0.3, top_p: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.9, timeout: Annotated[int, Ge(ge=1)] = 30, api_key: Optional[str] = None, api_base: Optional[str] = None, organization: Optional[str] = None, device: str = 'cpu', load_in_8bit: bool = False, system_prompt: Optional[str] = None, prompt_style: Literal['standard', 'detailed', 'minimal', 'association', 'association_extended'] = 'standard', max_context_docs: Annotated[int, Ge(ge=1), Le(le=20)] = 5, use_simple_prompt: bool = False, include_metadata: bool = False, branching_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.8, branching_min_branches: Annotated[int, Ge(ge=2), Le(le=10)] = 2, branching_max_gap: Annotated[float, Ge(ge=0.0), Le(le=0.5)] = 0.15) -> None",
        "docstring": "Language Model configuration",
        "full_name": "insightspike.providers.anthropic_provider.LLMConfig",
        "tags": []
      },
      {
        "name": "DistilGPT2Provider",
        "module": "insightspike.providers.distilgpt2_provider",
        "type": "class",
        "signature": "(config: Union[insightspike.config.models.LLMConfig, Dict[str, Any], NoneType] = None)",
        "docstring": "Simulated DistilGPT2 provider for experiments.",
        "full_name": "insightspike.providers.distilgpt2_provider.DistilGPT2Provider",
        "tags": []
      },
      {
        "name": "LLMConfig",
        "module": "insightspike.providers.distilgpt2_provider",
        "type": "class",
        "signature": "(*, provider: Literal['local', 'openai', 'anthropic', 'ollama', 'mock'] = 'local', model: str = 'distilgpt2', max_tokens: Annotated[int, Ge(ge=1), Le(le=4096)] = 256, temperature: Annotated[float, Ge(ge=0.0), Le(le=2.0)] = 0.3, top_p: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.9, timeout: Annotated[int, Ge(ge=1)] = 30, api_key: Optional[str] = None, api_base: Optional[str] = None, organization: Optional[str] = None, device: str = 'cpu', load_in_8bit: bool = False, system_prompt: Optional[str] = None, prompt_style: Literal['standard', 'detailed', 'minimal', 'association', 'association_extended'] = 'standard', max_context_docs: Annotated[int, Ge(ge=1), Le(le=20)] = 5, use_simple_prompt: bool = False, include_metadata: bool = False, branching_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.8, branching_min_branches: Annotated[int, Ge(ge=2), Le(le=10)] = 2, branching_max_gap: Annotated[float, Ge(ge=0.0), Le(le=0.5)] = 0.15) -> None",
        "docstring": "Language Model configuration",
        "full_name": "insightspike.providers.distilgpt2_provider.LLMConfig",
        "tags": []
      },
      {
        "name": "LLMConfig",
        "module": "insightspike.providers.local",
        "type": "class",
        "signature": "(*, provider: Literal['local', 'openai', 'anthropic', 'ollama', 'mock'] = 'local', model: str = 'distilgpt2', max_tokens: Annotated[int, Ge(ge=1), Le(le=4096)] = 256, temperature: Annotated[float, Ge(ge=0.0), Le(le=2.0)] = 0.3, top_p: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.9, timeout: Annotated[int, Ge(ge=1)] = 30, api_key: Optional[str] = None, api_base: Optional[str] = None, organization: Optional[str] = None, device: str = 'cpu', load_in_8bit: bool = False, system_prompt: Optional[str] = None, prompt_style: Literal['standard', 'detailed', 'minimal', 'association', 'association_extended'] = 'standard', max_context_docs: Annotated[int, Ge(ge=1), Le(le=20)] = 5, use_simple_prompt: bool = False, include_metadata: bool = False, branching_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.8, branching_min_branches: Annotated[int, Ge(ge=2), Le(le=10)] = 2, branching_max_gap: Annotated[float, Ge(ge=0.0), Le(le=0.5)] = 0.15) -> None",
        "docstring": "Language Model configuration",
        "full_name": "insightspike.providers.local.LLMConfig",
        "tags": []
      },
      {
        "name": "LocalProvider",
        "module": "insightspike.providers.local",
        "type": "class",
        "signature": "(config: Union[insightspike.config.models.LLMConfig, Dict[str, Any], NoneType] = None)",
        "docstring": "Provider for local language models using Hugging Face transformers.",
        "full_name": "insightspike.providers.local.LocalProvider",
        "tags": []
      },
      {
        "name": "LLMConfig",
        "module": "insightspike.providers.mock_provider",
        "type": "class",
        "signature": "(*, provider: Literal['local', 'openai', 'anthropic', 'ollama', 'mock'] = 'local', model: str = 'distilgpt2', max_tokens: Annotated[int, Ge(ge=1), Le(le=4096)] = 256, temperature: Annotated[float, Ge(ge=0.0), Le(le=2.0)] = 0.3, top_p: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.9, timeout: Annotated[int, Ge(ge=1)] = 30, api_key: Optional[str] = None, api_base: Optional[str] = None, organization: Optional[str] = None, device: str = 'cpu', load_in_8bit: bool = False, system_prompt: Optional[str] = None, prompt_style: Literal['standard', 'detailed', 'minimal', 'association', 'association_extended'] = 'standard', max_context_docs: Annotated[int, Ge(ge=1), Le(le=20)] = 5, use_simple_prompt: bool = False, include_metadata: bool = False, branching_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.8, branching_min_branches: Annotated[int, Ge(ge=2), Le(le=10)] = 2, branching_max_gap: Annotated[float, Ge(ge=0.0), Le(le=0.5)] = 0.15) -> None",
        "docstring": "Language Model configuration",
        "full_name": "insightspike.providers.mock_provider.LLMConfig",
        "tags": []
      },
      {
        "name": "MockProvider",
        "module": "insightspike.providers.mock_provider",
        "type": "class",
        "signature": "(config: Union[insightspike.config.models.LLMConfig, Dict[str, Any], NoneType] = None)",
        "docstring": "Mock LLM provider for testing",
        "full_name": "insightspike.providers.mock_provider.MockProvider",
        "tags": []
      },
      {
        "name": "LLMConfig",
        "module": "insightspike.providers.openai_provider",
        "type": "class",
        "signature": "(*, provider: Literal['local', 'openai', 'anthropic', 'ollama', 'mock'] = 'local', model: str = 'distilgpt2', max_tokens: Annotated[int, Ge(ge=1), Le(le=4096)] = 256, temperature: Annotated[float, Ge(ge=0.0), Le(le=2.0)] = 0.3, top_p: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.9, timeout: Annotated[int, Ge(ge=1)] = 30, api_key: Optional[str] = None, api_base: Optional[str] = None, organization: Optional[str] = None, device: str = 'cpu', load_in_8bit: bool = False, system_prompt: Optional[str] = None, prompt_style: Literal['standard', 'detailed', 'minimal', 'association', 'association_extended'] = 'standard', max_context_docs: Annotated[int, Ge(ge=1), Le(le=20)] = 5, use_simple_prompt: bool = False, include_metadata: bool = False, branching_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.8, branching_min_branches: Annotated[int, Ge(ge=2), Le(le=10)] = 2, branching_max_gap: Annotated[float, Ge(ge=0.0), Le(le=0.5)] = 0.15) -> None",
        "docstring": "Language Model configuration",
        "full_name": "insightspike.providers.openai_provider.LLMConfig",
        "tags": []
      },
      {
        "name": "OpenAIProvider",
        "module": "insightspike.providers.openai_provider",
        "type": "class",
        "signature": "(config: Union[insightspike.config.models.LLMConfig, Dict[str, Any], NoneType] = None)",
        "docstring": "OpenAI LLM provider implementation",
        "full_name": "insightspike.providers.openai_provider.OpenAIProvider",
        "tags": []
      },
      {
        "name": "AnthropicProvider",
        "module": "insightspike.providers.provider_factory",
        "type": "class",
        "signature": "(config: Union[insightspike.config.models.LLMConfig, Dict[str, Any], NoneType] = None)",
        "docstring": "Anthropic Claude provider implementation",
        "full_name": "insightspike.providers.provider_factory.AnthropicProvider",
        "tags": []
      },
      {
        "name": "DistilGPT2Provider",
        "module": "insightspike.providers.provider_factory",
        "type": "class",
        "signature": "(config: Union[insightspike.config.models.LLMConfig, Dict[str, Any], NoneType] = None)",
        "docstring": "Simulated DistilGPT2 provider for experiments.",
        "full_name": "insightspike.providers.provider_factory.DistilGPT2Provider",
        "tags": []
      },
      {
        "name": "LLMConfig",
        "module": "insightspike.providers.provider_factory",
        "type": "class",
        "signature": "(*, provider: Literal['local', 'openai', 'anthropic', 'ollama', 'mock'] = 'local', model: str = 'distilgpt2', max_tokens: Annotated[int, Ge(ge=1), Le(le=4096)] = 256, temperature: Annotated[float, Ge(ge=0.0), Le(le=2.0)] = 0.3, top_p: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.9, timeout: Annotated[int, Ge(ge=1)] = 30, api_key: Optional[str] = None, api_base: Optional[str] = None, organization: Optional[str] = None, device: str = 'cpu', load_in_8bit: bool = False, system_prompt: Optional[str] = None, prompt_style: Literal['standard', 'detailed', 'minimal', 'association', 'association_extended'] = 'standard', max_context_docs: Annotated[int, Ge(ge=1), Le(le=20)] = 5, use_simple_prompt: bool = False, include_metadata: bool = False, branching_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.8, branching_min_branches: Annotated[int, Ge(ge=2), Le(le=10)] = 2, branching_max_gap: Annotated[float, Ge(ge=0.0), Le(le=0.5)] = 0.15) -> None",
        "docstring": "Language Model configuration",
        "full_name": "insightspike.providers.provider_factory.LLMConfig",
        "tags": []
      },
      {
        "name": "LocalProvider",
        "module": "insightspike.providers.provider_factory",
        "type": "class",
        "signature": "(config: Union[insightspike.config.models.LLMConfig, Dict[str, Any], NoneType] = None)",
        "docstring": "Provider for local language models using Hugging Face transformers.",
        "full_name": "insightspike.providers.provider_factory.LocalProvider",
        "tags": []
      },
      {
        "name": "MockProvider",
        "module": "insightspike.providers.provider_factory",
        "type": "class",
        "signature": "(config: Union[insightspike.config.models.LLMConfig, Dict[str, Any], NoneType] = None)",
        "docstring": "Mock LLM provider for testing",
        "full_name": "insightspike.providers.provider_factory.MockProvider",
        "tags": []
      },
      {
        "name": "OpenAIProvider",
        "module": "insightspike.providers.provider_factory",
        "type": "class",
        "signature": "(config: Union[insightspike.config.models.LLMConfig, Dict[str, Any], NoneType] = None)",
        "docstring": "OpenAI LLM provider implementation",
        "full_name": "insightspike.providers.provider_factory.OpenAIProvider",
        "tags": []
      },
      {
        "name": "ProviderFactory",
        "module": "insightspike.providers.provider_factory",
        "type": "class",
        "signature": "()",
        "docstring": "Factory for creating LLM providers",
        "full_name": "insightspike.providers.provider_factory.ProviderFactory",
        "tags": []
      },
      {
        "name": "SimpleLocalProvider",
        "module": "insightspike.providers.provider_factory",
        "type": "class",
        "signature": "(config: Union[insightspike.config.models.LLMConfig, Dict[str, Any], NoneType] = None)",
        "docstring": "Simple local provider using DistilGPT2",
        "full_name": "insightspike.providers.provider_factory.SimpleLocalProvider",
        "tags": []
      },
      {
        "name": "LLMConfig",
        "module": "insightspike.providers.simple_local",
        "type": "class",
        "signature": "(*, provider: Literal['local', 'openai', 'anthropic', 'ollama', 'mock'] = 'local', model: str = 'distilgpt2', max_tokens: Annotated[int, Ge(ge=1), Le(le=4096)] = 256, temperature: Annotated[float, Ge(ge=0.0), Le(le=2.0)] = 0.3, top_p: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.9, timeout: Annotated[int, Ge(ge=1)] = 30, api_key: Optional[str] = None, api_base: Optional[str] = None, organization: Optional[str] = None, device: str = 'cpu', load_in_8bit: bool = False, system_prompt: Optional[str] = None, prompt_style: Literal['standard', 'detailed', 'minimal', 'association', 'association_extended'] = 'standard', max_context_docs: Annotated[int, Ge(ge=1), Le(le=20)] = 5, use_simple_prompt: bool = False, include_metadata: bool = False, branching_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.8, branching_min_branches: Annotated[int, Ge(ge=2), Le(le=10)] = 2, branching_max_gap: Annotated[float, Ge(ge=0.0), Le(le=0.5)] = 0.15) -> None",
        "docstring": "Language Model configuration",
        "full_name": "insightspike.providers.simple_local.LLMConfig",
        "tags": []
      },
      {
        "name": "SimpleLocalProvider",
        "module": "insightspike.providers.simple_local",
        "type": "class",
        "signature": "(config: Union[insightspike.config.models.LLMConfig, Dict[str, Any], NoneType] = None)",
        "docstring": "Simple local provider using DistilGPT2",
        "full_name": "insightspike.providers.simple_local.SimpleLocalProvider",
        "tags": []
      },
      {
        "name": "InsightAppWrapper",
        "module": "insightspike.public",
        "type": "class",
        "signature": "(provider: str = 'ollama', model: str = 'mistral', api_base: Optional[str] = 'http://localhost:11434/v1', api_key: str = 'ollama', data_dir: str = 'data/local_app', temperature: float = 0.7, max_cycles: int = 2)",
        "docstring": "A simplified interface for building local knowledge apps.",
        "full_name": "insightspike.public.InsightAppWrapper",
        "tags": []
      },
      {
        "name": "create_agent",
        "module": "insightspike.public",
        "type": "function",
        "signature": "(provider: 'str' = 'mock', **kwargs) -> 'MainAgent'",
        "docstring": "Create a ready-to-use InsightSpike agent with minimal configuration.",
        "full_name": "insightspike.public.create_agent",
        "tags": []
      },
      {
        "name": "create_datastore",
        "module": "insightspike.public",
        "type": "function",
        "signature": "(kind: 'str' = 'filesystem', **kwargs)",
        "docstring": "Create a simple, safe DataStore instance.",
        "full_name": "insightspike.public.create_datastore",
        "tags": []
      },
      {
        "name": "get_config_summary",
        "module": "insightspike.public",
        "type": "function",
        "signature": "(config=None)",
        "docstring": "Return a lightweight diagnostic summary for a config.",
        "full_name": "insightspike.public.get_config_summary",
        "tags": []
      },
      {
        "name": "load_config",
        "module": "insightspike.public",
        "type": "function",
        "signature": "(*args, **kwargs)",
        "docstring": "Public wrapper for configuration loading.",
        "full_name": "insightspike.public.load_config",
        "tags": []
      },
      {
        "name": "quick_demo",
        "module": "insightspike.public",
        "type": "function",
        "signature": "()",
        "docstring": "Run a quick demonstration of InsightSpike capabilities.",
        "full_name": "insightspike.public.quick_demo",
        "tags": []
      },
      {
        "name": "InsightAppWrapper",
        "module": "insightspike.public.wrapper",
        "type": "class",
        "signature": "(provider: str = 'ollama', model: str = 'mistral', api_base: Optional[str] = 'http://localhost:11434/v1', api_key: str = 'ollama', data_dir: str = 'data/local_app', temperature: float = 0.7, max_cycles: int = 2)",
        "docstring": "A simplified interface for building local knowledge apps.",
        "full_name": "insightspike.public.wrapper.InsightAppWrapper",
        "tags": []
      },
      {
        "name": "LLMConfig",
        "module": "insightspike.public.wrapper",
        "type": "class",
        "signature": "(*, provider: Literal['local', 'openai', 'anthropic', 'ollama', 'mock'] = 'local', model: str = 'distilgpt2', max_tokens: Annotated[int, Ge(ge=1), Le(le=4096)] = 256, temperature: Annotated[float, Ge(ge=0.0), Le(le=2.0)] = 0.3, top_p: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.9, timeout: Annotated[int, Ge(ge=1)] = 30, api_key: Optional[str] = None, api_base: Optional[str] = None, organization: Optional[str] = None, device: str = 'cpu', load_in_8bit: bool = False, system_prompt: Optional[str] = None, prompt_style: Literal['standard', 'detailed', 'minimal', 'association', 'association_extended'] = 'standard', max_context_docs: Annotated[int, Ge(ge=1), Le(le=20)] = 5, use_simple_prompt: bool = False, include_metadata: bool = False, branching_threshold: Annotated[float, Ge(ge=0.0), Le(le=1.0)] = 0.8, branching_min_branches: Annotated[int, Ge(ge=2), Le(le=10)] = 2, branching_max_gap: Annotated[float, Ge(ge=0.0), Le(le=0.5)] = 0.15) -> None",
        "docstring": "Language Model configuration",
        "full_name": "insightspike.public.wrapper.LLMConfig",
        "tags": []
      },
      {
        "name": "create_agent",
        "module": "insightspike.public.wrapper",
        "type": "function",
        "signature": "(provider: 'str' = 'mock', **kwargs) -> 'MainAgent'",
        "docstring": "Create a ready-to-use InsightSpike agent with minimal configuration.",
        "full_name": "insightspike.public.wrapper.create_agent",
        "tags": []
      },
      {
        "name": "AdaptiveTopKConfig",
        "module": "insightspike.query_adaptation",
        "type": "class",
        "signature": "(base_layer1_k: int = 20, base_layer2_k: int = 15, base_layer3_k: int = 12, synthesis_multiplier: float = 1.5, complexity_multiplier: float = 1.3, unknown_ratio_multiplier: float = 1.2, max_layer1_k: int = 50, max_layer2_k: int = 30, max_layer3_k: int = 25, min_k: int = 3, low_confidence_multiplier: float = 1.4, confidence_threshold: float = 0.6) -> None",
        "docstring": "Configuration for adaptive topK algorithm",
        "full_name": "insightspike.query_adaptation.AdaptiveTopKConfig",
        "tags": []
      },
      {
        "name": "Layer1AutoLearningSystem",
        "module": "insightspike.query_adaptation",
        "type": "class",
        "signature": "(storage_path: str = None)",
        "docstring": "Automatic learning system that captures and stores unknown information",
        "full_name": "insightspike.query_adaptation.Layer1AutoLearningSystem",
        "tags": []
      },
      {
        "name": "LearningSession",
        "module": "insightspike.query_adaptation",
        "type": "class",
        "signature": "(session_id: str, query: str, unknown_concepts: List[str], resolution_context: str, success_score: float, timestamp: datetime.datetime, concepts_learned: List[str]) -> None",
        "docstring": "Represents a learning session where unknown concepts were resolved",
        "full_name": "insightspike.query_adaptation.LearningSession",
        "tags": []
      },
      {
        "name": "UnknownConcept",
        "module": "insightspike.query_adaptation",
        "type": "class",
        "signature": "(concept: str, context_query: str, discovered_at: datetime.datetime, confidence_score: float, associated_concepts: List[str], resolution_attempts: int = 0, learned_definition: Optional[str] = None, source_context: Optional[str] = None, learning_priority: float = 1.0) -> None",
        "docstring": "Represents an unknown concept discovered during analysis",
        "full_name": "insightspike.query_adaptation.UnknownConcept",
        "tags": []
      },
      {
        "name": "UnknownLearner",
        "module": "insightspike.query_adaptation",
        "type": "class",
        "signature": "(db_path: Optional[pathlib._local.Path] = None)",
        "docstring": "Manages learning of unknown information with weak relationships and sleep-mode cleanup.",
        "full_name": "insightspike.query_adaptation.UnknownLearner",
        "tags": []
      },
      {
        "name": "WeakRelationship",
        "module": "insightspike.query_adaptation",
        "type": "class",
        "signature": "(concept1: str, concept2: str, confidence: float, source: str, usage_count: int, created_at: float, last_accessed: float, context: str = '') -> None",
        "docstring": "Represents a weak relationship between concepts",
        "full_name": "insightspike.query_adaptation.WeakRelationship",
        "tags": []
      },
      {
        "name": "calculate_adaptive_topk",
        "module": "insightspike.query_adaptation",
        "type": "function",
        "signature": "(l1_analysis: Dict[str, Any], config: insightspike.query_adaptation.adaptive_topk.AdaptiveTopKConfig = None) -> Dict[str, int]",
        "docstring": "Calculate adaptive topK values for each layer based on Layer1 analysis.",
        "full_name": "insightspike.query_adaptation.calculate_adaptive_topk",
        "tags": []
      },
      {
        "name": "estimate_chain_reaction_potential",
        "module": "insightspike.query_adaptation",
        "type": "function",
        "signature": "(l1_analysis: Dict[str, Any], adaptive_topk: Dict[str, int]) -> float",
        "docstring": "Estimate the potential for \"\u9023\u9396\u53cd\u5fdc\u7684\u6d1e\u5bdf\u5411\u4e0a\" (chain reaction insight improvement)",
        "full_name": "insightspike.query_adaptation.estimate_chain_reaction_potential",
        "tags": []
      },
      {
        "name": "get_unknown_learner",
        "module": "insightspike.query_adaptation",
        "type": "function",
        "signature": "() -> insightspike.query_adaptation.unknown_learner.UnknownLearner",
        "docstring": "Get or create global unknown learner instance",
        "full_name": "insightspike.query_adaptation.get_unknown_learner",
        "tags": []
      },
      {
        "name": "shutdown_unknown_learner",
        "module": "insightspike.query_adaptation",
        "type": "function",
        "signature": "()",
        "docstring": "Shutdown global unknown learner",
        "full_name": "insightspike.query_adaptation.shutdown_unknown_learner",
        "tags": []
      },
      {
        "name": "test_adaptive_topk",
        "module": "insightspike.query_adaptation",
        "type": "function",
        "signature": "()",
        "docstring": "Test the adaptive topK algorithm with various scenarios",
        "full_name": "insightspike.query_adaptation.test_adaptive_topk",
        "tags": []
      },
      {
        "name": "AdaptiveTopKConfig",
        "module": "insightspike.query_adaptation.adaptive_topk",
        "type": "class",
        "signature": "(base_layer1_k: int = 20, base_layer2_k: int = 15, base_layer3_k: int = 12, synthesis_multiplier: float = 1.5, complexity_multiplier: float = 1.3, unknown_ratio_multiplier: float = 1.2, max_layer1_k: int = 50, max_layer2_k: int = 30, max_layer3_k: int = 25, min_k: int = 3, low_confidence_multiplier: float = 1.4, confidence_threshold: float = 0.6) -> None",
        "docstring": "Configuration for adaptive topK algorithm",
        "full_name": "insightspike.query_adaptation.adaptive_topk.AdaptiveTopKConfig",
        "tags": []
      },
      {
        "name": "calculate_adaptive_topk",
        "module": "insightspike.query_adaptation.adaptive_topk",
        "type": "function",
        "signature": "(l1_analysis: Dict[str, Any], config: insightspike.query_adaptation.adaptive_topk.AdaptiveTopKConfig = None) -> Dict[str, int]",
        "docstring": "Calculate adaptive topK values for each layer based on Layer1 analysis.",
        "full_name": "insightspike.query_adaptation.adaptive_topk.calculate_adaptive_topk",
        "tags": []
      },
      {
        "name": "estimate_chain_reaction_potential",
        "module": "insightspike.query_adaptation.adaptive_topk",
        "type": "function",
        "signature": "(l1_analysis: Dict[str, Any], adaptive_topk: Dict[str, int]) -> float",
        "docstring": "Estimate the potential for \"\u9023\u9396\u53cd\u5fdc\u7684\u6d1e\u5bdf\u5411\u4e0a\" (chain reaction insight improvement)",
        "full_name": "insightspike.query_adaptation.adaptive_topk.estimate_chain_reaction_potential",
        "tags": []
      },
      {
        "name": "test_adaptive_topk",
        "module": "insightspike.query_adaptation.adaptive_topk",
        "type": "function",
        "signature": "()",
        "docstring": "Test the adaptive topK algorithm with various scenarios",
        "full_name": "insightspike.query_adaptation.adaptive_topk.test_adaptive_topk",
        "tags": []
      },
      {
        "name": "Layer1AutoLearningSystem",
        "module": "insightspike.query_adaptation.auto_learning",
        "type": "class",
        "signature": "(storage_path: str = None)",
        "docstring": "Automatic learning system that captures and stores unknown information",
        "full_name": "insightspike.query_adaptation.auto_learning.Layer1AutoLearningSystem",
        "tags": []
      },
      {
        "name": "LearningSession",
        "module": "insightspike.query_adaptation.auto_learning",
        "type": "class",
        "signature": "(session_id: str, query: str, unknown_concepts: List[str], resolution_context: str, success_score: float, timestamp: datetime.datetime, concepts_learned: List[str]) -> None",
        "docstring": "Represents a learning session where unknown concepts were resolved",
        "full_name": "insightspike.query_adaptation.auto_learning.LearningSession",
        "tags": []
      },
      {
        "name": "UnknownConcept",
        "module": "insightspike.query_adaptation.auto_learning",
        "type": "class",
        "signature": "(concept: str, context_query: str, discovered_at: datetime.datetime, confidence_score: float, associated_concepts: List[str], resolution_attempts: int = 0, learned_definition: Optional[str] = None, source_context: Optional[str] = None, learning_priority: float = 1.0) -> None",
        "docstring": "Represents an unknown concept discovered during analysis",
        "full_name": "insightspike.query_adaptation.auto_learning.UnknownConcept",
        "tags": []
      },
      {
        "name": "UnknownLearner",
        "module": "insightspike.query_adaptation.unknown_learner",
        "type": "class",
        "signature": "(db_path: Optional[pathlib._local.Path] = None)",
        "docstring": "Manages learning of unknown information with weak relationships and sleep-mode cleanup.",
        "full_name": "insightspike.query_adaptation.unknown_learner.UnknownLearner",
        "tags": []
      },
      {
        "name": "WeakRelationship",
        "module": "insightspike.query_adaptation.unknown_learner",
        "type": "class",
        "signature": "(concept1: str, concept2: str, confidence: float, source: str, usage_count: int, created_at: float, last_accessed: float, context: str = '') -> None",
        "docstring": "Represents a weak relationship between concepts",
        "full_name": "insightspike.query_adaptation.unknown_learner.WeakRelationship",
        "tags": []
      },
      {
        "name": "get_unknown_learner",
        "module": "insightspike.query_adaptation.unknown_learner",
        "type": "function",
        "signature": "() -> insightspike.query_adaptation.unknown_learner.UnknownLearner",
        "docstring": "Get or create global unknown learner instance",
        "full_name": "insightspike.query_adaptation.unknown_learner.get_unknown_learner",
        "tags": []
      },
      {
        "name": "shutdown_unknown_learner",
        "module": "insightspike.query_adaptation.unknown_learner",
        "type": "function",
        "signature": "()",
        "docstring": "Shutdown global unknown learner",
        "full_name": "insightspike.query_adaptation.unknown_learner.shutdown_unknown_learner",
        "tags": []
      },
      {
        "name": "MainAgent",
        "module": "insightspike.quick_start",
        "type": "class",
        "signature": "(config=None, datastore: Optional[insightspike.core.base.datastore.DataStore] = None)",
        "docstring": "Main orchestrating agent that coordinates all layers.",
        "full_name": "insightspike.quick_start.MainAgent",
        "tags": []
      },
      {
        "name": "create_agent",
        "module": "insightspike.quick_start",
        "type": "function",
        "signature": "(provider: 'str' = 'mock', **kwargs) -> 'MainAgent'",
        "docstring": "Create a ready-to-use InsightSpike agent with minimal configuration.",
        "full_name": "insightspike.quick_start.create_agent",
        "tags": []
      },
      {
        "name": "load_config",
        "module": "insightspike.quick_start",
        "type": "function",
        "signature": "(config_path: Union[str, pathlib._local.Path, NoneType] = None, preset: Optional[str] = None, overrides: Optional[Dict[str, Any]] = None) -> insightspike.config.models.InsightSpikeConfig",
        "docstring": "Load configuration using global loader",
        "full_name": "insightspike.quick_start.load_config",
        "tags": []
      },
      {
        "name": "quick_demo",
        "module": "insightspike.quick_start",
        "type": "function",
        "signature": "()",
        "docstring": "Run a quick demonstration of InsightSpike capabilities.",
        "full_name": "insightspike.quick_start.quick_demo",
        "tags": []
      },
      {
        "name": "SpikeDataCollector",
        "module": "insightspike.spike_pipeline",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Collects data needed for spike detection analysis.",
        "full_name": "insightspike.spike_pipeline.SpikeDataCollector",
        "tags": []
      },
      {
        "name": "SpikeDecisionEngine",
        "module": "insightspike.spike_pipeline",
        "type": "class",
        "signature": "(config=None, mode: insightspike.spike_pipeline.detector.SpikeDecisionMode = <SpikeDecisionMode.WEIGHTED: 'weighted'>)",
        "docstring": "Makes spike detection decisions based on computed statistics.",
        "full_name": "insightspike.spike_pipeline.SpikeDecisionEngine",
        "tags": []
      },
      {
        "name": "SpikeDecisionMode",
        "module": "insightspike.spike_pipeline",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Different modes for spike decision making.",
        "full_name": "insightspike.spike_pipeline.SpikeDecisionMode",
        "tags": []
      },
      {
        "name": "SpikePipeline",
        "module": "insightspike.spike_pipeline",
        "type": "class",
        "signature": "(config=None, decision_mode: insightspike.spike_pipeline.detector.SpikeDecisionMode = <SpikeDecisionMode.WEIGHTED: 'weighted'>, enable_history: bool = True)",
        "docstring": "Complete spike detection pipeline.",
        "full_name": "insightspike.spike_pipeline.SpikePipeline",
        "tags": []
      },
      {
        "name": "SpikePostProcessor",
        "module": "insightspike.spike_pipeline",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Post-processes spike detection results.",
        "full_name": "insightspike.spike_pipeline.SpikePostProcessor",
        "tags": []
      },
      {
        "name": "SpikeStatsAnalyzer",
        "module": "insightspike.spike_pipeline",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Analyzes spike data to compute detection statistics.",
        "full_name": "insightspike.spike_pipeline.SpikeStatsAnalyzer",
        "tags": []
      },
      {
        "name": "SpikeDataCollection",
        "module": "insightspike.spike_pipeline.analyzer",
        "type": "class",
        "signature": "(gedig_value: float, ged_value: float, ig_value: float, graph_metrics: Dict[str, Any], retrieved_documents: List[Dict[str, Any]], previous_state: Dict[str, Any], current_context: Dict[str, Any], timestamp: float, metadata: Dict[str, Any]) -> None",
        "docstring": "Raw data collected for spike detection.",
        "full_name": "insightspike.spike_pipeline.analyzer.SpikeDataCollection",
        "tags": []
      },
      {
        "name": "SpikeStats",
        "module": "insightspike.spike_pipeline.analyzer",
        "type": "class",
        "signature": "(ged_score: float, ig_score: float, conflict_score: float, composite_score: float, confidence: float, anomaly_indicators: Dict[str, float], trend_indicators: Dict[str, float], metadata: Dict[str, Any]) -> None",
        "docstring": "Computed statistics for spike detection.",
        "full_name": "insightspike.spike_pipeline.analyzer.SpikeStats",
        "tags": []
      },
      {
        "name": "SpikeStatsAnalyzer",
        "module": "insightspike.spike_pipeline.analyzer",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Analyzes spike data to compute detection statistics.",
        "full_name": "insightspike.spike_pipeline.analyzer.SpikeStatsAnalyzer",
        "tags": []
      },
      {
        "name": "SpikeDataCollection",
        "module": "insightspike.spike_pipeline.collector",
        "type": "class",
        "signature": "(gedig_value: float, ged_value: float, ig_value: float, graph_metrics: Dict[str, Any], retrieved_documents: List[Dict[str, Any]], previous_state: Dict[str, Any], current_context: Dict[str, Any], timestamp: float, metadata: Dict[str, Any]) -> None",
        "docstring": "Raw data collected for spike detection.",
        "full_name": "insightspike.spike_pipeline.collector.SpikeDataCollection",
        "tags": []
      },
      {
        "name": "SpikeDataCollector",
        "module": "insightspike.spike_pipeline.collector",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Collects data needed for spike detection analysis.",
        "full_name": "insightspike.spike_pipeline.collector.SpikeDataCollector",
        "tags": []
      },
      {
        "name": "SpikeDecision",
        "module": "insightspike.spike_pipeline.detector",
        "type": "class",
        "signature": "(detected: bool, confidence: float, score: float, reasons: List[str], mode: str, thresholds_used: Dict[str, float], metadata: Dict[str, Any]) -> None",
        "docstring": "Result of spike detection decision.",
        "full_name": "insightspike.spike_pipeline.detector.SpikeDecision",
        "tags": []
      },
      {
        "name": "SpikeDecisionEngine",
        "module": "insightspike.spike_pipeline.detector",
        "type": "class",
        "signature": "(config=None, mode: insightspike.spike_pipeline.detector.SpikeDecisionMode = <SpikeDecisionMode.WEIGHTED: 'weighted'>)",
        "docstring": "Makes spike detection decisions based on computed statistics.",
        "full_name": "insightspike.spike_pipeline.detector.SpikeDecisionEngine",
        "tags": []
      },
      {
        "name": "SpikeDecisionMode",
        "module": "insightspike.spike_pipeline.detector",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Different modes for spike decision making.",
        "full_name": "insightspike.spike_pipeline.detector.SpikeDecisionMode",
        "tags": []
      },
      {
        "name": "SpikeStats",
        "module": "insightspike.spike_pipeline.detector",
        "type": "class",
        "signature": "(ged_score: float, ig_score: float, conflict_score: float, composite_score: float, confidence: float, anomaly_indicators: Dict[str, float], trend_indicators: Dict[str, float], metadata: Dict[str, Any]) -> None",
        "docstring": "Computed statistics for spike detection.",
        "full_name": "insightspike.spike_pipeline.detector.SpikeStats",
        "tags": []
      },
      {
        "name": "SpikeDataCollection",
        "module": "insightspike.spike_pipeline.pipeline",
        "type": "class",
        "signature": "(gedig_value: float, ged_value: float, ig_value: float, graph_metrics: Dict[str, Any], retrieved_documents: List[Dict[str, Any]], previous_state: Dict[str, Any], current_context: Dict[str, Any], timestamp: float, metadata: Dict[str, Any]) -> None",
        "docstring": "Raw data collected for spike detection.",
        "full_name": "insightspike.spike_pipeline.pipeline.SpikeDataCollection",
        "tags": []
      },
      {
        "name": "SpikeDataCollector",
        "module": "insightspike.spike_pipeline.pipeline",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Collects data needed for spike detection analysis.",
        "full_name": "insightspike.spike_pipeline.pipeline.SpikeDataCollector",
        "tags": []
      },
      {
        "name": "SpikeDecision",
        "module": "insightspike.spike_pipeline.pipeline",
        "type": "class",
        "signature": "(detected: bool, confidence: float, score: float, reasons: List[str], mode: str, thresholds_used: Dict[str, float], metadata: Dict[str, Any]) -> None",
        "docstring": "Result of spike detection decision.",
        "full_name": "insightspike.spike_pipeline.pipeline.SpikeDecision",
        "tags": []
      },
      {
        "name": "SpikeDecisionEngine",
        "module": "insightspike.spike_pipeline.pipeline",
        "type": "class",
        "signature": "(config=None, mode: insightspike.spike_pipeline.detector.SpikeDecisionMode = <SpikeDecisionMode.WEIGHTED: 'weighted'>)",
        "docstring": "Makes spike detection decisions based on computed statistics.",
        "full_name": "insightspike.spike_pipeline.pipeline.SpikeDecisionEngine",
        "tags": []
      },
      {
        "name": "SpikeDecisionMode",
        "module": "insightspike.spike_pipeline.pipeline",
        "type": "class",
        "signature": "(*values)",
        "docstring": "Different modes for spike decision making.",
        "full_name": "insightspike.spike_pipeline.pipeline.SpikeDecisionMode",
        "tags": []
      },
      {
        "name": "SpikePipeline",
        "module": "insightspike.spike_pipeline.pipeline",
        "type": "class",
        "signature": "(config=None, decision_mode: insightspike.spike_pipeline.detector.SpikeDecisionMode = <SpikeDecisionMode.WEIGHTED: 'weighted'>, enable_history: bool = True)",
        "docstring": "Complete spike detection pipeline.",
        "full_name": "insightspike.spike_pipeline.pipeline.SpikePipeline",
        "tags": []
      },
      {
        "name": "SpikePostProcessor",
        "module": "insightspike.spike_pipeline.pipeline",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Post-processes spike detection results.",
        "full_name": "insightspike.spike_pipeline.pipeline.SpikePostProcessor",
        "tags": []
      },
      {
        "name": "SpikeProcessingResult",
        "module": "insightspike.spike_pipeline.pipeline",
        "type": "class",
        "signature": "(decision: insightspike.spike_pipeline.detector.SpikeDecision, insights_registered: List[str], processing_metadata: Dict[str, Any], formatted_result: Dict[str, Any], processing_time_ms: float) -> None",
        "docstring": "Final result after spike processing.",
        "full_name": "insightspike.spike_pipeline.pipeline.SpikeProcessingResult",
        "tags": []
      },
      {
        "name": "SpikeStats",
        "module": "insightspike.spike_pipeline.pipeline",
        "type": "class",
        "signature": "(ged_score: float, ig_score: float, conflict_score: float, composite_score: float, confidence: float, anomaly_indicators: Dict[str, float], trend_indicators: Dict[str, float], metadata: Dict[str, Any]) -> None",
        "docstring": "Computed statistics for spike detection.",
        "full_name": "insightspike.spike_pipeline.pipeline.SpikeStats",
        "tags": []
      },
      {
        "name": "SpikeStatsAnalyzer",
        "module": "insightspike.spike_pipeline.pipeline",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Analyzes spike data to compute detection statistics.",
        "full_name": "insightspike.spike_pipeline.pipeline.SpikeStatsAnalyzer",
        "tags": []
      },
      {
        "name": "create_adaptive_pipeline",
        "module": "insightspike.spike_pipeline.pipeline",
        "type": "function",
        "signature": "(config=None) -> insightspike.spike_pipeline.pipeline.SpikePipeline",
        "docstring": "Create pipeline with adaptive decision mode.",
        "full_name": "insightspike.spike_pipeline.pipeline.create_adaptive_pipeline",
        "tags": []
      },
      {
        "name": "create_standard_pipeline",
        "module": "insightspike.spike_pipeline.pipeline",
        "type": "function",
        "signature": "(config=None) -> insightspike.spike_pipeline.pipeline.SpikePipeline",
        "docstring": "Create pipeline with standard weighted decision mode.",
        "full_name": "insightspike.spike_pipeline.pipeline.create_standard_pipeline",
        "tags": []
      },
      {
        "name": "create_threshold_pipeline",
        "module": "insightspike.spike_pipeline.pipeline",
        "type": "function",
        "signature": "(config=None) -> insightspike.spike_pipeline.pipeline.SpikePipeline",
        "docstring": "Create pipeline with simple threshold decision mode.",
        "full_name": "insightspike.spike_pipeline.pipeline.create_threshold_pipeline",
        "tags": []
      },
      {
        "name": "SpikeDataCollection",
        "module": "insightspike.spike_pipeline.processor",
        "type": "class",
        "signature": "(gedig_value: float, ged_value: float, ig_value: float, graph_metrics: Dict[str, Any], retrieved_documents: List[Dict[str, Any]], previous_state: Dict[str, Any], current_context: Dict[str, Any], timestamp: float, metadata: Dict[str, Any]) -> None",
        "docstring": "Raw data collected for spike detection.",
        "full_name": "insightspike.spike_pipeline.processor.SpikeDataCollection",
        "tags": []
      },
      {
        "name": "SpikeDecision",
        "module": "insightspike.spike_pipeline.processor",
        "type": "class",
        "signature": "(detected: bool, confidence: float, score: float, reasons: List[str], mode: str, thresholds_used: Dict[str, float], metadata: Dict[str, Any]) -> None",
        "docstring": "Result of spike detection decision.",
        "full_name": "insightspike.spike_pipeline.processor.SpikeDecision",
        "tags": []
      },
      {
        "name": "SpikePostProcessor",
        "module": "insightspike.spike_pipeline.processor",
        "type": "class",
        "signature": "(config=None)",
        "docstring": "Post-processes spike detection results.",
        "full_name": "insightspike.spike_pipeline.processor.SpikePostProcessor",
        "tags": []
      },
      {
        "name": "SpikeProcessingResult",
        "module": "insightspike.spike_pipeline.processor",
        "type": "class",
        "signature": "(decision: insightspike.spike_pipeline.detector.SpikeDecision, insights_registered: List[str], processing_metadata: Dict[str, Any], formatted_result: Dict[str, Any], processing_time_ms: float) -> None",
        "docstring": "Final result after spike processing.",
        "full_name": "insightspike.spike_pipeline.processor.SpikeProcessingResult",
        "tags": []
      },
      {
        "name": "SpikeStats",
        "module": "insightspike.spike_pipeline.processor",
        "type": "class",
        "signature": "(ged_score: float, ig_score: float, conflict_score: float, composite_score: float, confidence: float, anomaly_indicators: Dict[str, float], trend_indicators: Dict[str, float], metadata: Dict[str, Any]) -> None",
        "docstring": "Computed statistics for spike detection.",
        "full_name": "insightspike.spike_pipeline.processor.SpikeStats",
        "tags": []
      },
      {
        "name": "predict",
        "module": "insightspike.training",
        "type": "function",
        "signature": "(question: str) -> str",
        "docstring": "Placeholder predict function.",
        "full_name": "insightspike.training.predict",
        "tags": []
      },
      {
        "name": "quantize",
        "module": "insightspike.training",
        "type": "function",
        "signature": "(model)",
        "docstring": "Placeholder quantization function.",
        "full_name": "insightspike.training.quantize",
        "tags": []
      },
      {
        "name": "train",
        "module": "insightspike.training",
        "type": "function",
        "signature": "()",
        "docstring": "Placeholder train function.",
        "full_name": "insightspike.training.train",
        "tags": []
      },
      {
        "name": "predict",
        "module": "insightspike.training.predict",
        "type": "function",
        "signature": "(question: str) -> str",
        "docstring": "Placeholder predict function.",
        "full_name": "insightspike.training.predict.predict",
        "tags": []
      },
      {
        "name": "quantize",
        "module": "insightspike.training.quantizer",
        "type": "function",
        "signature": "(model)",
        "docstring": "Placeholder quantization function.",
        "full_name": "insightspike.training.quantizer.quantize",
        "tags": []
      },
      {
        "name": "train",
        "module": "insightspike.training.train",
        "type": "function",
        "signature": "()",
        "docstring": "Placeholder train function.",
        "full_name": "insightspike.training.train.train",
        "tags": []
      },
      {
        "name": "InsightSpikeVisualizer",
        "module": "insightspike.utils",
        "type": "class",
        "signature": "(style: str = 'default', figsize: Tuple[int, int] = (12, 8))",
        "docstring": "Centralized visualization utilities for InsightSpike-AI",
        "full_name": "insightspike.utils.InsightSpikeVisualizer",
        "tags": []
      },
      {
        "name": "clean_text",
        "module": "insightspike.utils",
        "type": "function",
        "signature": "(text: str) -> str",
        "docstring": "Collapse whitespace and trim.",
        "full_name": "insightspike.utils.clean_text",
        "tags": []
      },
      {
        "name": "delta_ged",
        "module": "insightspike.utils",
        "type": "function",
        "signature": "(g_old: networkx.classes.graph.Graph, g_new: networkx.classes.graph.Graph) -> float",
        "docstring": "Calculate graph edit distance delta.",
        "full_name": "insightspike.utils.delta_ged",
        "tags": []
      },
      {
        "name": "delta_ig",
        "module": "insightspike.utils",
        "type": "function",
        "signature": "(vecs_old: numpy.ndarray, vecs_new: numpy.ndarray, k: int = 8) -> float",
        "docstring": "Calculate information gain delta between two vector sets.",
        "full_name": "insightspike.utils.delta_ig",
        "tags": []
      },
      {
        "name": "get_available_models",
        "module": "insightspike.utils",
        "type": "function",
        "signature": "()",
        "docstring": "Get list of available embedding models.",
        "full_name": "insightspike.utils.get_available_models",
        "tags": []
      },
      {
        "name": "iter_text",
        "module": "insightspike.utils",
        "type": "function",
        "signature": "(root: pathlib._local.Path, suffix: str = '.txt') -> Iterable[pathlib._local.Path]",
        "docstring": "Yield all text files under *root*.",
        "full_name": "insightspike.utils.iter_text",
        "tags": []
      },
      {
        "name": "quick_comparison",
        "module": "insightspike.utils",
        "type": "function",
        "signature": "(data1: List[float], data2: List[float], labels: List[str], title: str = 'Comparison', save_path: Optional[str] = None) -> str",
        "docstring": "Quickly create a comparison chart",
        "full_name": "insightspike.utils.quick_comparison",
        "tags": []
      },
      {
        "name": "quick_performance_chart",
        "module": "insightspike.utils",
        "type": "function",
        "signature": "(metrics: Dict[str, float], title: str = 'Performance', save_path: Optional[str] = None) -> str",
        "docstring": "Quickly create a performance chart",
        "full_name": "insightspike.utils.quick_performance_chart",
        "tags": []
      },
      {
        "name": "quick_progress_chart",
        "module": "insightspike.utils",
        "type": "function",
        "signature": "(episodes: List[int], rewards: List[float], save_path: Optional[str] = None) -> str",
        "docstring": "Quickly create a progress chart",
        "full_name": "insightspike.utils.quick_progress_chart",
        "tags": []
      },
      {
        "name": "safe_attr",
        "module": "insightspike.utils.config_access",
        "type": "function",
        "signature": "(obj: 'Any', path: 'str', default: 'Any' = None)",
        "docstring": "",
        "full_name": "insightspike.utils.config_access.safe_attr",
        "tags": []
      },
      {
        "name": "safe_has",
        "module": "insightspike.utils.config_access",
        "type": "function",
        "signature": "(obj: 'Any', path: 'str') -> 'bool'",
        "docstring": "",
        "full_name": "insightspike.utils.config_access.safe_has",
        "tags": []
      },
      {
        "name": "get_config_value",
        "module": "insightspike.utils.config_utils",
        "type": "function",
        "signature": "(config: Any, path: str, default: Any = None) -> Any",
        "docstring": "Get config value using dot notation.",
        "full_name": "insightspike.utils.config_utils.get_config_value",
        "tags": []
      },
      {
        "name": "is_dict_config",
        "module": "insightspike.utils.config_utils",
        "type": "function",
        "signature": "(config: Any) -> bool",
        "docstring": "Check if config is dict-based.",
        "full_name": "insightspike.utils.config_utils.is_dict_config",
        "tags": []
      },
      {
        "name": "is_object_config",
        "module": "insightspike.utils.config_utils",
        "type": "function",
        "signature": "(config: Any) -> bool",
        "docstring": "Check if config is object-based (has attributes).",
        "full_name": "insightspike.utils.config_utils.is_object_config",
        "tags": []
      },
      {
        "name": "merge_configs",
        "module": "insightspike.utils.config_utils",
        "type": "function",
        "signature": "(base: dict, override: dict) -> dict",
        "docstring": "Deep merge two dict configs.",
        "full_name": "insightspike.utils.config_utils.merge_configs",
        "tags": []
      },
      {
        "name": "normalize_to_dict",
        "module": "insightspike.utils.config_utils",
        "type": "function",
        "signature": "(config: Any) -> dict",
        "docstring": "Convert any config format to dict.",
        "full_name": "insightspike.utils.config_utils.normalize_to_dict",
        "tags": []
      },
      {
        "name": "safe_get",
        "module": "insightspike.utils.config_utils",
        "type": "function",
        "signature": "(config: Any, *keys: str, default: Any = None) -> Any",
        "docstring": "Safely get nested config values from dict or object configs.",
        "full_name": "insightspike.utils.config_utils.safe_get",
        "tags": []
      },
      {
        "name": "set_config_value",
        "module": "insightspike.utils.config_utils",
        "type": "function",
        "signature": "(config: dict, path: str, value: Any) -> None",
        "docstring": "Set config value using dot notation (dict configs only).",
        "full_name": "insightspike.utils.config_utils.set_config_value",
        "tags": []
      },
      {
        "name": "normalize_batch_embeddings",
        "module": "insightspike.utils.embedding_utils",
        "type": "function",
        "signature": "(embeddings: Union[numpy.ndarray, ForwardRef('torch.Tensor'), List]) -> numpy.ndarray",
        "docstring": "Normalize a batch of embeddings to shape (batch_size, dim).",
        "full_name": "insightspike.utils.embedding_utils.normalize_batch_embeddings",
        "tags": []
      },
      {
        "name": "normalize_embedding_shape",
        "module": "insightspike.utils.embedding_utils",
        "type": "function",
        "signature": "(embedding: Union[numpy.ndarray, ForwardRef('torch.Tensor'), List[float]]) -> numpy.ndarray",
        "docstring": "Normalize embedding to shape (dim,) instead of (1, dim).",
        "full_name": "insightspike.utils.embedding_utils.normalize_embedding_shape",
        "tags": []
      },
      {
        "name": "validate_embedding_dimension",
        "module": "insightspike.utils.embedding_utils",
        "type": "function",
        "signature": "(embedding: numpy.ndarray, expected_dim: int = 384) -> bool",
        "docstring": "Validate that embedding has the expected dimension.",
        "full_name": "insightspike.utils.embedding_utils.validate_embedding_dimension",
        "tags": []
      },
      {
        "name": "resolve_project_relative",
        "module": "insightspike.utils.path_utils",
        "type": "function",
        "signature": "(path_like: 'Union[str, Path]') -> 'str'",
        "docstring": "Resolve a path relative to the project root if it's not absolute.",
        "full_name": "insightspike.utils.path_utils.resolve_project_relative",
        "tags": []
      },
      {
        "name": "ResponseEvaluator",
        "module": "insightspike.utils.response_evaluator",
        "type": "class",
        "signature": "(embedding_model=None)",
        "docstring": "Evaluate response quality using multiple similarity metrics.",
        "full_name": "insightspike.utils.response_evaluator.ResponseEvaluator",
        "tags": []
      },
      {
        "name": "SimilarityConverter",
        "module": "insightspike.utils.response_evaluator",
        "type": "class",
        "signature": "()",
        "docstring": "Convert between distance and cosine similarity for normalized vectors.",
        "full_name": "insightspike.utils.response_evaluator.SimilarityConverter",
        "tags": []
      },
      {
        "name": "SimilarityConverter",
        "module": "insightspike.utils.similarity_converter",
        "type": "class",
        "signature": "()",
        "docstring": "Convert between distance and cosine similarity for normalized vectors.",
        "full_name": "insightspike.utils.similarity_converter.SimilarityConverter",
        "tags": []
      },
      {
        "name": "clean_text",
        "module": "insightspike.utils.text_utils",
        "type": "function",
        "signature": "(text: str) -> str",
        "docstring": "Collapse whitespace and trim.",
        "full_name": "insightspike.utils.text_utils.clean_text",
        "tags": []
      },
      {
        "name": "iter_text",
        "module": "insightspike.utils.text_utils",
        "type": "function",
        "signature": "(root: pathlib._local.Path, suffix: str = '.txt') -> Iterable[pathlib._local.Path]",
        "docstring": "Yield all text files under *root*.",
        "full_name": "insightspike.utils.text_utils.iter_text",
        "tags": []
      },
      {
        "name": "jaccard_similarity",
        "module": "insightspike.utils.text_utils",
        "type": "function",
        "signature": "(text1: str, text2: str) -> float",
        "docstring": "Calculate Jaccard similarity between two texts.",
        "full_name": "insightspike.utils.text_utils.jaccard_similarity",
        "tags": []
      },
      {
        "name": "NumpyNearestNeighborIndex",
        "module": "insightspike.vector_index",
        "type": "class",
        "signature": "(dimension: int, **kwargs)",
        "docstring": "NumPy-based nearest neighbor search implementation.",
        "full_name": "insightspike.vector_index.NumpyNearestNeighborIndex",
        "tags": []
      },
      {
        "name": "OptimizedNumpyIndex",
        "module": "insightspike.vector_index",
        "type": "class",
        "signature": "(dimension: int, normalize: bool = True, **kwargs)",
        "docstring": "Optimized NumPy index with batch processing and caching.",
        "full_name": "insightspike.vector_index.OptimizedNumpyIndex",
        "tags": []
      },
      {
        "name": "VectorIndexFactory",
        "module": "insightspike.vector_index",
        "type": "class",
        "signature": "()",
        "docstring": "Factory for creating vector indices.",
        "full_name": "insightspike.vector_index.VectorIndexFactory",
        "tags": []
      },
      {
        "name": "VectorIndexInterface",
        "module": "insightspike.vector_index",
        "type": "class",
        "signature": "(dimension: int, **kwargs)",
        "docstring": "Abstract base class for vector index implementations.",
        "full_name": "insightspike.vector_index.VectorIndexInterface",
        "tags": []
      },
      {
        "name": "FaissIndexWrapper",
        "module": "insightspike.vector_index.factory",
        "type": "class",
        "signature": "(dimension: int, index_type: str = 'Flat', **kwargs)",
        "docstring": "Wrapper for FAISS index to match our interface.",
        "full_name": "insightspike.vector_index.factory.FaissIndexWrapper",
        "tags": []
      },
      {
        "name": "NumpyNearestNeighborIndex",
        "module": "insightspike.vector_index.factory",
        "type": "class",
        "signature": "(dimension: int, **kwargs)",
        "docstring": "NumPy-based nearest neighbor search implementation.",
        "full_name": "insightspike.vector_index.factory.NumpyNearestNeighborIndex",
        "tags": []
      },
      {
        "name": "OptimizedNumpyIndex",
        "module": "insightspike.vector_index.factory",
        "type": "class",
        "signature": "(dimension: int, normalize: bool = True, **kwargs)",
        "docstring": "Optimized NumPy index with batch processing and caching.",
        "full_name": "insightspike.vector_index.factory.OptimizedNumpyIndex",
        "tags": []
      },
      {
        "name": "VectorIndexFactory",
        "module": "insightspike.vector_index.factory",
        "type": "class",
        "signature": "()",
        "docstring": "Factory for creating vector indices.",
        "full_name": "insightspike.vector_index.factory.VectorIndexFactory",
        "tags": []
      },
      {
        "name": "VectorIndexInterface",
        "module": "insightspike.vector_index.factory",
        "type": "class",
        "signature": "(dimension: int, **kwargs)",
        "docstring": "Abstract base class for vector index implementations.",
        "full_name": "insightspike.vector_index.factory.VectorIndexInterface",
        "tags": []
      },
      {
        "name": "VectorIndexInterface",
        "module": "insightspike.vector_index.interface",
        "type": "class",
        "signature": "(dimension: int, **kwargs)",
        "docstring": "Abstract base class for vector index implementations.",
        "full_name": "insightspike.vector_index.interface.VectorIndexInterface",
        "tags": []
      },
      {
        "name": "NumpyNearestNeighborIndex",
        "module": "insightspike.vector_index.numpy_index",
        "type": "class",
        "signature": "(dimension: int, **kwargs)",
        "docstring": "NumPy-based nearest neighbor search implementation.",
        "full_name": "insightspike.vector_index.numpy_index.NumpyNearestNeighborIndex",
        "tags": []
      },
      {
        "name": "OptimizedNumpyIndex",
        "module": "insightspike.vector_index.numpy_index",
        "type": "class",
        "signature": "(dimension: int, normalize: bool = True, **kwargs)",
        "docstring": "Optimized NumPy index with batch processing and caching.",
        "full_name": "insightspike.vector_index.numpy_index.OptimizedNumpyIndex",
        "tags": []
      },
      {
        "name": "VectorIndexInterface",
        "module": "insightspike.vector_index.numpy_index",
        "type": "class",
        "signature": "(dimension: int, **kwargs)",
        "docstring": "Abstract base class for vector index implementations.",
        "full_name": "insightspike.vector_index.numpy_index.VectorIndexInterface",
        "tags": []
      }
    ],
    "count": 763,
    "stats": {
      "total": 763,
      "by_type": {
        "class": 586,
        "function": 177
      },
      "modules": 152
    }
  },
  "scripts": {
    "scripts": [
      "aggregate_baseline_results.py",
      "aggregate_maze_batch.py",
      "aggregate_maze_lambda_sweep.py",
      "aggregate_rag_lambda_sweep.py",
      "analyze_ab_k_stats.py",
      "analyze_step_logs.py",
      "audit_large_files.py",
      "build_plan_index.py",
      "check_g0_snapshot.py",
      "convert_for_baselines.py",
      "decode_results.py",
      "doc_issue_scheduler.py",
      "doc_meta_update.py",
      "maze_phase1_replay.py",
      "migrate_datastore.py",
      "plot_step_log_hist.py",
      "run_baseline_compare.py",
      "run_fixed_mazes.py",
      "run_large_scale.py",
      "run_maze_batch_and_update.py",
      "selftest_ab_logger.py",
      "structural_cost_migration.py",
      "visualize_maze_gif.py"
    ],
    "count": 23,
    "info": [
      {
        "exists": true,
        "path": "/Users/4d/Documents/GitHub/InsightSpike-AI/scripts/aggregate_baseline_results.py",
        "name": "aggregate_baseline_results.py",
        "size": 1339,
        "docstring": "Aggregate geDIG and baseline metrics for quick comparison.  from __future__ import annotations  import argparse import json from dataclasses import dataclass from pathlib import Path from typing import Dict   @dataclass class Metrics: per_mean: float acceptance_rate: float fmr: float latency_p50: float   def load_metrics(path: Path, key: str) -> Metrics: data = json.loads(path.read_text()) result = data[\"results\"][key] return Metrics( per_mean=float(result[\"per_mean\"]), acceptance_rate=float(result[\"acceptance_rate\"]), fmr=float(result[\"fmr\"]), latency_p50=float(result[\"latency_p50\"]), )   def main() -> None: ap = argparse.ArgumentParser() ap.add_argument(\"--gedig\", type=Path, required=True, help=\"geDIG results JSON\") ap.add_argument(\"--baseline\", type=Path, required=True, help=\"baseline results JSON\") ap.add_argument(\"--baseline-key\", type=str, default=\"graphrag_baseline\") args = ap.parse_args()  gedig = load_metrics(args.gedig, \"gedig_ag_dg\") baseline = load_metrics(args.baseline, args.baseline_key)  table: Dict[str, Dict[str, float]] = { \"geDIG\": gedig.__dict__, \"baseline\": baseline.__dict__, } print(json.dumps(table, indent=2))   if __name__ == \"__main__\": main()"
      },
      {
        "exists": true,
        "path": "/Users/4d/Documents/GitHub/InsightSpike-AI/scripts/aggregate_maze_batch.py",
        "name": "aggregate_maze_batch.py",
        "size": 3634,
        "docstring": "Aggregate maze batch results into a single JSON for paper tables.  - Scans a directory for per-seed summary/step logs e.g., paper25_25x25_s500_seed*_summary.json and *_steps.json - Computes mean of key metrics across seeds - Optionally computes AG/DG rates from step logs (fraction of steps with ag_fire/dg_fire) - Emits a compact JSON suitable for docs/paper/data/*.json  Usage: python scripts/aggregate_maze_batch.py \\ --dir experiments/maze-query-hub-prototype/results/batch_25x25 \\ --prefix paper25_25x25_s500_eval_seed \\ --out docs/paper/data/maze_25x25_eval_s500.json  python scripts/aggregate_maze_batch.py \\ --dir experiments/maze-query-hub-prototype/results/batch_25x25 \\ --prefix paper25_25x25_s500_seed \\ --out docs/paper/data/maze_25x25_l3_s500.json"
      },
      {
        "exists": true,
        "path": "/Users/4d/Documents/GitHub/InsightSpike-AI/scripts/aggregate_maze_lambda_sweep.py",
        "name": "aggregate_maze_lambda_sweep.py",
        "size": 5545,
        "docstring": "Aggregate maze query-hub summaries by lambda and optionally plot.  Reads per-run summary JSONs produced by `experiments/maze-query-hub-prototype/run_experiment_query.py` and groups them by `lambda_weight` (taken from summary \u2192 config fallback).  Example: python scripts/aggregate_maze_lambda_sweep.py \\ --dir results/maze-lambda-sweep \\ --glob \"*_summary.json\" \\ --out results/maze-lambda-sweep/maze_lambda_agg.json \\ --plot results/maze-lambda-sweep/maze_lambda_plot.png"
      },
      {
        "exists": true,
        "path": "/Users/4d/Documents/GitHub/InsightSpike-AI/scripts/aggregate_rag_lambda_sweep.py",
        "name": "aggregate_rag_lambda_sweep.py",
        "size": 5167,
        "docstring": "Aggregate exp2to4_lite (RAG lite) results by lambda and optionally plot.  Reads JSON outputs from experiments/exp2to4_lite/src/run_suite.py and groups the chosen baseline metrics by `lambda_weight`.  Example: python scripts/aggregate_rag_lambda_sweep.py \\ --dir experiments/exp2to4_lite/results \\ --glob \"exp23_paper_lambda*_*.json\" \\ --baseline gedig_ag_dg \\ --out results/rag-lambda/agg.json \\ --plot results/rag-lambda/plot.png"
      },
      {
        "exists": true,
        "path": "/Users/4d/Documents/GitHub/InsightSpike-AI/scripts/analyze_ab_k_stats.py",
        "name": "analyze_ab_k_stats.py",
        "size": 2005,
        "docstring": "Analyze A/B geDIG k-estimates aggregated over one or more CSV logs.  Expected CSV header fields (minimal subset used by tests): - query_id, pure_gedig, full_gedig, pure_ged, full_ged, pure_ig, full_ig, k_estimate, k_missing_reason, window_corr_at_record, timestamp  Public function: compute_k_stats(paths: list[str]) -> dict Returns: { 'total_rows': int, 'rows_with_k': int, 'missing_rate': float, 'k_min': float|None, 'k_max': float|None, 'window_corr_last': float|None, }"
      },
      {
        "exists": true,
        "path": "/Users/4d/Documents/GitHub/InsightSpike-AI/scripts/analyze_step_logs.py",
        "name": "analyze_step_logs.py",
        "size": 2070,
        "docstring": ""
      },
      {
        "exists": true,
        "path": "/Users/4d/Documents/GitHub/InsightSpike-AI/scripts/audit_large_files.py",
        "name": "audit_large_files.py",
        "size": 1614,
        "docstring": "List large tracked files to help decide Releases/LFS moves.  Usage: python scripts/audit_large_files.py --min-mb 10 --top 200 > docs/asset_audit/LARGE_FILES.md"
      },
      {
        "exists": true,
        "path": "/Users/4d/Documents/GitHub/InsightSpike-AI/scripts/build_plan_index.py",
        "name": "build_plan_index.py",
        "size": 866,
        "docstring": "Legacy docs index builder stub.  The original project used this script to maintain an index under docs/development/. That directory no longer exists in this fork, but GitHub Actions still calls this script via docs_lint.yml. To keep CI green without reintroducing the old system, we provide a no-op stub that exits successfully."
      },
      {
        "exists": true,
        "path": "/Users/4d/Documents/GitHub/InsightSpike-AI/scripts/check_g0_snapshot.py",
        "name": "check_g0_snapshot.py",
        "size": 4257,
        "docstring": "Quick sanity checker for maze run outputs.  Loads a run JSON (either raw output from run_experiment.py or the derived visualization run_data.json) and verifies that:  * g0_history aligns with g0_components[*]['g0'] * gmin_history aligns with g0_components[*]['gmin'] when present * IG-related fields are populated when ig_value != 0  Intended for lightweight regression checks after navigator/geDIG changes."
      },
      {
        "exists": true,
        "path": "/Users/4d/Documents/GitHub/InsightSpike-AI/scripts/convert_for_baselines.py",
        "name": "convert_for_baselines.py",
        "size": 3690,
        "docstring": "Convert RAG JSONL datasets into baseline-friendly formats.  Currently supports: - GraphRAG: documents.tsv + questions.jsonl  Usage: python scripts/convert_for_baselines.py \\ --input data/sample_queries.jsonl \\ --output-dir experiments/rag-baselines-data/graph_rag"
      }
    ]
  },
  "metrics": {
    "collected": 3,
    "stats": {
      "discovered_methods": {
        "name": "discovered_methods",
        "count": 1,
        "mean": 763.0,
        "std": 0.0,
        "min": 763.0,
        "max": 763.0,
        "sum": 763.0,
        "median": 763.0
      },
      "discovered_modules": {
        "name": "discovered_modules",
        "count": 1,
        "mean": 152.0,
        "std": 0.0,
        "min": 152.0,
        "max": 152.0,
        "sum": 152.0,
        "median": 152.0
      },
      "available_scripts": {
        "name": "available_scripts",
        "count": 1,
        "mean": 23.0,
        "std": 0.0,
        "min": 23.0,
        "max": 23.0,
        "sum": 23.0,
        "median": 23.0
      }
    }
  },
  "summary": {
    "methods_discovered": 763,
    "scripts_available": 23,
    "metrics_collected": 3
  },
  "_export_metadata": {
    "format": "json",
    "timestamp": "2026-01-19T10:42:25.051539",
    "version": "1.0"
  }
}