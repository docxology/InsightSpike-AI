# InsightSpike-AI ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

**Version**: 1.0
**Date**: 2025-11-27
**Status**: Implementation Guideï¼ˆææ¡ˆãƒ»æœªå®Ÿè£…ã‚’å«ã‚€ï¼‰
**æ³¨è¨˜**: æœ¬ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã¯ç¾çŠ¶ã®å·¨å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ã™ã‚‹ã€Œæ¡ˆã€ã§ã™ã€‚è¨˜è¼‰ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª/ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆä¾‹: `layer3/core.py` ãªã©ï¼‰ã¯ã¾ã ãƒªãƒã‚¸ãƒˆãƒªã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚ç¾çŠ¶ã¯å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å®Ÿè£…ï¼ˆä¾‹: `layer3_graph_reasoner.py` 2244è¡Œï¼‰ãŒç¨¼åƒä¸­ã§ã™ã€‚

---

## ğŸ¯ æ¦‚è¦

æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€InsightSpike-AIã®3å¤§å·¨å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ã™ã‚‹ãŸã‚ã®**å…·ä½“çš„ãªå®Ÿè£…æ‰‹é †**ã‚’æä¾›ã—ã¾ã™ã€‚
ãƒ†ã‚¹ãƒˆã¯è»½é‡ãƒ¢ãƒ¼ãƒ‰ï¼ˆ`INSIGHTSPIKE_LITE_MODE=1`ï¼‰ã‚’å‰æã«æ®µéšçš„ã«å®Ÿæ–½ã—ã€mazeç³»ã®ãƒ¬ã‚¬ã‚·ãƒ¼ä¾å­˜ï¼ˆ`navigation`/`core` ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãªã©ï¼‰ãŒæ¬ ã‘ã‚‹ç’°å¢ƒã§ã¯ãã‚Œã‚‰ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã€‚

## ğŸ§ª ãƒ†ã‚¹ãƒˆè¨ˆç”»ï¼ˆå…±é€šï¼‰

### ã‚³ãƒãƒ³ãƒ‰ã‚»ãƒƒãƒˆï¼ˆè»½é‡ãƒ¢ãƒ¼ãƒ‰æƒ³å®šï¼‰

- ã‚¹ãƒ¢ãƒ¼ã‚¯ï¼‹ã‚«ãƒãƒ¬ãƒƒã‚¸å¯¾è±¡ï¼ˆé mazeï¼‰  
  `INSIGHTSPIKE_LITE_MODE=1 INSIGHTSPIKE_MIN_IMPORT=1 PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 pytest -p pytest_cov --cov=src/insightspike --cov-report=term --maxfail=1 tests/e2e tests/gedig`  
  - 2025-11-27 æ™‚ç‚¹ã®å®Ÿè¡Œçµæœ: 18/18 passã€ã‚«ãƒãƒ¬ãƒƒã‚¸ 16.9%ï¼ˆ`fail_under=35` ã§å¤±æ•—ï¼‰ã€‚maze ä¾å­˜ãƒ†ã‚¹ãƒˆã‚’é™¤å¤–ã—ãŸæš«å®šå€¤ã€‚
- Layer3 åˆ†å‰²å¾Œã®å±€æ‰€ã‚«ãƒãƒ¬ãƒƒã‚¸  
  `INSIGHTSPIKE_LITE_MODE=1 INSIGHTSPIKE_MIN_IMPORT=1 PYTEST_DISABLE_PLUGIN_AUTOLOAD=1 pytest -p pytest_cov --cov=src/insightspike/implementations/layers/layer3 --cov-report=term-missing tests/unit/test_layer3_graph_reasoner.py tests/unit/test_message_passing.py tests/unit/test_scalable_graph_builder.py`
- å¾Œæ–¹äº’æ›ç¢ºèª  
  `pytest -q tests/unit/test_layer3_graph_reasoner.py::test_backward_compat_import`
- maze ä¾å­˜ãƒ†ã‚¹ãƒˆï¼ˆ`navigation`/`core` ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å¿…è¦ã¨ã™ã‚‹ã‚‚ã®ï¼‰ã¯ã€ä¾å­˜ã‚’ç”¨æ„ã§ããªã„ç’°å¢ƒã§ã¯  
  `--ignore=tests/maze --ignore=tests/maze-query-hub-prototype --ignore=tests/test_macro_target_adaptive_p*.py --ignore=tests/test_macro_target_metrics.py --ignore=tests/test_maze_navigator_smoke.py --ignore=tests/unit/test_maze_simple_mode.py`  
  ã‚’ä»˜ã‘ã¦ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã€‚

### æˆæœç‰©ãƒã‚§ãƒƒã‚¯

- Layer3 åˆ†å‰² PR ã§ã¯:
  - æ—¢å­˜ãƒ‘ã‚¹ã® import äº’æ›æ€§ã‚’æ‹…ä¿ï¼ˆ`layer3_graph_reasoner` ã® wrapper çµŒç”±ï¼‰
  - ä¸Šè¨˜ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚³ãƒãƒ³ãƒ‰ãŒé€šã‚‹ã“ã¨ï¼ˆ`fail_under` ã‚’ä¸€æ™‚çš„ã«ä¸‹ã’ã¦ã‚‚è‰¯ã„ãŒã€ãƒ¬ãƒãƒ¼ãƒˆå€¤ã¯å¿…ãšè¨˜éŒ²ï¼‰
  - e2e ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆtests/e2eï¼‰ã¨ gedig ã‚¹ã‚¤ãƒ¼ãƒˆãŒã‚°ãƒªãƒ¼ãƒ³ã§ã‚ã‚‹ã“ã¨
- main_agent / gedig_core åˆ†å‰²ã§ã‚‚åŒæ§˜ã«å±€æ‰€ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’è¿½åŠ ã—ã€e2e/gedig ã‚¹ãƒ¢ãƒ¼ã‚¯ã‚’å¿…é ˆã¨ã™ã‚‹ã€‚
- é€²æ—ï¼ˆ2025-11-27â†’ç¾åœ¨ï¼‰: Layer3 ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸è¶³å ´ï¼‹`ConflictScore`/`GraphBuilder`/`message_passing` ãƒ©ãƒƒãƒ‘ãƒ¼æŠ½å‡ºæ¸ˆã¿ã€lazy wrapper ã¨ lite stub ãƒ†ã‚¹ãƒˆæ¸ˆã¿ã€‚MessagePassing åˆæœŸåŒ–ã¯ controller ã«å§”è­²æ¸ˆã¿ï¼ˆapply å®Ÿè¡Œå«ã‚€ï¼‰ã€‚GraphAnalyzer/RewardCalculator ã‚’ layer3 ã« self-contained ç§»æ¤ã—å†ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã€‚GNN åˆæœŸåŒ–ã¯ `layer3/gnn.py` ã«åˆ†é›¢ã€‚MetricsSelector ã‚‚ controller çµŒç”±ã«ã—ã€analysis/message_passing_controller/metrics_controller ã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆè¿½åŠ æ¸ˆã¿ã€‚`analyze_documents` ã¯ `analyzer_runner` ã«å®Œå…¨å§”è­²ï¼ˆæ—§æœ¬ä½“å‰Šé™¤ã€runner ä¾‹å¤–æ™‚ã®ã¿ `_fallback_result`ï¼‰ã€‚query-focal metrics ç”¨ãƒãƒ³ãƒ‰ãƒ©ã‚’ `analyzer_runner` ã«å®Ÿè£…ï¼ˆcore/cached ä¸¡ãƒ‘ã‚¹ã€å¤±æ•—æ™‚ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ï¼‰ã—ã€ãƒ¦ãƒ‹ãƒƒãƒˆè¿½åŠ æ¸ˆã¿ã€‚Layer3/ãƒ¡ãƒˆãƒªã‚¯ã‚¹/GeDIG å°ã‚°ãƒ©ãƒ•ç³»ã®è¿½åŠ ãƒ¦ãƒ‹ãƒƒãƒˆã«ã‚ˆã‚Šã‚«ãƒãƒ¬ãƒƒã‚¸ 18.93%ã€‚e2e+gedig ã‚¹ãƒ¢ãƒ¼ã‚¯ 18/18 pass ç¶™ç¶šã€‚

### æ®‹ã‚¿ã‚¹ã‚¯ï¼ˆLayer3 å®Œäº†ã«å‘ã‘ã¦ï¼‰
- Query-focal metrics ã®å®Ÿãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ï¼ˆk_star/centers/sp_engineï¼‰ã€‚core/cached ä¸¡ãƒ‘ã‚¹ã®æœŸå¾…å€¤ãƒ†ã‚¹ãƒˆã‚’å®Ÿã‚°ãƒ©ãƒ•ã§è¿½åŠ ã€‚
- Layer3 ä»¥å¤–ã®å·¨å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†å‰²ãƒ»ã‚«ãƒãƒ¬ãƒƒã‚¸å¼·åŒ–ï¼ˆmain_agent, gedig_core ãªã©ï¼‰ã€‚

### æ®µéšçš„å®Ÿè¡Œãƒ—ãƒ©ãƒ³ï¼ˆæ¨å¥¨ï¼‰

1. **ãƒ†ã‚¹ãƒˆåŸºç›¤ã®å®‰å®šåŒ–ï¼ˆæœ€åˆã®PRï¼‰**
   - mazeä¾å­˜ãƒ†ã‚¹ãƒˆã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ `-m "not maze"` ãªã©ã®ãƒãƒ¼ã‚«ãƒ¼/ignoreã§æ˜ç¤ºã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ¬ æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å¯¾ç­–ï¼‰
   - `fail_under` ã‚’ä¸€æ™‚çš„ã« 0ã€œ10 ã«ç·©å’Œã—ã€ãƒ¬ãƒãƒ¼ãƒˆå€¤ã‚’è¨˜éŒ²ã—ç¶šã‘ã‚‹ï¼ˆç¾çŠ¶ 10ï¼‰
   - ã‚³ãƒãƒ³ãƒ‰: ä¸Šè¨˜ã‚¹ãƒ¢ãƒ¼ã‚¯ï¼‹ã‚«ãƒãƒ¬ãƒƒã‚¸ï¼ˆe2e+gedigï¼‰ã§ã‚°ãƒªãƒ¼ãƒ³ã«ã™ã‚‹ï¼ˆç¾çŠ¶ 18/18 pass, 16.9%ï¼‰
   - Layer3 ã‚µãƒ–ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’è¿½åŠ ã—ã€å¾“æ¥å®Ÿè£…ã¸ã® lazy delegate ã¨ lite stub ã‚’ç”¨æ„ï¼ˆAPIã¯æœªåˆ†å‰²ã®ã¾ã¾ï¼‰

2. **Layer3 åˆ†å‰²ï¼ˆ2æœ¬ç›®ã®PRï¼‰**
   - `layer3/` ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åŒ–ï¼‹å¾Œæ–¹äº’æ›wrapperç¶­æŒ
   - å±€æ‰€ãƒ†ã‚¹ãƒˆè¿½åŠ ï¼ˆcore/lite_stub/backward compatï¼‰ï¼‹ e2e/gedig ã‚¹ãƒ¢ãƒ¼ã‚¯ã‚’é€šã™
   - ã‚«ãƒãƒ¬ãƒƒã‚¸ç›®æ¨™: ç¾çŠ¶ +5ã€œ10ptï¼ˆã¾ãšã¯ 25% ä»˜è¿‘ã‚’ç›®æŒ‡ã™ï¼‰

3. **main_agent åˆ†å‰²ï¼ˆ3æœ¬ç›®ã®PRï¼‰**
   - `main_agent/` æ§‹é€ åŒ–ï¼‹wrapper
   - å±€æ‰€ãƒ†ã‚¹ãƒˆè¿½åŠ ï¼ˆcycle/memory/layersçµ±åˆï¼‰ï¼‹ e2e/gedig ã‚¹ãƒ¢ãƒ¼ã‚¯
   - ã‚«ãƒãƒ¬ãƒƒã‚¸ç›®æ¨™: 30% ä»˜è¿‘ã¸å¼•ãä¸Šã’

4. **gedig_core åˆ†å‰²ï¼ˆ4æœ¬ç›®ã®PRï¼‰**
   - `algorithms/gedig/` ã¸ã®åˆ†å‰²ï¼‹wrapper
   - å±€æ‰€ãƒ†ã‚¹ãƒˆè¿½åŠ ï¼ˆmetrics/config/results/multihopï¼‰ï¼‹ e2e/gedig ã‚¹ãƒ¢ãƒ¼ã‚¯
   - ã‚«ãƒãƒ¬ãƒƒã‚¸ç›®æ¨™: 35% ä»¥ä¸Šï¼ˆfail_under ã‚’å…ƒã«æˆ»ã™ï¼‰

5. **å¾Œç¶šï¼ˆä»»æ„ï¼‰**
   - å‹ãƒã‚§ãƒƒã‚¯å¼·åŒ–ã€æ®‹ã‚Šå·¨å¤§ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆsqlite_store, layer4_llm_interface, cached_memory_manager, layer2_memory_managerï¼‰ã®ç¸®æ¸›

### å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«

| ãƒ•ã‚¡ã‚¤ãƒ« | è¡Œæ•° | å„ªå…ˆåº¦ | å·¥æ•° |
|---------|------|--------|------|
| layer3_graph_reasoner.py | 2244 | P0 (æœ€å„ªå…ˆ) | 3æ—¥ |
| main_agent.py | 2203 | P0 | 3æ—¥ |
| gedig_core.py | 2035 | P0 | 3æ—¥ |

---

## ğŸ“¦ Part 1: layer3_graph_reasoner.py ã®åˆ†å‰²

**ç¾çŠ¶**: 2244è¡Œï¼ˆæœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
**ç›®æ¨™**: 7ãƒ•ã‚¡ã‚¤ãƒ« Ã— å¹³å‡300è¡Œ

### ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®ä½œæˆ

```bash
cd src/insightspike/implementations/layers

# æ–°è¦ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p layer3/{__pycache__,tests}

# æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
cp layer3_graph_reasoner.py layer3_graph_reasoner.py.backup
```

**æœ€çµ‚çš„ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ **:

```
src/insightspike/implementations/layers/
â”œâ”€â”€ layer3/
â”‚   â”œâ”€â”€ __init__.py              # Public exports
â”‚   â”œâ”€â”€ core.py                  # L3GraphReasonerCore (300è¡Œ)
â”‚   â”œâ”€â”€ gnn.py                   # GNN processing (400è¡Œ)
â”‚   â”œâ”€â”€ conflict.py              # ConflictScore (200è¡Œ)
â”‚   â”œâ”€â”€ analysis.py              # Graph analysis (400è¡Œ)
â”‚   â”œâ”€â”€ message_passing.py       # Message passing (300è¡Œ)
â”‚   â”œâ”€â”€ lite_stub.py             # Lite mode stub (100è¡Œ)
â”‚   â””â”€â”€ diagnostics.py           # Diagnostic utilities (100è¡Œ)
â””â”€â”€ layer3_graph_reasoner.py     # å¾Œæ–¹äº’æ›wrapper (50è¡Œ)
```

---

### ã‚¹ãƒ†ãƒƒãƒ—2: core.py ã®ä½œæˆ

**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/insightspike/implementations/layers/layer3/core.py`

```python
"""Layer3 Core - Base graph reasoner implementation

This module provides the core L3GraphReasoner implementation without
GNN-specific or diagnostic code.
"""

from __future__ import annotations

import logging
import os
from typing import Any, Dict, List, Optional

import numpy as np
import networkx as nx

from ....core.base import L3GraphReasonerInterface, LayerInput, LayerOutput
from ....config import get_config
from ....config.legacy_adapter import LegacyConfigAdapter

logger = logging.getLogger(__name__)

# Lightweight cosine similarity fallback
def _cosine_similarity(a: np.ndarray, b: Optional[np.ndarray] = None):
    """Compute cosine similarity (NumPy-only implementation)"""
    if b is None:
        b = a
    a = np.asarray(a, dtype=float)
    b = np.asarray(b, dtype=float)
    a_norm = a / (np.linalg.norm(a, axis=1, keepdims=True) + 1e-12)
    b_norm = b / (np.linalg.norm(b, axis=1, keepdims=True) + 1e-12)
    return a_norm @ b_norm.T


class L3GraphReasonerCore(L3GraphReasonerInterface):
    """Base implementation of Layer3 graph reasoning.

    This class provides the core functionality without GNN or heavy
    dependencies, suitable for lite mode and testing.

    Attributes:
        config: Configuration object
        enabled: Whether the reasoner is enabled
        current_graph: Current graph state
    """

    def __init__(self, config=None):
        """Initialize the core reasoner.

        Args:
            config: Optional configuration. If None, loads default.
        """
        self.config = LegacyConfigAdapter.ensure_pydantic(config or get_config())
        self.enabled = True
        self.current_graph = None
        self._initialized = False

        logger.info("L3GraphReasonerCore initialized (lite mode)")

    def initialize(self) -> bool:
        """Initialize the reasoner.

        Returns:
            True if successful
        """
        self._initialized = True
        return True

    def analyze_documents(
        self,
        documents: List[Dict[str, Any]],
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Analyze documents and build/update graph.

        Args:
            documents: List of document dictionaries
            context: Optional context information

        Returns:
            Analysis results dictionary with keys:
                - graph: NetworkX graph
                - metrics: Delta metrics (GED, IG)
                - conflicts: Conflict detection results
                - reward: Reward signals
                - spike_detected: Whether insight spike detected
                - reasoning_quality: Quality score [0, 1]
        """
        if not self._initialized:
            self.initialize()

        # Build graph from documents
        from .graph_builder import build_graph_from_documents
        graph = build_graph_from_documents(documents, context)

        # Compute metrics
        from .metrics import compute_delta_metrics
        metrics = compute_delta_metrics(self.current_graph, graph)

        # Detect conflicts
        from .conflict import detect_conflicts
        conflicts = detect_conflicts(self.current_graph, graph, context or {})

        # Compute rewards
        reward = self._compute_reward(metrics, conflicts)

        # Spike detection
        spike_detected = self._detect_spike(metrics)

        # Update current graph
        self.current_graph = graph

        return {
            "graph": graph,
            "metrics": metrics,
            "conflicts": conflicts,
            "reward": reward,
            "spike_detected": spike_detected,
            "reasoning_quality": self._compute_quality(metrics, conflicts),
        }

    def _compute_reward(
        self,
        metrics: Dict[str, float],
        conflicts: Dict[str, float]
    ) -> Dict[str, float]:
        """Compute reward signals from metrics and conflicts.

        Args:
            metrics: Delta metrics
            conflicts: Conflict scores

        Returns:
            Reward dictionary
        """
        delta_ged = metrics.get("delta_ged", 0.0)
        delta_ig = metrics.get("delta_ig", 0.0)
        conflict_total = conflicts.get("total", 0.0)

        # Simple reward formula
        insight_reward = -delta_ged + delta_ig
        quality_bonus = max(0, 1.0 - conflict_total)
        total = insight_reward + 0.3 * quality_bonus

        return {
            "insight_reward": float(insight_reward),
            "quality_bonus": float(quality_bonus),
            "total": float(total),
        }

    def _detect_spike(self, metrics: Dict[str, float]) -> bool:
        """Detect insight spike from metrics.

        Args:
            metrics: Delta metrics

        Returns:
            True if spike detected
        """
        delta_ged = metrics.get("delta_ged", 0.0)
        delta_ig = metrics.get("delta_ig", 0.0)

        ged_threshold = self.config.graph.spike_ged_threshold
        ig_threshold = self.config.graph.spike_ig_threshold

        return delta_ged < ged_threshold and delta_ig > ig_threshold

    def _compute_quality(
        self,
        metrics: Dict[str, float],
        conflicts: Dict[str, float]
    ) -> float:
        """Compute reasoning quality score.

        Args:
            metrics: Delta metrics
            conflicts: Conflict scores

        Returns:
            Quality score [0, 1]
        """
        delta_ig = metrics.get("delta_ig", 0.0)
        conflict_total = conflicts.get("total", 0.0)

        # Higher IG and lower conflict = higher quality
        quality = 0.5 + 0.3 * min(delta_ig, 1.0) - 0.3 * conflict_total
        return float(np.clip(quality, 0.0, 1.0))


__all__ = ["L3GraphReasonerCore"]
```

---

### ã‚¹ãƒ†ãƒƒãƒ—3: lite_stub.py ã®ä½œæˆ

**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/insightspike/implementations/layers/layer3/lite_stub.py`

```python
"""Lite mode stub for Layer3 graph reasoner

Provides a minimal placeholder when torch/PyG are not available.
"""

from __future__ import annotations

import logging
from typing import Any, Dict, List, Optional

logger = logging.getLogger(__name__)


class L3GraphReasonerLiteStub:
    """Lightweight stub for lite mode.

    This stub is used when INSIGHTSPIKE_LITE_MODE=1 or when
    torch_geometric is not available.
    """

    def __init__(self, config=None):
        self.config = config
        self.enabled = False
        self.current_graph = None
        logger.info("L3GraphReasoner: Using lite stub (torch/PyG not available)")

    def initialize(self) -> bool:
        """Initialize (no-op)."""
        return True

    def analyze(self, *args, **kwargs) -> Dict[str, Any]:
        """Legacy analyze method (for backward compat)."""
        return {"enabled": False, "reason": "lite_mode"}

    def analyze_documents(
        self,
        documents: List[Dict[str, Any]],
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """Return minimal analysis dict that MainAgent expects.

        Args:
            documents: List of documents
            context: Optional context

        Returns:
            Minimal analysis result
        """
        return {
            "graph": None,
            "metrics": {"delta_ged": 0.0, "delta_ig": 0.0},
            "conflicts": {"total": 0},
            "reward": {"insight_reward": 0.0, "quality_bonus": 0.0, "total": 0.0},
            "reasoning_quality": 0.5,
            "spike_detected": False,
        }


__all__ = ["L3GraphReasonerLiteStub"]
```

---

### ã‚¹ãƒ†ãƒƒãƒ—4: __init__.py ã®ä½œæˆ

**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/insightspike/implementations/layers/layer3/__init__.py`

```python
"""Layer3 Graph Reasoner Package

This package provides graph-based reasoning with spike detection.

Modules:
    core: Base graph reasoner implementation
    gnn: GNN processing (requires torch_geometric)
    conflict: Conflict detection
    analysis: Graph analysis
    message_passing: Message passing operations
    lite_stub: Lightweight stub for lite mode
    diagnostics: Diagnostic utilities
"""

import os
import logging

logger = logging.getLogger(__name__)

# Check environment
LITE_MODE = os.getenv("INSIGHTSPIKE_LITE_MODE") == "1"
DISABLE_GNN = os.getenv("INSIGHTSPIKE_DISABLE_GNN") == "1"

# Check torch_geometric availability
def _have_torch_geometric() -> bool:
    try:
        import torch  # noqa: F401
        import torch_geometric  # noqa: F401
        return True
    except ImportError:
        return False

# Select implementation
if LITE_MODE or not _have_torch_geometric():
    # Use lite stub
    from .lite_stub import L3GraphReasonerLiteStub as L3GraphReasoner
    logger.info("Layer3: Using lite stub (torch/PyG not available)")
else:
    # Use full implementation
    if DISABLE_GNN:
        from .core import L3GraphReasonerCore as L3GraphReasoner
        logger.info("Layer3: Using core implementation (GNN disabled)")
    else:
        try:
            from .gnn import L3GraphReasonerWithGNN as L3GraphReasoner
            logger.info("Layer3: Using GNN implementation")
        except ImportError:
            from .core import L3GraphReasonerCore as L3GraphReasoner
            logger.warning("Layer3: GNN import failed, using core implementation")

# Export
__all__ = ["L3GraphReasoner"]
```

---

### ã‚¹ãƒ†ãƒƒãƒ—5: å¾Œæ–¹äº’æ›wrapper ã®ä½œæˆ

**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/insightspike/implementations/layers/layer3_graph_reasoner.py`

```python
"""Backward compatibility wrapper for Layer3GraphReasoner

This module maintains the original import path for backward compatibility.
New code should import from `layer3` package directly.

Example:
    # Old style (still works)
    from insightspike.implementations.layers.layer3_graph_reasoner import L3GraphReasoner

    # New style (preferred)
    from insightspike.implementations.layers.layer3 import L3GraphReasoner
"""

import warnings

# Import from new location
from .layer3 import L3GraphReasoner

# Deprecation warning (optional, can be removed later)
# warnings.warn(
#     "Importing from layer3_graph_reasoner is deprecated. "
#     "Use 'from insightspike.implementations.layers.layer3 import L3GraphReasoner' instead.",
#     DeprecationWarning,
#     stacklevel=2
# )

__all__ = ["L3GraphReasoner"]
```

---

### ã‚¹ãƒ†ãƒƒãƒ—6: ãƒ†ã‚¹ãƒˆã®ä½œæˆ

**ãƒ•ã‚¡ã‚¤ãƒ«**: `tests/unit/implementations/layers/test_layer3_refactored.py`

```python
"""Tests for refactored Layer3 modules"""

import pytest
from insightspike.implementations.layers.layer3 import L3GraphReasoner
from insightspike.implementations.layers.layer3.core import L3GraphReasonerCore
from insightspike.implementations.layers.layer3.lite_stub import L3GraphReasonerLiteStub


class TestLayer3Refactored:
    """Test refactored Layer3 components"""

    def test_import_backward_compat(self):
        """Test backward compatibility import"""
        from insightspike.implementations.layers.layer3_graph_reasoner import (
            L3GraphReasoner as LegacyL3
        )
        assert LegacyL3 is not None

    def test_core_initialization(self):
        """Test core reasoner initialization"""
        reasoner = L3GraphReasonerCore()
        assert reasoner is not None
        assert reasoner.initialize() is True

    def test_lite_stub_initialization(self):
        """Test lite stub initialization"""
        stub = L3GraphReasonerLiteStub()
        assert stub.enabled is False
        assert stub.initialize() is True

    def test_analyze_documents_core(self):
        """Test core analyze_documents"""
        reasoner = L3GraphReasonerCore()
        reasoner.initialize()

        documents = [
            {"text": "Test document 1"},
            {"text": "Test document 2"},
        ]

        result = reasoner.analyze_documents(documents)

        assert "graph" in result
        assert "metrics" in result
        assert "spike_detected" in result
        assert isinstance(result["reasoning_quality"], float)

    def test_analyze_documents_lite(self):
        """Test lite stub analyze_documents"""
        stub = L3GraphReasonerLiteStub()

        documents = [{"text": "Test"}]
        result = stub.analyze_documents(documents)

        assert result["graph"] is None
        assert result["spike_detected"] is False
```

---

### ã‚¹ãƒ†ãƒƒãƒ—7: ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] `layer3/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
- [ ] `core.py` å®Ÿè£…
- [ ] `lite_stub.py` å®Ÿè£…
- [ ] `__init__.py` å®Ÿè£…ï¼ˆlite modeåˆ‡ã‚Šæ›¿ãˆï¼‰
- [ ] å¾Œæ–¹äº’æ›wrapperä½œæˆ
- [ ] ãƒ†ã‚¹ãƒˆä½œæˆãƒ»å®Ÿè¡Œ
- [ ] CIé€šéç¢ºèª
- [ ] æ—¢å­˜ã®å…¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒå‹•ä½œç¢ºèª
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°

---

## ğŸ“¦ Part 2: main_agent.py ã®åˆ†å‰²

**ç¾çŠ¶**: 2203è¡Œ
**ç›®æ¨™**: 6ãƒ•ã‚¡ã‚¤ãƒ« Ã— å¹³å‡350è¡Œ

### åˆ†å‰²å¾Œã®æ§‹é€ 

```
src/insightspike/implementations/agents/
â”œâ”€â”€ main_agent/
â”‚   â”œâ”€â”€ __init__.py              # Public exports
â”‚   â”œâ”€â”€ core.py                  # MainAgent core (500è¡Œ)
â”‚   â”œâ”€â”€ cycle.py                 # Cycle processing (400è¡Œ)
â”‚   â”œâ”€â”€ memory.py                # Memory management (300è¡Œ)
â”‚   â”œâ”€â”€ layers.py                # Layer integration (400è¡Œ)
â”‚   â””â”€â”€ diagnostics.py           # Diagnostics (200è¡Œ)
â””â”€â”€ main_agent.py                # å¾Œæ–¹äº’æ›wrapper (50è¡Œ)
```

### å®Ÿè£…ã‚¬ã‚¤ãƒ‰

**core.py**: MainAgentã‚¯ãƒ©ã‚¹ã®åŸºæœ¬æ§‹é€ 
```python
"""MainAgent Core Implementation"""

from dataclasses import dataclass
from typing import Any, Dict, List, Optional

@dataclass
class CycleResult:
    """Result from one reasoning cycle"""
    question: str
    retrieved_documents: List[Dict[str, Any]]
    graph_analysis: Dict[str, Any]
    response: str
    reasoning_quality: float
    spike_detected: bool
    error_state: Dict[str, Any]
    cycle_number: int
    success: bool = True
    query_id: Optional[str] = None


class MainAgentCore:
    """Core orchestrating agent (without layer dependencies)"""

    def __init__(self, config=None, datastore=None):
        if config is None:
            raise ValueError("Config must be provided to MainAgent")

        self.config = config
        self.datastore = datastore
        self._initialized = False

    def initialize(self) -> bool:
        """Initialize agent components"""
        # Basic initialization (layers loaded separately)
        self._initialized = True
        return True
```

**cycle.py**: æ¨è«–ã‚µã‚¤ã‚¯ãƒ«å‡¦ç†
```python
"""Cycle Processing Logic"""

def process_cycle(
    agent,
    question: str,
    cycle_num: int,
    max_cycles: int,
    verbose: bool = False
) -> CycleResult:
    """Process single reasoning cycle"""
    # Document retrieval
    documents = agent.l2_memory.search_episodes(question)

    # Graph analysis
    graph_analysis = agent.l3_graph.analyze_documents(documents)

    # LLM generation
    response = agent.l4_llm.generate_response_detailed(
        context=documents,
        question=question
    )

    # Build result
    return CycleResult(
        question=question,
        retrieved_documents=documents,
        graph_analysis=graph_analysis,
        response=response["response"],
        reasoning_quality=0.8,
        spike_detected=graph_analysis.get("spike_detected", False),
        error_state={},
        cycle_number=cycle_num,
        success=True,
    )
```

---

## ğŸ“¦ Part 3: gedig_core.py ã®åˆ†å‰²

**ç¾çŠ¶**: 2035è¡Œ
**ç›®æ¨™**: 6ãƒ•ã‚¡ã‚¤ãƒ« Ã— å¹³å‡300è¡Œ

### åˆ†å‰²å¾Œã®æ§‹é€ 

```
src/insightspike/algorithms/
â”œâ”€â”€ gedig/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core.py                  # GeDIGCore class (400è¡Œ)
â”‚   â”œâ”€â”€ config.py                # Configuration (200è¡Œ)
â”‚   â”œâ”€â”€ multihop.py              # Multi-hop processing (500è¡Œ)
â”‚   â”œâ”€â”€ metrics.py               # Metrics calculation (300è¡Œ)
â”‚   â”œâ”€â”€ normalization.py         # Normalization (300è¡Œ)
â”‚   â””â”€â”€ results.py               # Result dataclasses (100è¡Œ)
â””â”€â”€ gedig_core.py                # å¾Œæ–¹äº’æ›wrapper (50è¡Œ)
```

### å®Ÿè£…ã‚¬ã‚¤ãƒ‰

**results.py**: ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹æŠ½å‡º
```python
"""geDIG Result Data Classes"""

from dataclasses import dataclass, asdict
from typing import Any, Dict, Optional, Set

@dataclass
class HopResult:
    """Per-hop evaluation result"""
    hop: int
    ged: float
    ig: float
    gedig: float
    struct_cost: float
    node_count: int
    edge_count: int
    sp: float = 0.0
    h_component: float = 0.0
    # ... (full fields)


@dataclass
class GeDIGResult:
    """Complete geDIG calculation result"""
    gedig_value: float
    ged_value: float
    ig_value: float
    raw_ged: float = 0.0
    ged_norm_den: float = 1.0
    # ... (full fields)

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)
```

**config.py**: è¨­å®šã‚¯ãƒ©ã‚¹æŠ½å‡º
```python
"""geDIG Configuration Management"""

from dataclasses import dataclass
from typing import Optional

@dataclass
class GeDIGConfig:
    """Configuration for geDIG calculator"""

    # Cost parameters
    node_cost: float = 1.0
    edge_cost: float = 1.0
    normalization: str = 'sum'
    efficiency_weight: float = 0.3

    # geDIG formula
    lambda_weight: float = 1.0
    sp_beta: float = 0.2

    # Multi-hop
    enable_multihop: bool = False
    max_hops: int = 3
    decay_factor: float = 0.7

    # Spike detection
    spike_threshold: float = -0.5
    tau_s: float = 0.15
    tau_i: float = 0.25

    # ... (other fields)
```

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### å¾Œæ–¹äº’æ›æ€§ãƒ†ã‚¹ãƒˆ

```python
# tests/integration/test_refactoring_backward_compat.py
"""Test backward compatibility after refactoring"""

def test_layer3_backward_compat():
    """Ensure old import path still works"""
    from insightspike.implementations.layers.layer3_graph_reasoner import (
        L3GraphReasoner
    )
    reasoner = L3GraphReasoner()
    assert reasoner is not None

def test_main_agent_backward_compat():
    """Ensure MainAgent still works"""
    from insightspike.implementations.agents.main_agent import MainAgent
    from insightspike.config.presets import ConfigPresets

    config = ConfigPresets.development()
    agent = MainAgent(config=config)
    assert agent is not None

def test_gedig_core_backward_compat():
    """Ensure GeDIGCore still works"""
    from insightspike.algorithms.gedig_core import GeDIGCore

    core = GeDIGCore()
    assert core is not None
```

---

## ğŸ“‹ å®Ÿè¡Œãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### Phase 1: layer3_graph_reasoner.py (Week 1)

- [ ] Day 1: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ + core.pyå®Ÿè£…
- [ ] Day 2: lite_stub.py + __init__.pyå®Ÿè£…
- [ ] Day 3: ãƒ†ã‚¹ãƒˆä½œæˆ + CIç¢ºèª

### Phase 2: main_agent.py (Week 2)

- [ ] Day 1: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€  + core.py
- [ ] Day 2: cycle.py + memory.py
- [ ] Day 3: ãƒ†ã‚¹ãƒˆ + CIç¢ºèª

### Phase 3: gedig_core.py (Week 3)

- [ ] Day 1: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€  + results.py + config.py
- [ ] Day 2: multihop.py + metrics.py
- [ ] Day 3: ãƒ†ã‚¹ãƒˆ + CIç¢ºèª

---

## âš ï¸ æ³¨æ„äº‹é …

### ç ´å£Šçš„å¤‰æ›´ã‚’é¿ã‘ã‚‹

1. **å¾Œæ–¹äº’æ›wrapperã‚’å¿…ãšä½œæˆ**
   - æ—¢å­˜ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã‚’ç¶­æŒ
   - Deprecationè­¦å‘Šã¯å¾Œã‹ã‚‰è¿½åŠ 

2. **æ®µéšçš„ç§»è¡Œ**
   - ä¸€åº¦ã«å…¨ã¦ã‚’å¤‰ãˆãªã„
   - å„ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«PRä½œæˆ

3. **ãƒ†ã‚¹ãƒˆã®å……å®Ÿ**
   - å„æ®µéšã§CIé€šéã‚’ç¢ºèª
   - æ—¢å­˜ãƒ†ã‚¹ãƒˆãŒå…¨ã¦ãƒ‘ã‚¹

### ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

```
refactor(layer3): split layer3_graph_reasoner.py into modular structure

- Create layer3/ package with core, gnn, conflict modules
- Add lite_stub for lightweight operation
- Maintain backward compatibility via wrapper
- Add tests for new structure

Refs: #123 (issue number)
```

---

## ğŸ“š å‚è€ƒè³‡æ–™

- Martin Fowler "Refactoring": Extract Module pattern
- "Working Effectively with Legacy Code": Seam patterns
- Python Import System: PEP 420 (Namespace packages)

---

**ã“ã®ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã«å¾“ãˆã°ã€3é€±é–“ã§å…¨ã¦ã®å·¨å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ã§ãã¾ã™ã€‚**

è©³ç´°ãªèƒŒæ™¯ã¨æˆ¦ç•¥ã¯ `comprehensive_improvement_plan.md` ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
